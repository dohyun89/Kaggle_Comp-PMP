{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77C_1TSRi_vG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5EKhetATjleA",
    "outputId": "94402b4b-58b0-4206-cc50-feaadf5cd17d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PN9rgPOZjvA2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "VDIupEzekKcQ",
    "outputId": "1f94624d-91eb-42d9-f56b-0b57e15c3db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "x94rJatBkR0W",
    "outputId": "8d3fc970-50ad-43bc-baab-84ef362cdf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ankush Boarding Pass.pdf'\n",
      "'Ankush_Hore (1).pdf'\n",
      "'Ankush_Hore (2).pdf'\n",
      " Ankush_Hore.pdf\n",
      " ASRM_552\n",
      " AV_Safety.ipynb\n",
      " Books\n",
      "'CFA Program Curriculum 2017 Level 1 Volume 1-6..pdf'\n",
      "'Colab Notebooks'\n",
      "'College list - CS.xlsx'\n",
      "'DESKTOP BACKUP'\n",
      " drive-download-20181231T075723Z-001\n",
      " DSC01682.JPG.gdoc\n",
      " Fl_Booking.GOFLDANDd1bcd1449157132_6E434_AF1D2R\n",
      " Frankl\n",
      " Images\n",
      " IMG_20181010_223213.jpg\n",
      " IMG_20181024_002029.jpg\n",
      "'[Joseph_Gallian]_Contemporary_Abstract_Algebra_9e_(BookZZ.org).pdf.zip'\n",
      "'Machine Learning_ A Probabilistic Perspective [Murphy 2012-08-24].pdf'\n",
      "'McGrawHill - Machine Learning -Tom Mitchell.pdf'\n",
      " PANO_20180504_160844.jpg\n",
      " pb5.jpg\n",
      " pf1.csv\n",
      " STAT542\n",
      " structures.csv\n",
      "'TCS_Resume Format_2012 - Copy.doc'\n",
      "'TCS_Resume Format_2012 - Copy.doc.gdoc'\n",
      " test.csv\n",
      " train.csv\n",
      " WIN_20180202_10_42_13_Pro.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGHQx4mUkdAn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9Ks-gO8os8K-",
    "outputId": "64375fcd-4700-4547-9a25-7357ca78d06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10kB 21.0MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 840kB/s eta 0:00:02\r",
      "\u001b[K     |█                               | 30kB 1.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 821kB/s eta 0:00:02\r",
      "\u001b[K     |█▋                              | 51kB 1.0MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 1.2MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 71kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 81kB 1.6MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 102kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 112kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 133kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 143kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 163kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 174kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 184kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 194kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 204kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 215kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 225kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 235kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 245kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 256kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 266kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 276kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 286kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 296kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 307kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 317kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 327kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 337kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 348kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 358kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 368kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 378kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 389kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 399kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 409kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 419kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 430kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 440kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 450kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 460kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 471kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 481kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 491kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 501kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 512kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 522kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 532kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 542kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 552kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 563kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 573kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 583kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 593kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 604kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 614kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 624kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 634kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 645kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 655kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 665kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 675kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 686kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 696kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 706kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 716kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 727kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 737kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 747kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 757kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 768kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 778kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 788kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 798kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 808kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 819kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 829kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 839kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 849kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 860kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 870kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 880kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 890kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 901kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 911kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 921kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 931kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 942kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 952kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 962kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 972kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 983kB 1.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 993kB 1.4MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aD-qtLV0s_EJ"
   },
   "outputs": [],
   "source": [
    "link_train = \"https://drive.google.com/open?id=1-0pw1faPNc0Ci0Lkhc5k1-yGG7tcq0Nv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HQjHDFMmu2Zu",
    "outputId": "9e3db21c-2025-4f1c-eccf-52f12dfd93ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-0pw1faPNc0Ci0Lkhc5k1-yGG7tcq0Nv\n"
     ]
    }
   ],
   "source": [
    "fluff, id = link_train.split('=')\n",
    "print (id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "KksWjvYBu9TP",
    "outputId": "2ea1f460-935c-4a4b-fae1-a96df5232141"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0809 02:11:42.353917 140262493333376 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
     ]
    }
   ],
   "source": [
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train.csv')  \n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Q-ga_7rvJ_7"
   },
   "outputs": [],
   "source": [
    "link_st = \"https://drive.google.com/open?id=1vw0iYk8oF6uXoFfyNutlQfLPZQbreVIj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AqXtfRoovOmj",
    "outputId": "07a014e9-40d6-4474-e2f5-3a7fe2c26e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1vw0iYk8oF6uXoFfyNutlQfLPZQbreVIj\n"
     ]
    }
   ],
   "source": [
    "fluff2, id2 = link_st.split('=')\n",
    "print (id2) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPEPW-_Pvh6a"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':id2}) \n",
    "downloaded.GetContentFile('structures.csv')  \n",
    "structures = pd.read_csv('structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCMw6Mo-vutK"
   },
   "outputs": [],
   "source": [
    "inter_train = train.merge(structures, how='inner', left_on=['molecule_name','atom_index_0'], \n",
    "                right_on=['molecule_name','atom_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhfAXL_tv0dX"
   },
   "outputs": [],
   "source": [
    "loaded_train = inter_train.merge(structures, how='inner', left_on=['molecule_name','atom_index_1'], \n",
    "                right_on=['molecule_name','atom_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhZ61IPowDdw"
   },
   "outputs": [],
   "source": [
    "loaded_train_dropped_cols = loaded_train.drop(['atom_index_x','atom_index_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "MU3zgc9twHFg",
    "outputId": "202ce043-78e6-43ed-8cd5-f9897d0058bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "type_field = loaded_train_dropped_cols[\"type\"]\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "type_field_bin = lb.fit_transform(type_field)\n",
    "\n",
    "coordinates_df = loaded_train_dropped_cols[[\"x_x\", \"y_x\", \"z_x\", \"x_y\", \"y_y\", \"z_y\", \"scalar_coupling_constant\"]]\n",
    "\n",
    "coordinates_array = coordinates_df.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O72OyWOVwdoc"
   },
   "outputs": [],
   "source": [
    "final_array = np.concatenate((type_field_bin, coordinates_array), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvfFpjJ_wfLc"
   },
   "outputs": [],
   "source": [
    "molecule_id = np.zeros(len(final_array))\n",
    "prev_molecule = \"garbage\"\n",
    "i = 0\n",
    "j = 0\n",
    "for each_row in loaded_train_dropped_cols.iterrows():\n",
    "    new_molecule = each_row[1][1]\n",
    "    if prev_molecule != new_molecule:\n",
    "        i = i + 1\n",
    "    molecule_id[j] = i\n",
    "    prev_molecule = new_molecule\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDlMuIOEwjr1"
   },
   "outputs": [],
   "source": [
    "molecule_id_T = molecule_id.reshape((len(molecule_id),1))\n",
    "\n",
    "final_array_2 = np.concatenate((molecule_id_T, final_array), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Hw6pEHwwqkJ"
   },
   "outputs": [],
   "source": [
    "final_array_3 = np.zeros((4658147, 17))\n",
    "\n",
    "final_array_3[:,:15] = final_array_2[:,:15]\n",
    "\n",
    "for i in range(len(final_array_3)):\n",
    "    final_array_3[i,15] = np.linalg.norm(final_array_3[i, 9:12] - final_array_3[i, 12:15])\n",
    "\n",
    "final_array_3[:,16] = final_array_2[:,15]\n",
    "\n",
    "#final_array_3[:25,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RVZSlj_zw4iu",
    "outputId": "8dbd87bb-9b34-4cdb-d263-a8b022e66495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 17)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_array_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9SRfgE5xAsH"
   },
   "outputs": [],
   "source": [
    "#old|def convert_to_superarray(final_array_2):\n",
    "    superarray = np.zeros((85003, 135, 17, 1))\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    mole = 0\n",
    "    last_flag = 0\n",
    "    while ((mole <= 85002) and (begin <= 4658146) and (end <= 4658146)):\n",
    "        while final_array_2[end][0] <= final_array_2[begin][0]:\n",
    "            if end == 4658146:\n",
    "                last_flag = 1\n",
    "                break\n",
    "            else:\n",
    "                end = end + 1\n",
    "        if last_flag == 1:\n",
    "            end = end + 1\n",
    "        length = end - begin\n",
    "        X_batch_temp_t = final_array_2[begin:end, :].copy()\n",
    "        up = (135 - length) // 2\n",
    "        if (135 - length) % 2 == 1:\n",
    "            down = ((135 - length) // 2) + 1\n",
    "        else:\n",
    "            down = ((135 - length) // 2)\n",
    "        X_batch_temp_2 = np.pad(X_batch_temp_t, ((up, down), (0, 0)), 'constant')\n",
    "        X_batch_temp_3 = X_batch_temp_2.reshape((135, 17, 1))\n",
    "        superarray[mole] = X_batch_temp_3\n",
    "        mole = mole + 1\n",
    "        begin = end\n",
    "    return superarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clea4zKaMUNn"
   },
   "outputs": [],
   "source": [
    "def convert_to_superarray(final_array_2):\n",
    "    superarray = np.zeros((85003, 135, 17, 1))\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    mole = 0\n",
    "    last_flag = 0\n",
    "    while ((mole <= 85002) and (begin <= 4658146) and (end <= 4658146)):\n",
    "        while final_array_2[end][0] <= final_array_2[begin][0]:\n",
    "            if end == 4658146:\n",
    "                last_flag = 1\n",
    "                break\n",
    "            else:\n",
    "                end = end + 1\n",
    "        if last_flag == 1:\n",
    "            end = end + 1\n",
    "        length = end - begin\n",
    "        X_batch_temp_t = final_array_2[begin:end, :].copy()\n",
    "        down = 135 - length\n",
    "        X_batch_temp_2 = np.pad(X_batch_temp_t, ((0, down), (0, 0)), 'constant')\n",
    "        X_batch_temp_3 = X_batch_temp_2.reshape((135, 17, 1))\n",
    "        superarray[mole] = X_batch_temp_3\n",
    "        mole = mole + 1\n",
    "        begin = end\n",
    "    return superarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mDWcZyB6xAdV",
    "outputId": "66eab2bb-5900-4b08-f5d9-5fbe39bd009f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85003, 135, 17, 1)\n",
      "(65000, 135, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "superarray = convert_to_superarray(final_array_3)\n",
    "\n",
    "print(superarray.shape)\n",
    "\n",
    "superarray2 = superarray.copy()\n",
    "np.random.shuffle(superarray2)\n",
    "\n",
    "superarray_train = superarray2[:65000, :, :, :].copy()\n",
    "superarray_val = superarray2[65000:, :, :, :].copy()\n",
    "\n",
    "print(superarray_train.shape)\n",
    "\n",
    "X_train = superarray_train[:, :, 1:16, :].copy()\n",
    "y_train_temp = superarray_train[:, :, 16, :].copy()\n",
    "y_train = y_train_temp.reshape((65000, 135))\n",
    "\n",
    "X_val = superarray_val[:, :, 1:16, :].copy()\n",
    "y_val_temp = superarray_val[:, :, 16, :].copy()\n",
    "y_val = y_val_temp.reshape((20003, 135))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Ih9pYLruxcjY",
    "outputId": "1f672997-8408-48fb-8520-0ca4686c7956"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 02:26:59.976041 140262493333376 deprecation.py:323] From <ipython-input-25-e8b2f7d840ad>:6: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 135, 15, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 135])\n",
    "training_flag = 1\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(batch_size).repeat()\n",
    "iter = dataset.make_initializable_iterator()\n",
    "features, labels = iter.get_next()\n",
    "#filter1 = #60 6 3 \\ 76 9 1 3\n",
    "#filter2 #25 4 6 \\ 36 3 3 6\n",
    "#filter3 #5 5 10 \\ 16 2 6 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "uq_ayIpExcgw",
    "outputId": "119ca189-e6eb-497b-d1a6-db4fc2a68b0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 05:35:52.299783 139722750404480 deprecation.py:323] From <ipython-input-26-8bfac6555419>:2: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0806 05:35:52.385833 139722750404480 deprecation.py:323] From <ipython-input-26-8bfac6555419>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0806 05:35:52.390032 139722750404480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0806 05:35:52.717778 139722750404480 deprecation.py:323] From <ipython-input-26-8bfac6555419>:12: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0806 05:35:52.933195 139722750404480 deprecation.py:323] From <ipython-input-26-8bfac6555419>:13: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"cnn\"):\n",
    "    X_normalized = tf.layers.batch_normalization(features, training = training_flag)\n",
    "    conv1 = tf.layers.conv2d(X_normalized, 3, [76, 10])\n",
    "    conv1_normalized = tf.layers.batch_normalization(conv1, training = training_flag)\n",
    "    conv1_out = tf.nn.relu(conv1_normalized)\n",
    "    conv2 = tf.layers.conv2d(conv1_out, 6, [36, 3])\n",
    "    conv2_normalized = tf.layers.batch_normalization(conv2, training = training_flag)\n",
    "    conv2_out = tf.nn.relu(conv2_normalized)\n",
    "    conv3 = tf.layers.conv2d(conv2_out, 10, [16, 2])\n",
    "    conv3_normalized = tf.layers.batch_normalization(conv3, training = training_flag)\n",
    "    conv3_out = tf.nn.relu(conv3_normalized)\n",
    "    flat = tf.layers.flatten(conv3)\n",
    "    output = tf.layers.dense(flat, 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "CwzRJzn3M3cF",
    "outputId": "05a03345-1964-4c4a-aa50-a3f6f1b5216b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 03:06:51.970146 140262493333376 deprecation.py:323] From <ipython-input-49-6e612d8da312>:4: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"cnn\"):\n",
    "    X0 = tf.layers.flatten(features)\n",
    "    X1 = tf.layers.dense(X0, 5000, activation = None)\n",
    "    X2 = tf.layers.batch_normalization(X1, training = training_flag)\n",
    "    X3 = tf.nn.relu(X2)\n",
    "    X4 = tf.layers.dropout(X3, rate=0.1)\n",
    "    X5 = tf.layers.dense(X4, 5000, activation = None)\n",
    "    X6 = tf.layers.batch_normalization(X5, training = training_flag)\n",
    "    X7 = tf.nn.relu(X6)\n",
    "    X8 = tf.layers.dropout(X7, rate=0.1)\n",
    "    X9 = tf.layers.dense(X8, 2500, activation = None)\n",
    "    X10 = tf.layers.batch_normalization(X9, training = training_flag)\n",
    "    X11 = tf.nn.relu(X10)\n",
    "    X12 = tf.layers.dropout(X11, rate=0.1)\n",
    "    X13 = tf.layers.dense(X12, 2500, activation = None)\n",
    "    X14 = tf.layers.batch_normalization(X13, training = training_flag)\n",
    "    X15 = tf.nn.relu(X14)\n",
    "    X16 = tf.layers.dropout(X15, rate=0.1)\n",
    "    X17 = tf.layers.dense(X16, 1200, activation = None)\n",
    "    X18 = tf.layers.batch_normalization(X17, training = training_flag)\n",
    "    X19 = tf.nn.relu(X18)\n",
    "    X20 = tf.layers.dropout(X19, rate=0.1)\n",
    "    X21 = tf.layers.dense(X20, 600, activation = None)\n",
    "    X22 = tf.layers.batch_normalization(X21, training = training_flag)\n",
    "    X23 = tf.nn.relu(X22)\n",
    "    X24 = tf.layers.dropout(X23, rate=0.1)\n",
    "    X25 = tf.layers.dense(X24, 300, activation = None)\n",
    "    X26 = tf.layers.batch_normalization(X25, training = training_flag)\n",
    "    X27 = tf.nn.relu(X26)\n",
    "    X28 = tf.layers.dropout(X27, rate=0.1)\n",
    "    output = tf.layers.dense(X28, 135, activation = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ed1pw925xceQ"
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    l2_loss = tf.losses.mean_squared_error(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5hpxRwFxcbp"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    training_op = tf.train.AdamOptimizer().minimize(l2_loss)\n",
    "    #training_op = optimizer.minimize(l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EzEiczfKxcZP"
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"estimated_MAE\"):\n",
    "    MAE_hat = tf.math.reduce_mean(tf.metrics.mean_absolute_error(labels, output))\n",
    "    log_MAE_hat = tf.math.log(MAE_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNVvdMZHxcWr"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9sLGkeaxcUH"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 65000\n",
    "n_batches = 65000 // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WcdjqPMaxcRw",
    "outputId": "d6171bb7-1cc3-49b3-d45d-785044f1dbb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Iter: 0, Loss: 597.7324, Train MAE hat: 1.3671\n",
      "Iter: 1, Loss: 590.1426, Train MAE hat: 2.0576\n",
      "Iter: 2, Loss: 585.4899, Train MAE hat: 2.0538\n",
      "Iter: 3, Loss: 581.7490, Train MAE hat: 2.0517\n",
      "Iter: 4, Loss: 578.4570, Train MAE hat: 2.0499\n",
      "Iter: 5, Loss: 575.3834, Train MAE hat: 2.0480\n",
      "Iter: 6, Loss: 572.6252, Train MAE hat: 2.0462\n",
      "Iter: 7, Loss: 570.0953, Train MAE hat: 2.0446\n",
      "Iter: 8, Loss: 567.7588, Train MAE hat: 2.0430\n",
      "Iter: 9, Loss: 565.4351, Train MAE hat: 2.0416\n",
      "Iter: 10, Loss: 563.1976, Train MAE hat: 2.0404\n",
      "Iter: 11, Loss: 560.8977, Train MAE hat: 2.0392\n",
      "Iter: 12, Loss: 558.6147, Train MAE hat: 2.0381\n",
      "Iter: 13, Loss: 556.3582, Train MAE hat: 2.0372\n",
      "Iter: 14, Loss: 554.1417, Train MAE hat: 2.0363\n",
      "Iter: 15, Loss: 552.0281, Train MAE hat: 2.0356\n",
      "Iter: 16, Loss: 549.8821, Train MAE hat: 2.0349\n",
      "Iter: 17, Loss: 547.8173, Train MAE hat: 2.0344\n",
      "Iter: 18, Loss: 545.7922, Train MAE hat: 2.0339\n",
      "Iter: 19, Loss: 543.8729, Train MAE hat: 2.0336\n",
      "Iter: 20, Loss: 541.9485, Train MAE hat: 2.0333\n",
      "Iter: 21, Loss: 539.8600, Train MAE hat: 2.0331\n",
      "Iter: 22, Loss: 538.0998, Train MAE hat: 2.0330\n",
      "Iter: 23, Loss: 536.4187, Train MAE hat: 2.0329\n",
      "Iter: 24, Loss: 534.3543, Train MAE hat: 2.0329\n",
      "Iter: 25, Loss: 532.5137, Train MAE hat: 2.0330\n",
      "Iter: 26, Loss: 530.6934, Train MAE hat: 2.0331\n",
      "Iter: 27, Loss: 528.8840, Train MAE hat: 2.0333\n",
      "Iter: 28, Loss: 527.1405, Train MAE hat: 2.0335\n",
      "Iter: 29, Loss: 525.3777, Train MAE hat: 2.0337\n",
      "Iter: 30, Loss: 523.6825, Train MAE hat: 2.0340\n",
      "Iter: 31, Loss: 521.9902, Train MAE hat: 2.0343\n",
      "Iter: 32, Loss: 520.3575, Train MAE hat: 2.0347\n",
      "Iter: 33, Loss: 518.7416, Train MAE hat: 2.0351\n",
      "Iter: 34, Loss: 517.2888, Train MAE hat: 2.0355\n",
      "Iter: 35, Loss: 515.6973, Train MAE hat: 2.0360\n",
      "Iter: 36, Loss: 514.1685, Train MAE hat: 2.0365\n",
      "Iter: 37, Loss: 512.7759, Train MAE hat: 2.0370\n",
      "Iter: 38, Loss: 511.2026, Train MAE hat: 2.0376\n",
      "Iter: 39, Loss: 509.6192, Train MAE hat: 2.0381\n",
      "Iter: 40, Loss: 508.1172, Train MAE hat: 2.0387\n",
      "Iter: 41, Loss: 506.6491, Train MAE hat: 2.0393\n",
      "Iter: 42, Loss: 505.1090, Train MAE hat: 2.0400\n",
      "Iter: 43, Loss: 503.6865, Train MAE hat: 2.0406\n",
      "Iter: 44, Loss: 502.2216, Train MAE hat: 2.0413\n",
      "Iter: 45, Loss: 500.8233, Train MAE hat: 2.0419\n",
      "Iter: 46, Loss: 499.4123, Train MAE hat: 2.0426\n",
      "Iter: 47, Loss: 498.0515, Train MAE hat: 2.0433\n",
      "Iter: 48, Loss: 496.7602, Train MAE hat: 2.0440\n",
      "Iter: 49, Loss: 495.7299, Train MAE hat: 2.0447\n",
      "Iter: 50, Loss: 495.1069, Train MAE hat: 2.0455\n",
      "Iter: 51, Loss: 493.4609, Train MAE hat: 2.0462\n",
      "Iter: 52, Loss: 492.0977, Train MAE hat: 2.0470\n",
      "Iter: 53, Loss: 490.6162, Train MAE hat: 2.0477\n",
      "Iter: 54, Loss: 489.3228, Train MAE hat: 2.0484\n",
      "Iter: 55, Loss: 488.0275, Train MAE hat: 2.0492\n",
      "Iter: 56, Loss: 486.6497, Train MAE hat: 2.0499\n",
      "Iter: 57, Loss: 485.4197, Train MAE hat: 2.0507\n",
      "Iter: 58, Loss: 484.1185, Train MAE hat: 2.0514\n",
      "Iter: 59, Loss: 482.8238, Train MAE hat: 2.0522\n",
      "Iter: 60, Loss: 481.5991, Train MAE hat: 2.0529\n",
      "Iter: 61, Loss: 480.3098, Train MAE hat: 2.0537\n",
      "Iter: 62, Loss: 479.0924, Train MAE hat: 2.0544\n",
      "Iter: 63, Loss: 477.8104, Train MAE hat: 2.0551\n",
      "Iter: 64, Loss: 476.6277, Train MAE hat: 2.0559\n",
      "Iter: 65, Loss: 475.3844, Train MAE hat: 2.0566\n",
      "Iter: 66, Loss: 474.2191, Train MAE hat: 2.0573\n",
      "Iter: 67, Loss: 472.9967, Train MAE hat: 2.0580\n",
      "Iter: 68, Loss: 471.9416, Train MAE hat: 2.0588\n",
      "Iter: 69, Loss: 470.9203, Train MAE hat: 2.0595\n",
      "Iter: 70, Loss: 469.9407, Train MAE hat: 2.0602\n",
      "Iter: 71, Loss: 468.5185, Train MAE hat: 2.0609\n",
      "Iter: 72, Loss: 467.3443, Train MAE hat: 2.0616\n",
      "Iter: 73, Loss: 466.0855, Train MAE hat: 2.0623\n",
      "Iter: 74, Loss: 464.9005, Train MAE hat: 2.0630\n",
      "Iter: 75, Loss: 463.6807, Train MAE hat: 2.0636\n",
      "Iter: 76, Loss: 462.5129, Train MAE hat: 2.0643\n",
      "Iter: 77, Loss: 461.3214, Train MAE hat: 2.0650\n",
      "Iter: 78, Loss: 460.1516, Train MAE hat: 2.0656\n",
      "Iter: 79, Loss: 458.9847, Train MAE hat: 2.0663\n",
      "Iter: 80, Loss: 457.8166, Train MAE hat: 2.0669\n",
      "Iter: 81, Loss: 456.7004, Train MAE hat: 2.0675\n",
      "Iter: 82, Loss: 455.5651, Train MAE hat: 2.0681\n",
      "Iter: 83, Loss: 454.5213, Train MAE hat: 2.0687\n",
      "Iter: 84, Loss: 453.4833, Train MAE hat: 2.0693\n",
      "Iter: 85, Loss: 452.5960, Train MAE hat: 2.0699\n",
      "Iter: 86, Loss: 451.9297, Train MAE hat: 2.0705\n",
      "Iter: 87, Loss: 450.4614, Train MAE hat: 2.0711\n",
      "Iter: 88, Loss: 449.4572, Train MAE hat: 2.0717\n",
      "Iter: 89, Loss: 448.2382, Train MAE hat: 2.0722\n",
      "Iter: 90, Loss: 447.0601, Train MAE hat: 2.0728\n",
      "Iter: 91, Loss: 445.8723, Train MAE hat: 2.0733\n",
      "Iter: 92, Loss: 444.7575, Train MAE hat: 2.0738\n",
      "Iter: 93, Loss: 443.5345, Train MAE hat: 2.0743\n",
      "Iter: 94, Loss: 442.3270, Train MAE hat: 2.0748\n",
      "Iter: 95, Loss: 441.1975, Train MAE hat: 2.0753\n",
      "Iter: 96, Loss: 440.0142, Train MAE hat: 2.0758\n",
      "Iter: 97, Loss: 438.9554, Train MAE hat: 2.0763\n",
      "Iter: 98, Loss: 437.7577, Train MAE hat: 2.0768\n",
      "Iter: 99, Loss: 436.6702, Train MAE hat: 2.0772\n",
      "Iter: 100, Loss: 435.6359, Train MAE hat: 2.0777\n",
      "Iter: 101, Loss: 434.7572, Train MAE hat: 2.0781\n",
      "Iter: 102, Loss: 433.4178, Train MAE hat: 2.0786\n",
      "Iter: 103, Loss: 432.2879, Train MAE hat: 2.0790\n",
      "Iter: 104, Loss: 431.1677, Train MAE hat: 2.0794\n",
      "Iter: 105, Loss: 430.0272, Train MAE hat: 2.0798\n",
      "Iter: 106, Loss: 428.9227, Train MAE hat: 2.0802\n",
      "Iter: 107, Loss: 427.7778, Train MAE hat: 2.0806\n",
      "Iter: 108, Loss: 426.6350, Train MAE hat: 2.0809\n",
      "Iter: 109, Loss: 425.5237, Train MAE hat: 2.0813\n",
      "Iter: 110, Loss: 424.4810, Train MAE hat: 2.0816\n",
      "Iter: 111, Loss: 423.4165, Train MAE hat: 2.0820\n",
      "Iter: 112, Loss: 422.3482, Train MAE hat: 2.0823\n",
      "Iter: 113, Loss: 421.3570, Train MAE hat: 2.0826\n",
      "Iter: 114, Loss: 420.3700, Train MAE hat: 2.0830\n",
      "Iter: 115, Loss: 419.5742, Train MAE hat: 2.0833\n",
      "Iter: 116, Loss: 418.2331, Train MAE hat: 2.0836\n",
      "Iter: 117, Loss: 417.4436, Train MAE hat: 2.0839\n",
      "Iter: 118, Loss: 416.0359, Train MAE hat: 2.0841\n",
      "Iter: 119, Loss: 414.9341, Train MAE hat: 2.0844\n",
      "Iter: 120, Loss: 413.7475, Train MAE hat: 2.0847\n",
      "Iter: 121, Loss: 412.7535, Train MAE hat: 2.0849\n",
      "Iter: 122, Loss: 411.5609, Train MAE hat: 2.0852\n",
      "Iter: 123, Loss: 410.2798, Train MAE hat: 2.0854\n",
      "Iter: 124, Loss: 409.1080, Train MAE hat: 2.0856\n",
      "Iter: 125, Loss: 407.9445, Train MAE hat: 2.0859\n",
      "Iter: 126, Loss: 406.7935, Train MAE hat: 2.0861\n",
      "Iter: 127, Loss: 405.6071, Train MAE hat: 2.0863\n",
      "Iter: 128, Loss: 404.4745, Train MAE hat: 2.0865\n",
      "Iter: 129, Loss: 403.3226, Train MAE hat: 2.0866\n",
      "Iter: 130, Loss: 402.1847, Train MAE hat: 2.0868\n",
      "Iter: 131, Loss: 401.0462, Train MAE hat: 2.0870\n",
      "Iter: 132, Loss: 399.9569, Train MAE hat: 2.0871\n",
      "Iter: 133, Loss: 398.8977, Train MAE hat: 2.0873\n",
      "Iter: 134, Loss: 397.9724, Train MAE hat: 2.0874\n",
      "Iter: 135, Loss: 397.2071, Train MAE hat: 2.0876\n",
      "Iter: 136, Loss: 396.5646, Train MAE hat: 2.0877\n",
      "Iter: 137, Loss: 395.2930, Train MAE hat: 2.0878\n",
      "Iter: 138, Loss: 394.1623, Train MAE hat: 2.0880\n",
      "Iter: 139, Loss: 393.1106, Train MAE hat: 2.0881\n",
      "Iter: 140, Loss: 391.7124, Train MAE hat: 2.0882\n",
      "Iter: 141, Loss: 390.6693, Train MAE hat: 2.0883\n",
      "Iter: 142, Loss: 389.4752, Train MAE hat: 2.0883\n",
      "Iter: 143, Loss: 388.2720, Train MAE hat: 2.0884\n",
      "Iter: 144, Loss: 387.0643, Train MAE hat: 2.0885\n",
      "Iter: 145, Loss: 385.9319, Train MAE hat: 2.0886\n",
      "Iter: 146, Loss: 384.7733, Train MAE hat: 2.0886\n",
      "Iter: 147, Loss: 383.6466, Train MAE hat: 2.0887\n",
      "Iter: 148, Loss: 382.5522, Train MAE hat: 2.0887\n",
      "Iter: 149, Loss: 381.4236, Train MAE hat: 2.0887\n",
      "Iter: 150, Loss: 380.3823, Train MAE hat: 2.0888\n",
      "Iter: 151, Loss: 379.3586, Train MAE hat: 2.0888\n",
      "Iter: 152, Loss: 378.3394, Train MAE hat: 2.0888\n",
      "Iter: 153, Loss: 377.4074, Train MAE hat: 2.0888\n",
      "Iter: 154, Loss: 376.2917, Train MAE hat: 2.0888\n",
      "Iter: 155, Loss: 375.1366, Train MAE hat: 2.0888\n",
      "Iter: 156, Loss: 374.1557, Train MAE hat: 2.0888\n",
      "Iter: 157, Loss: 373.0954, Train MAE hat: 2.0888\n",
      "Iter: 158, Loss: 372.0399, Train MAE hat: 2.0888\n",
      "Iter: 159, Loss: 370.8246, Train MAE hat: 2.0888\n",
      "Iter: 160, Loss: 369.8299, Train MAE hat: 2.0887\n",
      "Iter: 161, Loss: 368.5513, Train MAE hat: 2.0887\n",
      "Iter: 162, Loss: 367.5173, Train MAE hat: 2.0887\n",
      "Iter: 163, Loss: 366.3159, Train MAE hat: 2.0886\n",
      "Iter: 164, Loss: 365.2618, Train MAE hat: 2.0886\n",
      "Iter: 165, Loss: 364.0223, Train MAE hat: 2.0885\n",
      "Iter: 166, Loss: 362.9108, Train MAE hat: 2.0884\n",
      "Iter: 167, Loss: 361.7932, Train MAE hat: 2.0884\n",
      "Iter: 168, Loss: 360.7415, Train MAE hat: 2.0883\n",
      "Iter: 169, Loss: 359.6648, Train MAE hat: 2.0882\n",
      "Iter: 170, Loss: 358.6445, Train MAE hat: 2.0881\n",
      "Iter: 171, Loss: 357.5504, Train MAE hat: 2.0880\n",
      "Iter: 172, Loss: 356.4243, Train MAE hat: 2.0879\n",
      "Iter: 173, Loss: 355.2663, Train MAE hat: 2.0878\n",
      "Iter: 174, Loss: 354.2379, Train MAE hat: 2.0877\n",
      "Iter: 175, Loss: 353.1686, Train MAE hat: 2.0876\n",
      "Iter: 176, Loss: 352.0236, Train MAE hat: 2.0875\n",
      "Iter: 177, Loss: 350.8622, Train MAE hat: 2.0873\n",
      "Iter: 178, Loss: 349.8828, Train MAE hat: 2.0872\n",
      "Iter: 179, Loss: 349.0627, Train MAE hat: 2.0871\n",
      "Iter: 180, Loss: 348.4840, Train MAE hat: 2.0869\n",
      "Iter: 181, Loss: 347.7940, Train MAE hat: 2.0868\n",
      "Iter: 182, Loss: 346.1818, Train MAE hat: 2.0867\n",
      "Iter: 183, Loss: 345.1847, Train MAE hat: 2.0865\n",
      "Iter: 184, Loss: 344.2790, Train MAE hat: 2.0864\n",
      "Iter: 185, Loss: 343.0052, Train MAE hat: 2.0862\n",
      "Iter: 186, Loss: 342.0552, Train MAE hat: 2.0860\n",
      "Iter: 187, Loss: 340.7705, Train MAE hat: 2.0859\n",
      "Iter: 188, Loss: 339.7614, Train MAE hat: 2.0857\n",
      "Iter: 189, Loss: 338.5305, Train MAE hat: 2.0855\n",
      "Iter: 190, Loss: 337.4250, Train MAE hat: 2.0853\n",
      "Iter: 191, Loss: 336.3701, Train MAE hat: 2.0852\n",
      "Iter: 192, Loss: 335.3004, Train MAE hat: 2.0850\n",
      "Iter: 193, Loss: 334.2265, Train MAE hat: 2.0848\n",
      "Iter: 194, Loss: 333.1144, Train MAE hat: 2.0846\n",
      "Iter: 195, Loss: 332.0418, Train MAE hat: 2.0844\n",
      "Iter: 196, Loss: 331.0054, Train MAE hat: 2.0842\n",
      "Iter: 197, Loss: 329.9772, Train MAE hat: 2.0839\n",
      "Iter: 198, Loss: 328.9640, Train MAE hat: 2.0837\n",
      "Iter: 199, Loss: 327.8289, Train MAE hat: 2.0835\n",
      "Test Loss: 334.8526, Test MAE hat: 2.0834\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # initialise iterator with train data\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_train, y: y_train, batch_size: BATCH_SIZE})\n",
    "    print('Training...')\n",
    "    for i in range(EPOCHS):\n",
    "        tot_loss = 0\n",
    "        for _ in range(n_batches):\n",
    "            _, loss_value, tr_lmae = sess.run([training_op, l2_loss, log_MAE_hat])\n",
    "            tot_loss += loss_value\n",
    "        print(\"Iter: {}, Loss: {:.4f}, Train MAE hat: {:.4f}\".format(i, tot_loss / n_batches, tr_lmae))\n",
    "    # initialise iterator with test data\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_val, y: y_val, batch_size: X_val.shape[0]})\n",
    "    t_loss, l_mae = sess.run([l2_loss, log_MAE_hat])\n",
    "    print('Test Loss: {:.4f}, Test MAE hat: {:.4f}'.format(t_loss, l_mae))\n",
    "    save_path = saver.save(sess, \"./my_model_final5.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ld4ozf-yiNy2",
    "outputId": "8e5a9966-4a02-4ee7-fb6b-a316b28b8ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Test Loss: 18.2971, Test MAE hat: -0.0453\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./my_model_final3.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_val, y: y_val, batch_size: X_val.shape[0]})\n",
    "    out, t_loss, l_mae = sess.run([output, l2_loss, log_MAE_hat])\n",
    "    print('Test Loss: {:.4f}, Test MAE hat: {:.4f}'.format(t_loss, l_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSjapbyxxAI2"
   },
   "outputs": [],
   "source": [
    "def actual_mae(X_val, y_val, out):\n",
    "    abs_err = np.absolute(y_val - out)\n",
    "    summe = np.zeros(8)\n",
    "    for i in range(8):\n",
    "        new_X_val = X_val[:,:,i,0]\n",
    "        mult = abs_err * new_X_val\n",
    "        summe[i] = np.sum(mult)/np.sum(new_X_val)\n",
    "    summe = np.log(summe)\n",
    "    MAE = np.sum(summe)/8.0\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W16OWEItiAXB",
    "outputId": "46ce6b8f-0b5f-4b41-b498-36900205af3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3304788416424806\n"
     ]
    }
   ],
   "source": [
    "mae = actual_mae(X_val, y_val, out)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LTSzaIlDiFX5",
    "outputId": "ebecbc80-7630-482f-d012-cb3fe2458e31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 03:37:40.269182 140262493333376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Training...\n",
      "Iter: 0, Loss: 326.8297, Train MAE hat: 1.3418\n",
      "Iter: 1, Loss: 325.8465, Train MAE hat: 2.0357\n",
      "Iter: 2, Loss: 324.9893, Train MAE hat: 2.0358\n",
      "Iter: 3, Loss: 324.0090, Train MAE hat: 2.0352\n",
      "Iter: 4, Loss: 323.0121, Train MAE hat: 2.0348\n",
      "Iter: 5, Loss: 321.9562, Train MAE hat: 2.0341\n",
      "Iter: 6, Loss: 321.1499, Train MAE hat: 2.0336\n",
      "Iter: 7, Loss: 320.1131, Train MAE hat: 2.0330\n",
      "Iter: 8, Loss: 319.0588, Train MAE hat: 2.0323\n",
      "Iter: 9, Loss: 318.0389, Train MAE hat: 2.0318\n",
      "Iter: 10, Loss: 317.1223, Train MAE hat: 2.0312\n",
      "Iter: 11, Loss: 316.1216, Train MAE hat: 2.0305\n",
      "Iter: 12, Loss: 315.2513, Train MAE hat: 2.0300\n",
      "Iter: 13, Loss: 314.1132, Train MAE hat: 2.0294\n",
      "Iter: 14, Loss: 313.0199, Train MAE hat: 2.0287\n",
      "Iter: 15, Loss: 312.0131, Train MAE hat: 2.0281\n",
      "Iter: 16, Loss: 311.0743, Train MAE hat: 2.0275\n",
      "Iter: 17, Loss: 310.1294, Train MAE hat: 2.0268\n",
      "Iter: 18, Loss: 308.9428, Train MAE hat: 2.0262\n",
      "Iter: 19, Loss: 307.8678, Train MAE hat: 2.0255\n",
      "Iter: 20, Loss: 306.7870, Train MAE hat: 2.0249\n",
      "Iter: 21, Loss: 305.7679, Train MAE hat: 2.0242\n",
      "Iter: 22, Loss: 304.5576, Train MAE hat: 2.0236\n",
      "Iter: 23, Loss: 303.5653, Train MAE hat: 2.0229\n",
      "Iter: 24, Loss: 302.5261, Train MAE hat: 2.0222\n",
      "Iter: 25, Loss: 301.4784, Train MAE hat: 2.0215\n",
      "Iter: 26, Loss: 300.4415, Train MAE hat: 2.0208\n",
      "Iter: 27, Loss: 299.4194, Train MAE hat: 2.0202\n",
      "Iter: 28, Loss: 298.3951, Train MAE hat: 2.0195\n",
      "Iter: 29, Loss: 297.4739, Train MAE hat: 2.0188\n",
      "Iter: 30, Loss: 296.5622, Train MAE hat: 2.0181\n",
      "Iter: 31, Loss: 295.8243, Train MAE hat: 2.0175\n",
      "Iter: 32, Loss: 295.0952, Train MAE hat: 2.0168\n",
      "Iter: 33, Loss: 294.2355, Train MAE hat: 2.0161\n",
      "Iter: 34, Loss: 293.3246, Train MAE hat: 2.0155\n",
      "Iter: 35, Loss: 292.5151, Train MAE hat: 2.0148\n",
      "Iter: 36, Loss: 291.3847, Train MAE hat: 2.0142\n",
      "Iter: 37, Loss: 290.5161, Train MAE hat: 2.0135\n",
      "Iter: 38, Loss: 289.4756, Train MAE hat: 2.0128\n",
      "Iter: 39, Loss: 288.6293, Train MAE hat: 2.0122\n",
      "Iter: 40, Loss: 287.7328, Train MAE hat: 2.0115\n",
      "Iter: 41, Loss: 286.6292, Train MAE hat: 2.0109\n",
      "Iter: 42, Loss: 285.7693, Train MAE hat: 2.0102\n",
      "Iter: 43, Loss: 284.8394, Train MAE hat: 2.0095\n",
      "Iter: 44, Loss: 283.9176, Train MAE hat: 2.0089\n",
      "Iter: 45, Loss: 282.9474, Train MAE hat: 2.0082\n",
      "Iter: 46, Loss: 281.9126, Train MAE hat: 2.0075\n",
      "Iter: 47, Loss: 280.9969, Train MAE hat: 2.0069\n",
      "Iter: 48, Loss: 279.9992, Train MAE hat: 2.0062\n",
      "Iter: 49, Loss: 279.1230, Train MAE hat: 2.0055\n",
      "Iter: 50, Loss: 278.1547, Train MAE hat: 2.0048\n",
      "Iter: 51, Loss: 277.1245, Train MAE hat: 2.0042\n",
      "Iter: 52, Loss: 276.1621, Train MAE hat: 2.0035\n",
      "Iter: 53, Loss: 275.1809, Train MAE hat: 2.0028\n",
      "Iter: 54, Loss: 274.2856, Train MAE hat: 2.0021\n",
      "Iter: 55, Loss: 273.3432, Train MAE hat: 2.0014\n",
      "Iter: 56, Loss: 272.5844, Train MAE hat: 2.0007\n",
      "Iter: 57, Loss: 271.6552, Train MAE hat: 2.0000\n",
      "Iter: 58, Loss: 270.8668, Train MAE hat: 1.9994\n",
      "Iter: 59, Loss: 269.9014, Train MAE hat: 1.9987\n",
      "Iter: 60, Loss: 269.0679, Train MAE hat: 1.9980\n",
      "Iter: 61, Loss: 268.0866, Train MAE hat: 1.9973\n",
      "Iter: 62, Loss: 267.2022, Train MAE hat: 1.9966\n",
      "Iter: 63, Loss: 266.2929, Train MAE hat: 1.9959\n",
      "Iter: 64, Loss: 265.2754, Train MAE hat: 1.9952\n",
      "Iter: 65, Loss: 264.4956, Train MAE hat: 1.9946\n",
      "Iter: 66, Loss: 263.5901, Train MAE hat: 1.9939\n",
      "Iter: 67, Loss: 262.6331, Train MAE hat: 1.9932\n",
      "Iter: 68, Loss: 261.7375, Train MAE hat: 1.9925\n",
      "Iter: 69, Loss: 260.8192, Train MAE hat: 1.9918\n",
      "Iter: 70, Loss: 260.1179, Train MAE hat: 1.9911\n",
      "Iter: 71, Loss: 259.4195, Train MAE hat: 1.9904\n",
      "Iter: 72, Loss: 258.5881, Train MAE hat: 1.9897\n",
      "Iter: 73, Loss: 257.6978, Train MAE hat: 1.9890\n",
      "Iter: 74, Loss: 256.7058, Train MAE hat: 1.9883\n",
      "Iter: 75, Loss: 256.0591, Train MAE hat: 1.9876\n",
      "Iter: 76, Loss: 255.1276, Train MAE hat: 1.9869\n",
      "Iter: 77, Loss: 254.2341, Train MAE hat: 1.9862\n",
      "Iter: 78, Loss: 253.3682, Train MAE hat: 1.9856\n",
      "Iter: 79, Loss: 252.4476, Train MAE hat: 1.9849\n",
      "Iter: 80, Loss: 251.6420, Train MAE hat: 1.9842\n",
      "Iter: 81, Loss: 250.6747, Train MAE hat: 1.9835\n",
      "Iter: 82, Loss: 249.7329, Train MAE hat: 1.9828\n",
      "Iter: 83, Loss: 248.8851, Train MAE hat: 1.9821\n",
      "Iter: 84, Loss: 248.0212, Train MAE hat: 1.9814\n",
      "Iter: 85, Loss: 247.2003, Train MAE hat: 1.9807\n",
      "Iter: 86, Loss: 246.3938, Train MAE hat: 1.9800\n",
      "Iter: 87, Loss: 245.4720, Train MAE hat: 1.9793\n",
      "Iter: 88, Loss: 244.5621, Train MAE hat: 1.9785\n",
      "Iter: 89, Loss: 243.7557, Train MAE hat: 1.9778\n",
      "Iter: 90, Loss: 242.8524, Train MAE hat: 1.9771\n",
      "Iter: 91, Loss: 242.0464, Train MAE hat: 1.9764\n",
      "Iter: 92, Loss: 241.3249, Train MAE hat: 1.9757\n",
      "Iter: 93, Loss: 240.5817, Train MAE hat: 1.9750\n",
      "Iter: 94, Loss: 239.8842, Train MAE hat: 1.9743\n",
      "Iter: 95, Loss: 239.0271, Train MAE hat: 1.9736\n",
      "Iter: 96, Loss: 238.1705, Train MAE hat: 1.9729\n",
      "Iter: 97, Loss: 237.5384, Train MAE hat: 1.9722\n",
      "Iter: 98, Loss: 236.8136, Train MAE hat: 1.9714\n",
      "Iter: 99, Loss: 236.1712, Train MAE hat: 1.9707\n",
      "Iter: 100, Loss: 235.4269, Train MAE hat: 1.9700\n",
      "Iter: 101, Loss: 234.7052, Train MAE hat: 1.9693\n",
      "Iter: 102, Loss: 233.6486, Train MAE hat: 1.9686\n",
      "Iter: 103, Loss: 232.8322, Train MAE hat: 1.9679\n",
      "Iter: 104, Loss: 231.9268, Train MAE hat: 1.9672\n",
      "Iter: 105, Loss: 231.0381, Train MAE hat: 1.9665\n",
      "Iter: 106, Loss: 230.1875, Train MAE hat: 1.9658\n",
      "Iter: 107, Loss: 229.3531, Train MAE hat: 1.9651\n",
      "Iter: 108, Loss: 228.4565, Train MAE hat: 1.9644\n",
      "Iter: 109, Loss: 227.6493, Train MAE hat: 1.9636\n",
      "Iter: 110, Loss: 226.7845, Train MAE hat: 1.9629\n",
      "Iter: 111, Loss: 226.0176, Train MAE hat: 1.9622\n",
      "Iter: 112, Loss: 225.3205, Train MAE hat: 1.9615\n",
      "Iter: 113, Loss: 224.6577, Train MAE hat: 1.9608\n",
      "Iter: 114, Loss: 223.8667, Train MAE hat: 1.9600\n",
      "Iter: 115, Loss: 223.0759, Train MAE hat: 1.9593\n",
      "Iter: 116, Loss: 222.3487, Train MAE hat: 1.9586\n",
      "Iter: 117, Loss: 221.7146, Train MAE hat: 1.9579\n",
      "Iter: 118, Loss: 221.1411, Train MAE hat: 1.9572\n",
      "Iter: 119, Loss: 220.2596, Train MAE hat: 1.9564\n",
      "Iter: 120, Loss: 219.6401, Train MAE hat: 1.9557\n",
      "Iter: 121, Loss: 219.1234, Train MAE hat: 1.9550\n",
      "Iter: 122, Loss: 218.1881, Train MAE hat: 1.9543\n",
      "Iter: 123, Loss: 217.4338, Train MAE hat: 1.9536\n",
      "Iter: 124, Loss: 216.5484, Train MAE hat: 1.9529\n",
      "Iter: 125, Loss: 215.7648, Train MAE hat: 1.9521\n",
      "Iter: 126, Loss: 215.0294, Train MAE hat: 1.9514\n",
      "Iter: 127, Loss: 214.0606, Train MAE hat: 1.9507\n",
      "Iter: 128, Loss: 213.3000, Train MAE hat: 1.9500\n",
      "Iter: 129, Loss: 212.4899, Train MAE hat: 1.9493\n",
      "Iter: 130, Loss: 211.7179, Train MAE hat: 1.9485\n",
      "Iter: 131, Loss: 210.9492, Train MAE hat: 1.9478\n",
      "Iter: 132, Loss: 210.1637, Train MAE hat: 1.9471\n",
      "Iter: 133, Loss: 209.4936, Train MAE hat: 1.9463\n",
      "Iter: 134, Loss: 208.8499, Train MAE hat: 1.9456\n",
      "Iter: 135, Loss: 208.2243, Train MAE hat: 1.9449\n",
      "Iter: 136, Loss: 207.4660, Train MAE hat: 1.9442\n",
      "Iter: 137, Loss: 206.6528, Train MAE hat: 1.9434\n",
      "Iter: 138, Loss: 206.0235, Train MAE hat: 1.9427\n",
      "Iter: 139, Loss: 205.4480, Train MAE hat: 1.9420\n",
      "Iter: 140, Loss: 204.8674, Train MAE hat: 1.9412\n",
      "Iter: 141, Loss: 204.1124, Train MAE hat: 1.9405\n",
      "Iter: 142, Loss: 203.5771, Train MAE hat: 1.9398\n",
      "Iter: 143, Loss: 202.9268, Train MAE hat: 1.9391\n",
      "Iter: 144, Loss: 202.2655, Train MAE hat: 1.9384\n",
      "Iter: 145, Loss: 201.5232, Train MAE hat: 1.9376\n",
      "Iter: 146, Loss: 200.8904, Train MAE hat: 1.9369\n",
      "Iter: 147, Loss: 200.0816, Train MAE hat: 1.9362\n",
      "Iter: 148, Loss: 199.4423, Train MAE hat: 1.9355\n",
      "Iter: 149, Loss: 198.6079, Train MAE hat: 1.9348\n",
      "Iter: 150, Loss: 197.9882, Train MAE hat: 1.9340\n",
      "Iter: 151, Loss: 197.0664, Train MAE hat: 1.9333\n",
      "Iter: 152, Loss: 196.3541, Train MAE hat: 1.9326\n",
      "Iter: 153, Loss: 195.4124, Train MAE hat: 1.9319\n",
      "Iter: 154, Loss: 194.7356, Train MAE hat: 1.9311\n",
      "Iter: 155, Loss: 193.9948, Train MAE hat: 1.9304\n",
      "Iter: 156, Loss: 193.3295, Train MAE hat: 1.9297\n",
      "Iter: 157, Loss: 192.6380, Train MAE hat: 1.9289\n",
      "Iter: 158, Loss: 192.0774, Train MAE hat: 1.9282\n",
      "Iter: 159, Loss: 191.5130, Train MAE hat: 1.9275\n",
      "Iter: 160, Loss: 191.0184, Train MAE hat: 1.9267\n",
      "Iter: 161, Loss: 190.2038, Train MAE hat: 1.9260\n",
      "Iter: 162, Loss: 189.4662, Train MAE hat: 1.9253\n",
      "Iter: 163, Loss: 188.8403, Train MAE hat: 1.9245\n",
      "Iter: 164, Loss: 188.0856, Train MAE hat: 1.9238\n",
      "Iter: 165, Loss: 187.3556, Train MAE hat: 1.9231\n",
      "Iter: 166, Loss: 186.6807, Train MAE hat: 1.9223\n",
      "Iter: 167, Loss: 185.9133, Train MAE hat: 1.9216\n",
      "Iter: 168, Loss: 185.2294, Train MAE hat: 1.9209\n",
      "Iter: 169, Loss: 184.4815, Train MAE hat: 1.9201\n",
      "Iter: 170, Loss: 183.7060, Train MAE hat: 1.9194\n",
      "Iter: 171, Loss: 183.0158, Train MAE hat: 1.9187\n",
      "Iter: 172, Loss: 182.4246, Train MAE hat: 1.9179\n",
      "Iter: 173, Loss: 181.8126, Train MAE hat: 1.9172\n",
      "Iter: 174, Loss: 181.2438, Train MAE hat: 1.9164\n",
      "Iter: 175, Loss: 180.5350, Train MAE hat: 1.9157\n",
      "Iter: 176, Loss: 179.9203, Train MAE hat: 1.9150\n",
      "Iter: 177, Loss: 179.3795, Train MAE hat: 1.9142\n",
      "Iter: 178, Loss: 178.7181, Train MAE hat: 1.9135\n",
      "Iter: 179, Loss: 178.1386, Train MAE hat: 1.9128\n",
      "Iter: 180, Loss: 177.5432, Train MAE hat: 1.9120\n",
      "Iter: 181, Loss: 176.8986, Train MAE hat: 1.9113\n",
      "Iter: 182, Loss: 176.3076, Train MAE hat: 1.9106\n",
      "Iter: 183, Loss: 175.7889, Train MAE hat: 1.9098\n",
      "Iter: 184, Loss: 175.3478, Train MAE hat: 1.9091\n",
      "Iter: 185, Loss: 174.7915, Train MAE hat: 1.9084\n",
      "Iter: 186, Loss: 174.1555, Train MAE hat: 1.9076\n",
      "Iter: 187, Loss: 173.4481, Train MAE hat: 1.9069\n",
      "Iter: 188, Loss: 172.8840, Train MAE hat: 1.9062\n",
      "Iter: 189, Loss: 172.3364, Train MAE hat: 1.9055\n",
      "Iter: 190, Loss: 171.5472, Train MAE hat: 1.9047\n",
      "Iter: 191, Loss: 170.8446, Train MAE hat: 1.9040\n",
      "Iter: 192, Loss: 170.1304, Train MAE hat: 1.9033\n",
      "Iter: 193, Loss: 169.3757, Train MAE hat: 1.9025\n",
      "Iter: 194, Loss: 168.6699, Train MAE hat: 1.9018\n",
      "Iter: 195, Loss: 167.9960, Train MAE hat: 1.9011\n",
      "Iter: 196, Loss: 167.3526, Train MAE hat: 1.9003\n",
      "Iter: 197, Loss: 166.6104, Train MAE hat: 1.8996\n",
      "Iter: 198, Loss: 166.0032, Train MAE hat: 1.8989\n",
      "Iter: 199, Loss: 165.3491, Train MAE hat: 1.8981\n",
      "Iter: 200, Loss: 164.6952, Train MAE hat: 1.8974\n",
      "Iter: 201, Loss: 164.0257, Train MAE hat: 1.8966\n",
      "Iter: 202, Loss: 163.4022, Train MAE hat: 1.8959\n",
      "Iter: 203, Loss: 162.7889, Train MAE hat: 1.8952\n",
      "Iter: 204, Loss: 162.2358, Train MAE hat: 1.8944\n",
      "Iter: 205, Loss: 161.6641, Train MAE hat: 1.8937\n",
      "Iter: 206, Loss: 161.2622, Train MAE hat: 1.8929\n",
      "Iter: 207, Loss: 160.9043, Train MAE hat: 1.8922\n",
      "Iter: 208, Loss: 160.7075, Train MAE hat: 1.8914\n",
      "Iter: 209, Loss: 160.1116, Train MAE hat: 1.8907\n",
      "Iter: 210, Loss: 159.6550, Train MAE hat: 1.8900\n",
      "Iter: 211, Loss: 159.0707, Train MAE hat: 1.8893\n",
      "Iter: 212, Loss: 158.5679, Train MAE hat: 1.8885\n",
      "Iter: 213, Loss: 157.8520, Train MAE hat: 1.8878\n",
      "Iter: 214, Loss: 157.2171, Train MAE hat: 1.8871\n",
      "Iter: 215, Loss: 156.5420, Train MAE hat: 1.8864\n",
      "Iter: 216, Loss: 155.8771, Train MAE hat: 1.8856\n",
      "Iter: 217, Loss: 155.2438, Train MAE hat: 1.8849\n",
      "Iter: 218, Loss: 154.4975, Train MAE hat: 1.8842\n",
      "Iter: 219, Loss: 153.8337, Train MAE hat: 1.8834\n",
      "Iter: 220, Loss: 153.1429, Train MAE hat: 1.8827\n",
      "Iter: 221, Loss: 152.5074, Train MAE hat: 1.8820\n",
      "Iter: 222, Loss: 151.8026, Train MAE hat: 1.8812\n",
      "Iter: 223, Loss: 151.1747, Train MAE hat: 1.8805\n",
      "Iter: 224, Loss: 150.6201, Train MAE hat: 1.8797\n",
      "Iter: 225, Loss: 150.0528, Train MAE hat: 1.8790\n",
      "Iter: 226, Loss: 149.4581, Train MAE hat: 1.8783\n",
      "Iter: 227, Loss: 148.8801, Train MAE hat: 1.8775\n",
      "Iter: 228, Loss: 148.2999, Train MAE hat: 1.8768\n",
      "Iter: 229, Loss: 147.7576, Train MAE hat: 1.8760\n",
      "Iter: 230, Loss: 147.2151, Train MAE hat: 1.8753\n",
      "Iter: 231, Loss: 146.6885, Train MAE hat: 1.8746\n",
      "Iter: 232, Loss: 146.1122, Train MAE hat: 1.8738\n",
      "Iter: 233, Loss: 145.5353, Train MAE hat: 1.8731\n",
      "Iter: 234, Loss: 145.0312, Train MAE hat: 1.8723\n",
      "Iter: 235, Loss: 144.4553, Train MAE hat: 1.8716\n",
      "Iter: 236, Loss: 143.9050, Train MAE hat: 1.8709\n",
      "Iter: 237, Loss: 143.3188, Train MAE hat: 1.8701\n",
      "Iter: 238, Loss: 142.8636, Train MAE hat: 1.8694\n",
      "Iter: 239, Loss: 142.4200, Train MAE hat: 1.8686\n",
      "Iter: 240, Loss: 141.8877, Train MAE hat: 1.8679\n",
      "Iter: 241, Loss: 141.4444, Train MAE hat: 1.8672\n",
      "Iter: 242, Loss: 141.0584, Train MAE hat: 1.8664\n",
      "Iter: 243, Loss: 140.5971, Train MAE hat: 1.8657\n",
      "Iter: 244, Loss: 140.4132, Train MAE hat: 1.8650\n",
      "Iter: 245, Loss: 139.8360, Train MAE hat: 1.8642\n",
      "Iter: 246, Loss: 139.1377, Train MAE hat: 1.8635\n",
      "Iter: 247, Loss: 138.5090, Train MAE hat: 1.8628\n",
      "Iter: 248, Loss: 137.8561, Train MAE hat: 1.8620\n",
      "Iter: 249, Loss: 137.2902, Train MAE hat: 1.8613\n",
      "Iter: 250, Loss: 136.6200, Train MAE hat: 1.8606\n",
      "Iter: 251, Loss: 136.0648, Train MAE hat: 1.8598\n",
      "Iter: 252, Loss: 135.4340, Train MAE hat: 1.8591\n",
      "Iter: 253, Loss: 134.8445, Train MAE hat: 1.8584\n",
      "Iter: 254, Loss: 134.2528, Train MAE hat: 1.8576\n",
      "Iter: 255, Loss: 133.6291, Train MAE hat: 1.8569\n",
      "Iter: 256, Loss: 133.0183, Train MAE hat: 1.8561\n",
      "Iter: 257, Loss: 132.4148, Train MAE hat: 1.8554\n",
      "Iter: 258, Loss: 131.8288, Train MAE hat: 1.8546\n",
      "Iter: 259, Loss: 131.2590, Train MAE hat: 1.8539\n",
      "Iter: 260, Loss: 130.7813, Train MAE hat: 1.8531\n",
      "Iter: 261, Loss: 130.2317, Train MAE hat: 1.8524\n",
      "Iter: 262, Loss: 129.7053, Train MAE hat: 1.8516\n",
      "Iter: 263, Loss: 129.1244, Train MAE hat: 1.8509\n",
      "Iter: 264, Loss: 128.6025, Train MAE hat: 1.8501\n",
      "Iter: 265, Loss: 128.1174, Train MAE hat: 1.8494\n",
      "Iter: 266, Loss: 127.6688, Train MAE hat: 1.8486\n",
      "Iter: 267, Loss: 127.1619, Train MAE hat: 1.8479\n",
      "Iter: 268, Loss: 126.7058, Train MAE hat: 1.8471\n",
      "Iter: 269, Loss: 126.3443, Train MAE hat: 1.8464\n",
      "Iter: 270, Loss: 125.9630, Train MAE hat: 1.8456\n",
      "Iter: 271, Loss: 125.5387, Train MAE hat: 1.8449\n",
      "Iter: 272, Loss: 125.1946, Train MAE hat: 1.8441\n",
      "Iter: 273, Loss: 124.6311, Train MAE hat: 1.8434\n",
      "Iter: 274, Loss: 124.0846, Train MAE hat: 1.8426\n",
      "Iter: 275, Loss: 123.7572, Train MAE hat: 1.8419\n",
      "Iter: 276, Loss: 123.3444, Train MAE hat: 1.8411\n",
      "Iter: 277, Loss: 122.9277, Train MAE hat: 1.8404\n",
      "Iter: 278, Loss: 122.4717, Train MAE hat: 1.8397\n",
      "Iter: 279, Loss: 122.2741, Train MAE hat: 1.8389\n",
      "Iter: 280, Loss: 121.7546, Train MAE hat: 1.8382\n",
      "Iter: 281, Loss: 121.4177, Train MAE hat: 1.8375\n",
      "Iter: 282, Loss: 120.8840, Train MAE hat: 1.8367\n",
      "Iter: 283, Loss: 120.1905, Train MAE hat: 1.8360\n",
      "Iter: 284, Loss: 119.6148, Train MAE hat: 1.8353\n",
      "Iter: 285, Loss: 119.1160, Train MAE hat: 1.8345\n",
      "Iter: 286, Loss: 118.5569, Train MAE hat: 1.8338\n",
      "Iter: 287, Loss: 118.0871, Train MAE hat: 1.8330\n",
      "Iter: 288, Loss: 117.3837, Train MAE hat: 1.8323\n",
      "Iter: 289, Loss: 116.8329, Train MAE hat: 1.8315\n",
      "Iter: 290, Loss: 116.2579, Train MAE hat: 1.8308\n",
      "Iter: 291, Loss: 115.6608, Train MAE hat: 1.8300\n",
      "Iter: 292, Loss: 115.0607, Train MAE hat: 1.8293\n",
      "Iter: 293, Loss: 114.5744, Train MAE hat: 1.8285\n",
      "Iter: 294, Loss: 113.9575, Train MAE hat: 1.8278\n",
      "Iter: 295, Loss: 113.4264, Train MAE hat: 1.8270\n",
      "Iter: 296, Loss: 112.8862, Train MAE hat: 1.8263\n",
      "Iter: 297, Loss: 112.3631, Train MAE hat: 1.8255\n",
      "Iter: 298, Loss: 111.8572, Train MAE hat: 1.8247\n",
      "Iter: 299, Loss: 111.3496, Train MAE hat: 1.8240\n",
      "Iter: 300, Loss: 110.8674, Train MAE hat: 1.8232\n",
      "Iter: 301, Loss: 110.4278, Train MAE hat: 1.8224\n",
      "Iter: 302, Loss: 110.0142, Train MAE hat: 1.8217\n",
      "Iter: 303, Loss: 109.6559, Train MAE hat: 1.8209\n",
      "Iter: 304, Loss: 109.3107, Train MAE hat: 1.8201\n",
      "Iter: 305, Loss: 109.0050, Train MAE hat: 1.8194\n",
      "Iter: 306, Loss: 108.6043, Train MAE hat: 1.8186\n",
      "Iter: 307, Loss: 108.1908, Train MAE hat: 1.8178\n",
      "Iter: 308, Loss: 107.9188, Train MAE hat: 1.8171\n",
      "Iter: 309, Loss: 107.7488, Train MAE hat: 1.8163\n",
      "Iter: 310, Loss: 107.5250, Train MAE hat: 1.8156\n",
      "Iter: 311, Loss: 106.8268, Train MAE hat: 1.8148\n",
      "Iter: 312, Loss: 106.5297, Train MAE hat: 1.8141\n",
      "Iter: 313, Loss: 106.2884, Train MAE hat: 1.8133\n",
      "Iter: 314, Loss: 105.6583, Train MAE hat: 1.8126\n",
      "Iter: 315, Loss: 105.3700, Train MAE hat: 1.8118\n",
      "Iter: 316, Loss: 104.8758, Train MAE hat: 1.8111\n",
      "Iter: 317, Loss: 104.3831, Train MAE hat: 1.8103\n",
      "Iter: 318, Loss: 103.9895, Train MAE hat: 1.8096\n",
      "Iter: 319, Loss: 103.6883, Train MAE hat: 1.8088\n",
      "Iter: 320, Loss: 103.1460, Train MAE hat: 1.8081\n",
      "Iter: 321, Loss: 102.5891, Train MAE hat: 1.8073\n",
      "Iter: 322, Loss: 102.0253, Train MAE hat: 1.8066\n",
      "Iter: 323, Loss: 101.6332, Train MAE hat: 1.8058\n",
      "Iter: 324, Loss: 101.1093, Train MAE hat: 1.8051\n",
      "Iter: 325, Loss: 100.6094, Train MAE hat: 1.8043\n",
      "Iter: 326, Loss: 100.0600, Train MAE hat: 1.8036\n",
      "Iter: 327, Loss: 99.6869, Train MAE hat: 1.8028\n",
      "Iter: 328, Loss: 99.1670, Train MAE hat: 1.8020\n",
      "Iter: 329, Loss: 98.6671, Train MAE hat: 1.8013\n",
      "Iter: 330, Loss: 98.1369, Train MAE hat: 1.8005\n",
      "Iter: 331, Loss: 97.6969, Train MAE hat: 1.7997\n",
      "Iter: 332, Loss: 97.2295, Train MAE hat: 1.7990\n",
      "Iter: 333, Loss: 96.7705, Train MAE hat: 1.7982\n",
      "Iter: 334, Loss: 96.2822, Train MAE hat: 1.7974\n",
      "Iter: 335, Loss: 95.7717, Train MAE hat: 1.7967\n",
      "Iter: 336, Loss: 95.3179, Train MAE hat: 1.7959\n",
      "Iter: 337, Loss: 94.9059, Train MAE hat: 1.7951\n",
      "Iter: 338, Loss: 94.4770, Train MAE hat: 1.7943\n",
      "Iter: 339, Loss: 94.0496, Train MAE hat: 1.7935\n",
      "Iter: 340, Loss: 93.6994, Train MAE hat: 1.7928\n",
      "Iter: 341, Loss: 93.3234, Train MAE hat: 1.7920\n",
      "Iter: 342, Loss: 92.9280, Train MAE hat: 1.7912\n",
      "Iter: 343, Loss: 92.4821, Train MAE hat: 1.7904\n",
      "Iter: 344, Loss: 92.0543, Train MAE hat: 1.7897\n",
      "Iter: 345, Loss: 91.6821, Train MAE hat: 1.7889\n",
      "Iter: 346, Loss: 91.4400, Train MAE hat: 1.7881\n",
      "Iter: 347, Loss: 91.3020, Train MAE hat: 1.7873\n",
      "Iter: 348, Loss: 91.2604, Train MAE hat: 1.7865\n",
      "Iter: 349, Loss: 91.0652, Train MAE hat: 1.7858\n",
      "Iter: 350, Loss: 90.7809, Train MAE hat: 1.7850\n",
      "Iter: 351, Loss: 90.6428, Train MAE hat: 1.7843\n",
      "Iter: 352, Loss: 90.6874, Train MAE hat: 1.7835\n",
      "Iter: 353, Loss: 90.2660, Train MAE hat: 1.7828\n",
      "Iter: 354, Loss: 90.0106, Train MAE hat: 1.7820\n",
      "Iter: 355, Loss: 89.5734, Train MAE hat: 1.7813\n",
      "Iter: 356, Loss: 89.1319, Train MAE hat: 1.7805\n",
      "Iter: 357, Loss: 88.6158, Train MAE hat: 1.7798\n",
      "Iter: 358, Loss: 88.4124, Train MAE hat: 1.7790\n",
      "Iter: 359, Loss: 87.8399, Train MAE hat: 1.7783\n",
      "Iter: 360, Loss: 87.5356, Train MAE hat: 1.7775\n",
      "Iter: 361, Loss: 86.9177, Train MAE hat: 1.7768\n",
      "Iter: 362, Loss: 86.4821, Train MAE hat: 1.7760\n",
      "Iter: 363, Loss: 85.8958, Train MAE hat: 1.7752\n",
      "Iter: 364, Loss: 85.3778, Train MAE hat: 1.7745\n",
      "Iter: 365, Loss: 84.8506, Train MAE hat: 1.7737\n",
      "Iter: 366, Loss: 84.3932, Train MAE hat: 1.7730\n",
      "Iter: 367, Loss: 83.8669, Train MAE hat: 1.7722\n",
      "Iter: 368, Loss: 83.3632, Train MAE hat: 1.7714\n",
      "Iter: 369, Loss: 82.8873, Train MAE hat: 1.7706\n",
      "Iter: 370, Loss: 82.4538, Train MAE hat: 1.7698\n",
      "Iter: 371, Loss: 81.9921, Train MAE hat: 1.7691\n",
      "Iter: 372, Loss: 81.5846, Train MAE hat: 1.7683\n",
      "Iter: 373, Loss: 81.1500, Train MAE hat: 1.7675\n",
      "Iter: 374, Loss: 80.7151, Train MAE hat: 1.7667\n",
      "Iter: 375, Loss: 80.2961, Train MAE hat: 1.7659\n",
      "Iter: 376, Loss: 79.8895, Train MAE hat: 1.7651\n",
      "Iter: 377, Loss: 79.4846, Train MAE hat: 1.7643\n",
      "Iter: 378, Loss: 79.0932, Train MAE hat: 1.7635\n",
      "Iter: 379, Loss: 78.7011, Train MAE hat: 1.7627\n",
      "Iter: 380, Loss: 78.3366, Train MAE hat: 1.7619\n",
      "Iter: 381, Loss: 77.9736, Train MAE hat: 1.7611\n",
      "Iter: 382, Loss: 77.6445, Train MAE hat: 1.7603\n",
      "Iter: 383, Loss: 77.3331, Train MAE hat: 1.7595\n",
      "Iter: 384, Loss: 77.1254, Train MAE hat: 1.7587\n",
      "Iter: 385, Loss: 76.9830, Train MAE hat: 1.7579\n",
      "Iter: 386, Loss: 77.0321, Train MAE hat: 1.7571\n",
      "Iter: 387, Loss: 77.0727, Train MAE hat: 1.7564\n",
      "Iter: 388, Loss: 76.9811, Train MAE hat: 1.7556\n",
      "Iter: 389, Loss: 76.6057, Train MAE hat: 1.7548\n",
      "Iter: 390, Loss: 76.7201, Train MAE hat: 1.7540\n",
      "Iter: 391, Loss: 77.6630, Train MAE hat: 1.7533\n",
      "Iter: 392, Loss: 77.0185, Train MAE hat: 1.7525\n",
      "Iter: 393, Loss: 76.5171, Train MAE hat: 1.7518\n",
      "Iter: 394, Loss: 77.0810, Train MAE hat: 1.7510\n",
      "Iter: 395, Loss: 76.3277, Train MAE hat: 1.7503\n",
      "Iter: 396, Loss: 75.9493, Train MAE hat: 1.7496\n",
      "Iter: 397, Loss: 75.4472, Train MAE hat: 1.7488\n",
      "Iter: 398, Loss: 74.8306, Train MAE hat: 1.7481\n",
      "Iter: 399, Loss: 74.3785, Train MAE hat: 1.7473\n",
      "Iter: 400, Loss: 73.6678, Train MAE hat: 1.7466\n",
      "Iter: 401, Loss: 73.1153, Train MAE hat: 1.7458\n",
      "Iter: 402, Loss: 72.6230, Train MAE hat: 1.7450\n",
      "Iter: 403, Loss: 72.0185, Train MAE hat: 1.7443\n",
      "Iter: 404, Loss: 71.5945, Train MAE hat: 1.7435\n",
      "Iter: 405, Loss: 71.0840, Train MAE hat: 1.7427\n",
      "Iter: 406, Loss: 70.6539, Train MAE hat: 1.7419\n",
      "Iter: 407, Loss: 70.2059, Train MAE hat: 1.7411\n",
      "Iter: 408, Loss: 69.7829, Train MAE hat: 1.7403\n",
      "Iter: 409, Loss: 69.3790, Train MAE hat: 1.7396\n",
      "Iter: 410, Loss: 68.9720, Train MAE hat: 1.7388\n",
      "Iter: 411, Loss: 68.5996, Train MAE hat: 1.7380\n",
      "Iter: 412, Loss: 68.1921, Train MAE hat: 1.7372\n",
      "Iter: 413, Loss: 67.8345, Train MAE hat: 1.7364\n",
      "Iter: 414, Loss: 67.4584, Train MAE hat: 1.7356\n",
      "Iter: 415, Loss: 67.0945, Train MAE hat: 1.7347\n",
      "Iter: 416, Loss: 66.7424, Train MAE hat: 1.7339\n",
      "Iter: 417, Loss: 66.3907, Train MAE hat: 1.7331\n",
      "Iter: 418, Loss: 66.0425, Train MAE hat: 1.7323\n",
      "Iter: 419, Loss: 65.7029, Train MAE hat: 1.7315\n",
      "Iter: 420, Loss: 65.3677, Train MAE hat: 1.7307\n",
      "Iter: 421, Loss: 65.0368, Train MAE hat: 1.7299\n",
      "Iter: 422, Loss: 64.7064, Train MAE hat: 1.7291\n",
      "Iter: 423, Loss: 64.3859, Train MAE hat: 1.7282\n",
      "Iter: 424, Loss: 64.0668, Train MAE hat: 1.7274\n",
      "Iter: 425, Loss: 63.7542, Train MAE hat: 1.7266\n",
      "Iter: 426, Loss: 63.4491, Train MAE hat: 1.7258\n",
      "Iter: 427, Loss: 63.1584, Train MAE hat: 1.7249\n",
      "Iter: 428, Loss: 62.8906, Train MAE hat: 1.7241\n",
      "Iter: 429, Loss: 62.6777, Train MAE hat: 1.7233\n",
      "Iter: 430, Loss: 62.5752, Train MAE hat: 1.7225\n",
      "Iter: 431, Loss: 62.6914, Train MAE hat: 1.7217\n",
      "Iter: 432, Loss: 63.1809, Train MAE hat: 1.7209\n",
      "Iter: 433, Loss: 63.6933, Train MAE hat: 1.7201\n",
      "Iter: 434, Loss: 63.1288, Train MAE hat: 1.7193\n",
      "Iter: 435, Loss: 61.8553, Train MAE hat: 1.7185\n",
      "Iter: 436, Loss: 62.4952, Train MAE hat: 1.7177\n",
      "Iter: 437, Loss: 63.3453, Train MAE hat: 1.7170\n",
      "Iter: 438, Loss: 62.4345, Train MAE hat: 1.7162\n",
      "Iter: 439, Loss: 62.8021, Train MAE hat: 1.7154\n",
      "Iter: 440, Loss: 62.8568, Train MAE hat: 1.7147\n",
      "Iter: 441, Loss: 62.6072, Train MAE hat: 1.7139\n",
      "Iter: 442, Loss: 62.3628, Train MAE hat: 1.7132\n",
      "Iter: 443, Loss: 61.7046, Train MAE hat: 1.7124\n",
      "Iter: 444, Loss: 61.2866, Train MAE hat: 1.7117\n",
      "Iter: 445, Loss: 61.0028, Train MAE hat: 1.7109\n",
      "Iter: 446, Loss: 60.3884, Train MAE hat: 1.7101\n",
      "Iter: 447, Loss: 59.8609, Train MAE hat: 1.7094\n",
      "Iter: 448, Loss: 59.3403, Train MAE hat: 1.7086\n",
      "Iter: 449, Loss: 58.9027, Train MAE hat: 1.7078\n",
      "Iter: 450, Loss: 58.4587, Train MAE hat: 1.7070\n",
      "Iter: 451, Loss: 58.0142, Train MAE hat: 1.7062\n",
      "Iter: 452, Loss: 57.6131, Train MAE hat: 1.7054\n",
      "Iter: 453, Loss: 57.2207, Train MAE hat: 1.7047\n",
      "Iter: 454, Loss: 56.8118, Train MAE hat: 1.7039\n",
      "Iter: 455, Loss: 56.4500, Train MAE hat: 1.7030\n",
      "Iter: 456, Loss: 56.1271, Train MAE hat: 1.7022\n",
      "Iter: 457, Loss: 55.7675, Train MAE hat: 1.7014\n",
      "Iter: 458, Loss: 55.4266, Train MAE hat: 1.7006\n",
      "Iter: 459, Loss: 55.1107, Train MAE hat: 1.6998\n",
      "Iter: 460, Loss: 54.7984, Train MAE hat: 1.6990\n",
      "Iter: 461, Loss: 54.4708, Train MAE hat: 1.6982\n",
      "Iter: 462, Loss: 54.1744, Train MAE hat: 1.6973\n",
      "Iter: 463, Loss: 53.8738, Train MAE hat: 1.6965\n",
      "Iter: 464, Loss: 53.5823, Train MAE hat: 1.6957\n",
      "Iter: 465, Loss: 53.2938, Train MAE hat: 1.6949\n",
      "Iter: 466, Loss: 53.0034, Train MAE hat: 1.6940\n",
      "Iter: 467, Loss: 52.7253, Train MAE hat: 1.6932\n",
      "Iter: 468, Loss: 52.4569, Train MAE hat: 1.6924\n",
      "Iter: 469, Loss: 52.1884, Train MAE hat: 1.6916\n",
      "Iter: 470, Loss: 51.9267, Train MAE hat: 1.6907\n",
      "Iter: 471, Loss: 51.6719, Train MAE hat: 1.6899\n",
      "Iter: 472, Loss: 51.4354, Train MAE hat: 1.6891\n",
      "Iter: 473, Loss: 51.2221, Train MAE hat: 1.6882\n",
      "Iter: 474, Loss: 51.0598, Train MAE hat: 1.6874\n",
      "Iter: 475, Loss: 50.9787, Train MAE hat: 1.6866\n",
      "Iter: 476, Loss: 51.0400, Train MAE hat: 1.6857\n",
      "Iter: 477, Loss: 51.2104, Train MAE hat: 1.6849\n",
      "Iter: 478, Loss: 51.2659, Train MAE hat: 1.6841\n",
      "Iter: 479, Loss: 50.7907, Train MAE hat: 1.6833\n",
      "Iter: 480, Loss: 50.2329, Train MAE hat: 1.6825\n",
      "Iter: 481, Loss: 50.4999, Train MAE hat: 1.6817\n",
      "Iter: 482, Loss: 51.1109, Train MAE hat: 1.6809\n",
      "Iter: 483, Loss: 50.7512, Train MAE hat: 1.6801\n",
      "Iter: 484, Loss: 50.6950, Train MAE hat: 1.6793\n",
      "Iter: 485, Loss: 50.9427, Train MAE hat: 1.6785\n",
      "Iter: 486, Loss: 50.4925, Train MAE hat: 1.6777\n",
      "Iter: 487, Loss: 50.3674, Train MAE hat: 1.6769\n",
      "Iter: 488, Loss: 50.3345, Train MAE hat: 1.6762\n",
      "Iter: 489, Loss: 49.5622, Train MAE hat: 1.6754\n",
      "Iter: 490, Loss: 49.4470, Train MAE hat: 1.6746\n",
      "Iter: 491, Loss: 48.9862, Train MAE hat: 1.6738\n",
      "Iter: 492, Loss: 48.6580, Train MAE hat: 1.6730\n",
      "Iter: 493, Loss: 48.2713, Train MAE hat: 1.6722\n",
      "Iter: 494, Loss: 47.8245, Train MAE hat: 1.6714\n",
      "Iter: 495, Loss: 47.5317, Train MAE hat: 1.6706\n",
      "Iter: 496, Loss: 47.0952, Train MAE hat: 1.6698\n",
      "Iter: 497, Loss: 46.8092, Train MAE hat: 1.6690\n",
      "Iter: 498, Loss: 46.4641, Train MAE hat: 1.6682\n",
      "Iter: 499, Loss: 46.1388, Train MAE hat: 1.6674\n",
      "Iter: 500, Loss: 45.8367, Train MAE hat: 1.6666\n",
      "Iter: 501, Loss: 45.5538, Train MAE hat: 1.6658\n",
      "Iter: 502, Loss: 45.2609, Train MAE hat: 1.6649\n",
      "Iter: 503, Loss: 44.9992, Train MAE hat: 1.6641\n",
      "Iter: 504, Loss: 44.7232, Train MAE hat: 1.6633\n",
      "Iter: 505, Loss: 44.4627, Train MAE hat: 1.6625\n",
      "Iter: 506, Loss: 44.2110, Train MAE hat: 1.6616\n",
      "Iter: 507, Loss: 43.9595, Train MAE hat: 1.6608\n",
      "Iter: 508, Loss: 43.7191, Train MAE hat: 1.6600\n",
      "Iter: 509, Loss: 43.4818, Train MAE hat: 1.6591\n",
      "Iter: 510, Loss: 43.2438, Train MAE hat: 1.6583\n",
      "Iter: 511, Loss: 43.0162, Train MAE hat: 1.6574\n",
      "Iter: 512, Loss: 42.7957, Train MAE hat: 1.6566\n",
      "Iter: 513, Loss: 42.5727, Train MAE hat: 1.6558\n",
      "Iter: 514, Loss: 42.3611, Train MAE hat: 1.6549\n",
      "Iter: 515, Loss: 42.1530, Train MAE hat: 1.6541\n",
      "Iter: 516, Loss: 41.9635, Train MAE hat: 1.6532\n",
      "Iter: 517, Loss: 41.7963, Train MAE hat: 1.6524\n",
      "Iter: 518, Loss: 41.6728, Train MAE hat: 1.6516\n",
      "Iter: 519, Loss: 41.6210, Train MAE hat: 1.6507\n",
      "Iter: 520, Loss: 41.6880, Train MAE hat: 1.6499\n",
      "Iter: 521, Loss: 41.8777, Train MAE hat: 1.6491\n",
      "Iter: 522, Loss: 41.9724, Train MAE hat: 1.6482\n",
      "Iter: 523, Loss: 41.6607, Train MAE hat: 1.6474\n",
      "Iter: 524, Loss: 41.0239, Train MAE hat: 1.6466\n",
      "Iter: 525, Loss: 41.0356, Train MAE hat: 1.6458\n",
      "Iter: 526, Loss: 41.7981, Train MAE hat: 1.6450\n",
      "Iter: 527, Loss: 41.9338, Train MAE hat: 1.6442\n",
      "Iter: 528, Loss: 41.3858, Train MAE hat: 1.6434\n",
      "Iter: 529, Loss: 41.9693, Train MAE hat: 1.6426\n",
      "Iter: 530, Loss: 41.9204, Train MAE hat: 1.6418\n",
      "Iter: 531, Loss: 41.3673, Train MAE hat: 1.6410\n",
      "Iter: 532, Loss: 41.6311, Train MAE hat: 1.6403\n",
      "Iter: 533, Loss: 41.2256, Train MAE hat: 1.6395\n",
      "Iter: 534, Loss: 40.8660, Train MAE hat: 1.6387\n",
      "Iter: 535, Loss: 40.8201, Train MAE hat: 1.6379\n",
      "Iter: 536, Loss: 40.5676, Train MAE hat: 1.6371\n",
      "Iter: 537, Loss: 40.1846, Train MAE hat: 1.6364\n",
      "Iter: 538, Loss: 39.8517, Train MAE hat: 1.6356\n",
      "Iter: 539, Loss: 39.4458, Train MAE hat: 1.6348\n",
      "Iter: 540, Loss: 39.2318, Train MAE hat: 1.6340\n",
      "Iter: 541, Loss: 38.8912, Train MAE hat: 1.6332\n",
      "Iter: 542, Loss: 38.4851, Train MAE hat: 1.6324\n",
      "Iter: 543, Loss: 38.1358, Train MAE hat: 1.6316\n",
      "Iter: 544, Loss: 37.8157, Train MAE hat: 1.6308\n",
      "Iter: 545, Loss: 37.5668, Train MAE hat: 1.6300\n",
      "Iter: 546, Loss: 37.3119, Train MAE hat: 1.6292\n",
      "Iter: 547, Loss: 37.0311, Train MAE hat: 1.6283\n",
      "Iter: 548, Loss: 36.7715, Train MAE hat: 1.6275\n",
      "Iter: 549, Loss: 36.5537, Train MAE hat: 1.6267\n",
      "Iter: 550, Loss: 36.3155, Train MAE hat: 1.6259\n",
      "Iter: 551, Loss: 36.0843, Train MAE hat: 1.6250\n",
      "Iter: 552, Loss: 35.8691, Train MAE hat: 1.6242\n",
      "Iter: 553, Loss: 35.6610, Train MAE hat: 1.6234\n",
      "Iter: 554, Loss: 35.4455, Train MAE hat: 1.6225\n",
      "Iter: 555, Loss: 35.2437, Train MAE hat: 1.6217\n",
      "Iter: 556, Loss: 35.0464, Train MAE hat: 1.6209\n",
      "Iter: 557, Loss: 34.8443, Train MAE hat: 1.6200\n",
      "Iter: 558, Loss: 34.6557, Train MAE hat: 1.6192\n",
      "Iter: 559, Loss: 34.4637, Train MAE hat: 1.6183\n",
      "Iter: 560, Loss: 34.2816, Train MAE hat: 1.6175\n",
      "Iter: 561, Loss: 34.0955, Train MAE hat: 1.6167\n",
      "Iter: 562, Loss: 33.9132, Train MAE hat: 1.6158\n",
      "Iter: 563, Loss: 33.7401, Train MAE hat: 1.6150\n",
      "Iter: 564, Loss: 33.5648, Train MAE hat: 1.6141\n",
      "Iter: 565, Loss: 33.3957, Train MAE hat: 1.6133\n",
      "Iter: 566, Loss: 33.2321, Train MAE hat: 1.6124\n",
      "Iter: 567, Loss: 33.0727, Train MAE hat: 1.6116\n",
      "Iter: 568, Loss: 32.9293, Train MAE hat: 1.6107\n",
      "Iter: 569, Loss: 32.8224, Train MAE hat: 1.6099\n",
      "Iter: 570, Loss: 32.7878, Train MAE hat: 1.6090\n",
      "Iter: 571, Loss: 32.9066, Train MAE hat: 1.6082\n",
      "Iter: 572, Loss: 33.3866, Train MAE hat: 1.6074\n",
      "Iter: 573, Loss: 34.1568, Train MAE hat: 1.6066\n",
      "Iter: 574, Loss: 34.8294, Train MAE hat: 1.6058\n",
      "Iter: 575, Loss: 33.7648, Train MAE hat: 1.6050\n",
      "Iter: 576, Loss: 33.5819, Train MAE hat: 1.6042\n",
      "Iter: 577, Loss: 34.9514, Train MAE hat: 1.6034\n",
      "Iter: 578, Loss: 34.8051, Train MAE hat: 1.6026\n",
      "Iter: 579, Loss: 35.1105, Train MAE hat: 1.6019\n",
      "Iter: 580, Loss: 35.1613, Train MAE hat: 1.6012\n",
      "Iter: 581, Loss: 34.9398, Train MAE hat: 1.6004\n",
      "Iter: 582, Loss: 34.5841, Train MAE hat: 1.5997\n",
      "Iter: 583, Loss: 34.3322, Train MAE hat: 1.5990\n",
      "Iter: 584, Loss: 33.7457, Train MAE hat: 1.5982\n",
      "Iter: 585, Loss: 33.2449, Train MAE hat: 1.5975\n",
      "Iter: 586, Loss: 32.8844, Train MAE hat: 1.5967\n",
      "Iter: 587, Loss: 32.3142, Train MAE hat: 1.5959\n",
      "Iter: 588, Loss: 31.9903, Train MAE hat: 1.5952\n",
      "Iter: 589, Loss: 31.6831, Train MAE hat: 1.5944\n",
      "Iter: 590, Loss: 31.3384, Train MAE hat: 1.5936\n",
      "Iter: 591, Loss: 31.0282, Train MAE hat: 1.5928\n",
      "Iter: 592, Loss: 30.7718, Train MAE hat: 1.5920\n",
      "Iter: 593, Loss: 30.4851, Train MAE hat: 1.5912\n",
      "Iter: 594, Loss: 30.2535, Train MAE hat: 1.5904\n",
      "Iter: 595, Loss: 29.9852, Train MAE hat: 1.5896\n",
      "Iter: 596, Loss: 29.7821, Train MAE hat: 1.5888\n",
      "Iter: 597, Loss: 29.5428, Train MAE hat: 1.5880\n",
      "Iter: 598, Loss: 29.3433, Train MAE hat: 1.5872\n",
      "Iter: 599, Loss: 29.1218, Train MAE hat: 1.5863\n",
      "Iter: 600, Loss: 28.9343, Train MAE hat: 1.5855\n",
      "Iter: 601, Loss: 28.7362, Train MAE hat: 1.5847\n",
      "Iter: 602, Loss: 28.5550, Train MAE hat: 1.5839\n",
      "Iter: 603, Loss: 28.3663, Train MAE hat: 1.5830\n",
      "Iter: 604, Loss: 28.1956, Train MAE hat: 1.5822\n",
      "Iter: 605, Loss: 28.0167, Train MAE hat: 1.5814\n",
      "Iter: 606, Loss: 27.8468, Train MAE hat: 1.5805\n",
      "Iter: 607, Loss: 27.6863, Train MAE hat: 1.5797\n",
      "Iter: 608, Loss: 27.5190, Train MAE hat: 1.5789\n",
      "Iter: 609, Loss: 27.3627, Train MAE hat: 1.5780\n",
      "Iter: 610, Loss: 27.2079, Train MAE hat: 1.5772\n",
      "Iter: 611, Loss: 27.0512, Train MAE hat: 1.5763\n",
      "Iter: 612, Loss: 26.9035, Train MAE hat: 1.5755\n",
      "Iter: 613, Loss: 26.7524, Train MAE hat: 1.5746\n",
      "Iter: 614, Loss: 26.6078, Train MAE hat: 1.5738\n",
      "Iter: 615, Loss: 26.4638, Train MAE hat: 1.5730\n",
      "Iter: 616, Loss: 26.3224, Train MAE hat: 1.5721\n",
      "Iter: 617, Loss: 26.1836, Train MAE hat: 1.5713\n",
      "Iter: 618, Loss: 26.0467, Train MAE hat: 1.5704\n",
      "Iter: 619, Loss: 25.9153, Train MAE hat: 1.5696\n",
      "Iter: 620, Loss: 25.7898, Train MAE hat: 1.5687\n",
      "Iter: 621, Loss: 25.6785, Train MAE hat: 1.5679\n",
      "Iter: 622, Loss: 25.5935, Train MAE hat: 1.5670\n",
      "Iter: 623, Loss: 25.5643, Train MAE hat: 1.5662\n",
      "Iter: 624, Loss: 25.6489, Train MAE hat: 1.5654\n",
      "Iter: 625, Loss: 25.9438, Train MAE hat: 1.5645\n",
      "Iter: 626, Loss: 26.4992, Train MAE hat: 1.5637\n",
      "Iter: 627, Loss: 26.9747, Train MAE hat: 1.5629\n",
      "Iter: 628, Loss: 26.5503, Train MAE hat: 1.5622\n",
      "Iter: 629, Loss: 25.4829, Train MAE hat: 1.5614\n",
      "Iter: 630, Loss: 25.7021, Train MAE hat: 1.5605\n",
      "Iter: 631, Loss: 26.2322, Train MAE hat: 1.5597\n",
      "Iter: 632, Loss: 25.6135, Train MAE hat: 1.5590\n",
      "Iter: 633, Loss: 25.3794, Train MAE hat: 1.5582\n",
      "Iter: 634, Loss: 25.7097, Train MAE hat: 1.5574\n",
      "Iter: 635, Loss: 25.0935, Train MAE hat: 1.5566\n",
      "Iter: 636, Loss: 24.9768, Train MAE hat: 1.5558\n",
      "Iter: 637, Loss: 24.9039, Train MAE hat: 1.5550\n",
      "Iter: 638, Loss: 24.5624, Train MAE hat: 1.5541\n",
      "Iter: 639, Loss: 24.5397, Train MAE hat: 1.5533\n",
      "Iter: 640, Loss: 24.1887, Train MAE hat: 1.5525\n",
      "Iter: 641, Loss: 24.0492, Train MAE hat: 1.5517\n",
      "Iter: 642, Loss: 23.8897, Train MAE hat: 1.5509\n",
      "Iter: 643, Loss: 23.6684, Train MAE hat: 1.5501\n",
      "Iter: 644, Loss: 23.5398, Train MAE hat: 1.5493\n",
      "Iter: 645, Loss: 23.3119, Train MAE hat: 1.5484\n",
      "Iter: 646, Loss: 23.1716, Train MAE hat: 1.5476\n",
      "Iter: 647, Loss: 23.0156, Train MAE hat: 1.5468\n",
      "Iter: 648, Loss: 22.8500, Train MAE hat: 1.5460\n",
      "Iter: 649, Loss: 22.7187, Train MAE hat: 1.5451\n",
      "Iter: 650, Loss: 22.5790, Train MAE hat: 1.5443\n",
      "Iter: 651, Loss: 22.4659, Train MAE hat: 1.5435\n",
      "Iter: 652, Loss: 22.3515, Train MAE hat: 1.5426\n",
      "Iter: 653, Loss: 22.2367, Train MAE hat: 1.5418\n",
      "Iter: 654, Loss: 22.1559, Train MAE hat: 1.5410\n",
      "Iter: 655, Loss: 22.0567, Train MAE hat: 1.5402\n",
      "Iter: 656, Loss: 21.9931, Train MAE hat: 1.5393\n",
      "Iter: 657, Loss: 21.9352, Train MAE hat: 1.5385\n",
      "Iter: 658, Loss: 21.8922, Train MAE hat: 1.5377\n",
      "Iter: 659, Loss: 21.8519, Train MAE hat: 1.5368\n",
      "Iter: 660, Loss: 21.8275, Train MAE hat: 1.5360\n",
      "Iter: 661, Loss: 21.8229, Train MAE hat: 1.5352\n",
      "Iter: 662, Loss: 21.8359, Train MAE hat: 1.5344\n",
      "Iter: 663, Loss: 21.8928, Train MAE hat: 1.5336\n",
      "Iter: 664, Loss: 21.8904, Train MAE hat: 1.5328\n",
      "Iter: 665, Loss: 21.8201, Train MAE hat: 1.5320\n",
      "Iter: 666, Loss: 21.6210, Train MAE hat: 1.5312\n",
      "Iter: 667, Loss: 21.4396, Train MAE hat: 1.5304\n",
      "Iter: 668, Loss: 21.3305, Train MAE hat: 1.5296\n",
      "Iter: 669, Loss: 21.2576, Train MAE hat: 1.5288\n",
      "Iter: 670, Loss: 21.1177, Train MAE hat: 1.5280\n",
      "Iter: 671, Loss: 20.9210, Train MAE hat: 1.5272\n",
      "Iter: 672, Loss: 20.7824, Train MAE hat: 1.5263\n",
      "Iter: 673, Loss: 20.7028, Train MAE hat: 1.5255\n",
      "Iter: 674, Loss: 20.5810, Train MAE hat: 1.5247\n",
      "Iter: 675, Loss: 20.4412, Train MAE hat: 1.5239\n",
      "Iter: 676, Loss: 20.2424, Train MAE hat: 1.5231\n",
      "Iter: 677, Loss: 20.0580, Train MAE hat: 1.5223\n",
      "Iter: 678, Loss: 19.9484, Train MAE hat: 1.5215\n",
      "Iter: 679, Loss: 19.8286, Train MAE hat: 1.5207\n",
      "Iter: 680, Loss: 19.6507, Train MAE hat: 1.5198\n",
      "Iter: 681, Loss: 19.5292, Train MAE hat: 1.5190\n",
      "Iter: 682, Loss: 19.3763, Train MAE hat: 1.5182\n",
      "Iter: 683, Loss: 19.2460, Train MAE hat: 1.5174\n",
      "Iter: 684, Loss: 19.1659, Train MAE hat: 1.5165\n",
      "Iter: 685, Loss: 19.0304, Train MAE hat: 1.5157\n",
      "Iter: 686, Loss: 18.9128, Train MAE hat: 1.5149\n",
      "Iter: 687, Loss: 18.8243, Train MAE hat: 1.5141\n",
      "Iter: 688, Loss: 18.7345, Train MAE hat: 1.5132\n",
      "Iter: 689, Loss: 18.6774, Train MAE hat: 1.5124\n",
      "Iter: 690, Loss: 18.6225, Train MAE hat: 1.5116\n",
      "Iter: 691, Loss: 18.5777, Train MAE hat: 1.5108\n",
      "Iter: 692, Loss: 18.5499, Train MAE hat: 1.5099\n",
      "Iter: 693, Loss: 18.5120, Train MAE hat: 1.5091\n",
      "Iter: 694, Loss: 18.4579, Train MAE hat: 1.5083\n",
      "Iter: 695, Loss: 18.3544, Train MAE hat: 1.5075\n",
      "Iter: 696, Loss: 18.2447, Train MAE hat: 1.5067\n",
      "Iter: 697, Loss: 18.1798, Train MAE hat: 1.5059\n",
      "Iter: 698, Loss: 18.2408, Train MAE hat: 1.5050\n",
      "Iter: 699, Loss: 18.3673, Train MAE hat: 1.5042\n",
      "Iter: 700, Loss: 18.4642, Train MAE hat: 1.5034\n",
      "Iter: 701, Loss: 18.4560, Train MAE hat: 1.5027\n",
      "Iter: 702, Loss: 18.4341, Train MAE hat: 1.5019\n",
      "Iter: 703, Loss: 18.5116, Train MAE hat: 1.5011\n",
      "Iter: 704, Loss: 18.5960, Train MAE hat: 1.5003\n",
      "Iter: 705, Loss: 18.5142, Train MAE hat: 1.4995\n",
      "Iter: 706, Loss: 18.5050, Train MAE hat: 1.4988\n",
      "Iter: 707, Loss: 18.5417, Train MAE hat: 1.4980\n",
      "Iter: 708, Loss: 18.4460, Train MAE hat: 1.4972\n",
      "Iter: 709, Loss: 18.3307, Train MAE hat: 1.4965\n",
      "Iter: 710, Loss: 18.2123, Train MAE hat: 1.4957\n",
      "Iter: 711, Loss: 18.2531, Train MAE hat: 1.4949\n",
      "Iter: 712, Loss: 17.8877, Train MAE hat: 1.4942\n",
      "Iter: 713, Loss: 17.8489, Train MAE hat: 1.4934\n",
      "Iter: 714, Loss: 17.7110, Train MAE hat: 1.4926\n",
      "Iter: 715, Loss: 17.4849, Train MAE hat: 1.4918\n",
      "Iter: 716, Loss: 17.2895, Train MAE hat: 1.4911\n",
      "Iter: 717, Loss: 17.0787, Train MAE hat: 1.4903\n",
      "Iter: 718, Loss: 16.8743, Train MAE hat: 1.4895\n",
      "Iter: 719, Loss: 16.7082, Train MAE hat: 1.4887\n",
      "Iter: 720, Loss: 16.5327, Train MAE hat: 1.4879\n",
      "Iter: 721, Loss: 16.4011, Train MAE hat: 1.4871\n",
      "Iter: 722, Loss: 16.2498, Train MAE hat: 1.4863\n",
      "Iter: 723, Loss: 16.0916, Train MAE hat: 1.4855\n",
      "Iter: 724, Loss: 15.9597, Train MAE hat: 1.4847\n",
      "Iter: 725, Loss: 15.8345, Train MAE hat: 1.4839\n",
      "Iter: 726, Loss: 15.7116, Train MAE hat: 1.4831\n",
      "Iter: 727, Loss: 15.5998, Train MAE hat: 1.4823\n",
      "Iter: 728, Loss: 15.4831, Train MAE hat: 1.4815\n",
      "Iter: 729, Loss: 15.3721, Train MAE hat: 1.4807\n",
      "Iter: 730, Loss: 15.2751, Train MAE hat: 1.4798\n",
      "Iter: 731, Loss: 15.1722, Train MAE hat: 1.4790\n",
      "Iter: 732, Loss: 15.0614, Train MAE hat: 1.4782\n",
      "Iter: 733, Loss: 14.9693, Train MAE hat: 1.4774\n",
      "Iter: 734, Loss: 14.8778, Train MAE hat: 1.4766\n",
      "Iter: 735, Loss: 14.7887, Train MAE hat: 1.4758\n",
      "Iter: 736, Loss: 14.7082, Train MAE hat: 1.4749\n",
      "Iter: 737, Loss: 14.6229, Train MAE hat: 1.4741\n",
      "Iter: 738, Loss: 14.5569, Train MAE hat: 1.4733\n",
      "Iter: 739, Loss: 14.5063, Train MAE hat: 1.4725\n",
      "Iter: 740, Loss: 14.4928, Train MAE hat: 1.4717\n",
      "Iter: 741, Loss: 14.5403, Train MAE hat: 1.4708\n",
      "Iter: 742, Loss: 14.7115, Train MAE hat: 1.4700\n",
      "Iter: 743, Loss: 15.0394, Train MAE hat: 1.4692\n",
      "Iter: 744, Loss: 15.4998, Train MAE hat: 1.4685\n",
      "Iter: 745, Loss: 15.8052, Train MAE hat: 1.4677\n",
      "Iter: 746, Loss: 15.7076, Train MAE hat: 1.4670\n",
      "Iter: 747, Loss: 15.5928, Train MAE hat: 1.4662\n",
      "Iter: 748, Loss: 16.1148, Train MAE hat: 1.4655\n",
      "Iter: 749, Loss: 16.3155, Train MAE hat: 1.4647\n",
      "Iter: 750, Loss: 15.7957, Train MAE hat: 1.4640\n",
      "Iter: 751, Loss: 15.6316, Train MAE hat: 1.4633\n",
      "Iter: 752, Loss: 15.5641, Train MAE hat: 1.4625\n",
      "Iter: 753, Loss: 15.1682, Train MAE hat: 1.4618\n",
      "Iter: 754, Loss: 15.0719, Train MAE hat: 1.4610\n",
      "Iter: 755, Loss: 14.8844, Train MAE hat: 1.4603\n",
      "Iter: 756, Loss: 14.5892, Train MAE hat: 1.4595\n",
      "Iter: 757, Loss: 14.4367, Train MAE hat: 1.4588\n",
      "Iter: 758, Loss: 14.1480, Train MAE hat: 1.4580\n",
      "Iter: 759, Loss: 13.9457, Train MAE hat: 1.4573\n",
      "Iter: 760, Loss: 13.8323, Train MAE hat: 1.4565\n",
      "Iter: 761, Loss: 13.6582, Train MAE hat: 1.4557\n",
      "Iter: 762, Loss: 13.5399, Train MAE hat: 1.4549\n",
      "Iter: 763, Loss: 13.3554, Train MAE hat: 1.4542\n",
      "Iter: 764, Loss: 13.2380, Train MAE hat: 1.4534\n",
      "Iter: 765, Loss: 13.0916, Train MAE hat: 1.4526\n",
      "Iter: 766, Loss: 12.9784, Train MAE hat: 1.4518\n",
      "Iter: 767, Loss: 12.8670, Train MAE hat: 1.4510\n",
      "Iter: 768, Loss: 12.7627, Train MAE hat: 1.4502\n",
      "Iter: 769, Loss: 12.6571, Train MAE hat: 1.4494\n",
      "Iter: 770, Loss: 12.5533, Train MAE hat: 1.4486\n",
      "Iter: 771, Loss: 12.4651, Train MAE hat: 1.4478\n",
      "Iter: 772, Loss: 12.3679, Train MAE hat: 1.4470\n",
      "Iter: 773, Loss: 12.2785, Train MAE hat: 1.4462\n",
      "Iter: 774, Loss: 12.1900, Train MAE hat: 1.4454\n",
      "Iter: 775, Loss: 12.1015, Train MAE hat: 1.4446\n",
      "Iter: 776, Loss: 12.0150, Train MAE hat: 1.4438\n",
      "Iter: 777, Loss: 11.9324, Train MAE hat: 1.4430\n",
      "Iter: 778, Loss: 11.8536, Train MAE hat: 1.4421\n",
      "Iter: 779, Loss: 11.7769, Train MAE hat: 1.4413\n",
      "Iter: 780, Loss: 11.7007, Train MAE hat: 1.4405\n",
      "Iter: 781, Loss: 11.6238, Train MAE hat: 1.4397\n",
      "Iter: 782, Loss: 11.5514, Train MAE hat: 1.4389\n",
      "Iter: 783, Loss: 11.4804, Train MAE hat: 1.4381\n",
      "Iter: 784, Loss: 11.4140, Train MAE hat: 1.4373\n",
      "Iter: 785, Loss: 11.3483, Train MAE hat: 1.4365\n",
      "Iter: 786, Loss: 11.2874, Train MAE hat: 1.4356\n",
      "Iter: 787, Loss: 11.2368, Train MAE hat: 1.4348\n",
      "Iter: 788, Loss: 11.2045, Train MAE hat: 1.4340\n",
      "Iter: 789, Loss: 11.2088, Train MAE hat: 1.4332\n",
      "Iter: 790, Loss: 11.2899, Train MAE hat: 1.4324\n",
      "Iter: 791, Loss: 11.4982, Train MAE hat: 1.4316\n",
      "Iter: 792, Loss: 11.9497, Train MAE hat: 1.4308\n",
      "Iter: 793, Loss: 12.5576, Train MAE hat: 1.4301\n",
      "Iter: 794, Loss: 12.9480, Train MAE hat: 1.4294\n",
      "Iter: 795, Loss: 12.4268, Train MAE hat: 1.4286\n",
      "Iter: 796, Loss: 11.9786, Train MAE hat: 1.4279\n",
      "Iter: 797, Loss: 12.9854, Train MAE hat: 1.4272\n",
      "Iter: 798, Loss: 13.4830, Train MAE hat: 1.4265\n",
      "Iter: 799, Loss: 12.4334, Train MAE hat: 1.4257\n",
      "Iter: 800, Loss: 12.7974, Train MAE hat: 1.4250\n",
      "Iter: 801, Loss: 13.0416, Train MAE hat: 1.4243\n",
      "Iter: 802, Loss: 11.9597, Train MAE hat: 1.4236\n",
      "Iter: 803, Loss: 12.3935, Train MAE hat: 1.4229\n",
      "Iter: 804, Loss: 11.9515, Train MAE hat: 1.4222\n",
      "Iter: 805, Loss: 11.7457, Train MAE hat: 1.4214\n",
      "Iter: 806, Loss: 11.6444, Train MAE hat: 1.4207\n",
      "Iter: 807, Loss: 11.2216, Train MAE hat: 1.4200\n",
      "Iter: 808, Loss: 11.2278, Train MAE hat: 1.4192\n",
      "Iter: 809, Loss: 10.9213, Train MAE hat: 1.4185\n",
      "Iter: 810, Loss: 10.8288, Train MAE hat: 1.4177\n",
      "Iter: 811, Loss: 10.6186, Train MAE hat: 1.4170\n",
      "Iter: 812, Loss: 10.5373, Train MAE hat: 1.4162\n",
      "Iter: 813, Loss: 10.4026, Train MAE hat: 1.4154\n",
      "Iter: 814, Loss: 10.2645, Train MAE hat: 1.4147\n",
      "Iter: 815, Loss: 10.1623, Train MAE hat: 1.4139\n",
      "Iter: 816, Loss: 10.0548, Train MAE hat: 1.4131\n",
      "Iter: 817, Loss: 9.9533, Train MAE hat: 1.4123\n",
      "Iter: 818, Loss: 9.8637, Train MAE hat: 1.4115\n",
      "Iter: 819, Loss: 9.7658, Train MAE hat: 1.4108\n",
      "Iter: 820, Loss: 9.6838, Train MAE hat: 1.4100\n",
      "Iter: 821, Loss: 9.5970, Train MAE hat: 1.4092\n",
      "Iter: 822, Loss: 9.5148, Train MAE hat: 1.4084\n",
      "Iter: 823, Loss: 9.4345, Train MAE hat: 1.4076\n",
      "Iter: 824, Loss: 9.3592, Train MAE hat: 1.4068\n",
      "Iter: 825, Loss: 9.2922, Train MAE hat: 1.4060\n",
      "Iter: 826, Loss: 9.2169, Train MAE hat: 1.4052\n",
      "Iter: 827, Loss: 9.1473, Train MAE hat: 1.4044\n",
      "Iter: 828, Loss: 9.0800, Train MAE hat: 1.4036\n",
      "Iter: 829, Loss: 9.0164, Train MAE hat: 1.4028\n",
      "Iter: 830, Loss: 8.9528, Train MAE hat: 1.4020\n",
      "Iter: 831, Loss: 8.8891, Train MAE hat: 1.4012\n",
      "Iter: 832, Loss: 8.8299, Train MAE hat: 1.4004\n",
      "Iter: 833, Loss: 8.7719, Train MAE hat: 1.3996\n",
      "Iter: 834, Loss: 8.7159, Train MAE hat: 1.3988\n",
      "Iter: 835, Loss: 8.6646, Train MAE hat: 1.3980\n",
      "Iter: 836, Loss: 8.6170, Train MAE hat: 1.3972\n",
      "Iter: 837, Loss: 8.5831, Train MAE hat: 1.3964\n",
      "Iter: 838, Loss: 8.5721, Train MAE hat: 1.3956\n",
      "Iter: 839, Loss: 8.6020, Train MAE hat: 1.3948\n",
      "Iter: 840, Loss: 8.7204, Train MAE hat: 1.3940\n",
      "Iter: 841, Loss: 8.9569, Train MAE hat: 1.3933\n",
      "Iter: 842, Loss: 9.4010, Train MAE hat: 1.3925\n",
      "Iter: 843, Loss: 9.7952, Train MAE hat: 1.3918\n",
      "Iter: 844, Loss: 9.8175, Train MAE hat: 1.3910\n",
      "Iter: 845, Loss: 9.2190, Train MAE hat: 1.3903\n",
      "Iter: 846, Loss: 9.1897, Train MAE hat: 1.3895\n",
      "Iter: 847, Loss: 9.9146, Train MAE hat: 1.3888\n",
      "Iter: 848, Loss: 9.8230, Train MAE hat: 1.3881\n",
      "Iter: 849, Loss: 9.2840, Train MAE hat: 1.3874\n",
      "Iter: 850, Loss: 9.6159, Train MAE hat: 1.3867\n",
      "Iter: 851, Loss: 9.2774, Train MAE hat: 1.3859\n",
      "Iter: 852, Loss: 8.9486, Train MAE hat: 1.3852\n",
      "Iter: 853, Loss: 9.0880, Train MAE hat: 1.3845\n",
      "Iter: 854, Loss: 8.7856, Train MAE hat: 1.3837\n",
      "Iter: 855, Loss: 8.6707, Train MAE hat: 1.3830\n",
      "Iter: 856, Loss: 8.5787, Train MAE hat: 1.3822\n",
      "Iter: 857, Loss: 8.3577, Train MAE hat: 1.3815\n",
      "Iter: 858, Loss: 8.2702, Train MAE hat: 1.3807\n",
      "Iter: 859, Loss: 8.1321, Train MAE hat: 1.3800\n",
      "Iter: 860, Loss: 8.0156, Train MAE hat: 1.3792\n",
      "Iter: 861, Loss: 7.9560, Train MAE hat: 1.3785\n",
      "Iter: 862, Loss: 7.8229, Train MAE hat: 1.3777\n",
      "Iter: 863, Loss: 7.7602, Train MAE hat: 1.3769\n",
      "Iter: 864, Loss: 7.6509, Train MAE hat: 1.3761\n",
      "Iter: 865, Loss: 7.5746, Train MAE hat: 1.3754\n",
      "Iter: 866, Loss: 7.5072, Train MAE hat: 1.3746\n",
      "Iter: 867, Loss: 7.4360, Train MAE hat: 1.3738\n",
      "Iter: 868, Loss: 7.3687, Train MAE hat: 1.3730\n",
      "Iter: 869, Loss: 7.2997, Train MAE hat: 1.3723\n",
      "Iter: 870, Loss: 7.2409, Train MAE hat: 1.3715\n",
      "Iter: 871, Loss: 7.1775, Train MAE hat: 1.3707\n",
      "Iter: 872, Loss: 7.1196, Train MAE hat: 1.3699\n",
      "Iter: 873, Loss: 7.0587, Train MAE hat: 1.3691\n",
      "Iter: 874, Loss: 7.0079, Train MAE hat: 1.3683\n",
      "Iter: 875, Loss: 6.9532, Train MAE hat: 1.3675\n",
      "Iter: 876, Loss: 6.8994, Train MAE hat: 1.3668\n",
      "Iter: 877, Loss: 6.8501, Train MAE hat: 1.3660\n",
      "Iter: 878, Loss: 6.8017, Train MAE hat: 1.3652\n",
      "Iter: 879, Loss: 6.7525, Train MAE hat: 1.3644\n",
      "Iter: 880, Loss: 6.7063, Train MAE hat: 1.3636\n",
      "Iter: 881, Loss: 6.6611, Train MAE hat: 1.3628\n",
      "Iter: 882, Loss: 6.6199, Train MAE hat: 1.3620\n",
      "Iter: 883, Loss: 6.5808, Train MAE hat: 1.3612\n",
      "Iter: 884, Loss: 6.5493, Train MAE hat: 1.3604\n",
      "Iter: 885, Loss: 6.5297, Train MAE hat: 1.3596\n",
      "Iter: 886, Loss: 6.5315, Train MAE hat: 1.3589\n",
      "Iter: 887, Loss: 6.5726, Train MAE hat: 1.3581\n",
      "Iter: 888, Loss: 6.6999, Train MAE hat: 1.3573\n",
      "Iter: 889, Loss: 6.9478, Train MAE hat: 1.3565\n",
      "Iter: 890, Loss: 7.4054, Train MAE hat: 1.3558\n",
      "Iter: 891, Loss: 7.9056, Train MAE hat: 1.3551\n",
      "Iter: 892, Loss: 8.1412, Train MAE hat: 1.3544\n",
      "Iter: 893, Loss: 7.8235, Train MAE hat: 1.3537\n",
      "Iter: 894, Loss: 8.4466, Train MAE hat: 1.3530\n",
      "Iter: 895, Loss: 10.2581, Train MAE hat: 1.3523\n",
      "Iter: 896, Loss: 10.1964, Train MAE hat: 1.3517\n",
      "Iter: 897, Loss: 9.5881, Train MAE hat: 1.3511\n",
      "Iter: 898, Loss: 9.8319, Train MAE hat: 1.3505\n",
      "Iter: 899, Loss: 10.0470, Train MAE hat: 1.3499\n",
      "Iter: 900, Loss: 9.5570, Train MAE hat: 1.3492\n",
      "Iter: 901, Loss: 9.3323, Train MAE hat: 1.3486\n",
      "Iter: 902, Loss: 8.7452, Train MAE hat: 1.3480\n",
      "Iter: 903, Loss: 8.4273, Train MAE hat: 1.3474\n",
      "Iter: 904, Loss: 8.1176, Train MAE hat: 1.3467\n",
      "Iter: 905, Loss: 7.7794, Train MAE hat: 1.3461\n",
      "Iter: 906, Loss: 7.5660, Train MAE hat: 1.3454\n",
      "Iter: 907, Loss: 7.3479, Train MAE hat: 1.3447\n",
      "Iter: 908, Loss: 7.1543, Train MAE hat: 1.3440\n",
      "Iter: 909, Loss: 6.9677, Train MAE hat: 1.3433\n",
      "Iter: 910, Loss: 6.8047, Train MAE hat: 1.3426\n",
      "Iter: 911, Loss: 6.6707, Train MAE hat: 1.3419\n",
      "Iter: 912, Loss: 6.5114, Train MAE hat: 1.3412\n",
      "Iter: 913, Loss: 6.4094, Train MAE hat: 1.3405\n",
      "Iter: 914, Loss: 6.2726, Train MAE hat: 1.3397\n",
      "Iter: 915, Loss: 6.1804, Train MAE hat: 1.3390\n",
      "Iter: 916, Loss: 6.0748, Train MAE hat: 1.3383\n",
      "Iter: 917, Loss: 5.9757, Train MAE hat: 1.3375\n",
      "Iter: 918, Loss: 5.8912, Train MAE hat: 1.3368\n",
      "Iter: 919, Loss: 5.8070, Train MAE hat: 1.3361\n",
      "Iter: 920, Loss: 5.7319, Train MAE hat: 1.3353\n",
      "Iter: 921, Loss: 5.6562, Train MAE hat: 1.3346\n",
      "Iter: 922, Loss: 5.5873, Train MAE hat: 1.3338\n",
      "Iter: 923, Loss: 5.5173, Train MAE hat: 1.3331\n",
      "Iter: 924, Loss: 5.4584, Train MAE hat: 1.3323\n",
      "Iter: 925, Loss: 5.3937, Train MAE hat: 1.3315\n",
      "Iter: 926, Loss: 5.3384, Train MAE hat: 1.3308\n",
      "Iter: 927, Loss: 5.2847, Train MAE hat: 1.3300\n",
      "Iter: 928, Loss: 5.2277, Train MAE hat: 1.3293\n",
      "Iter: 929, Loss: 5.1798, Train MAE hat: 1.3285\n",
      "Iter: 930, Loss: 5.1286, Train MAE hat: 1.3277\n",
      "Iter: 931, Loss: 5.0823, Train MAE hat: 1.3270\n",
      "Iter: 932, Loss: 5.0348, Train MAE hat: 1.3262\n",
      "Iter: 933, Loss: 4.9907, Train MAE hat: 1.3254\n",
      "Iter: 934, Loss: 4.9483, Train MAE hat: 1.3246\n",
      "Iter: 935, Loss: 4.9051, Train MAE hat: 1.3239\n",
      "Iter: 936, Loss: 4.8647, Train MAE hat: 1.3231\n",
      "Iter: 937, Loss: 4.8249, Train MAE hat: 1.3223\n",
      "Iter: 938, Loss: 4.7863, Train MAE hat: 1.3215\n",
      "Iter: 939, Loss: 4.7480, Train MAE hat: 1.3208\n",
      "Iter: 940, Loss: 4.7111, Train MAE hat: 1.3200\n",
      "Iter: 941, Loss: 4.6748, Train MAE hat: 1.3192\n",
      "Iter: 942, Loss: 4.6392, Train MAE hat: 1.3184\n",
      "Iter: 943, Loss: 4.6048, Train MAE hat: 1.3177\n",
      "Iter: 944, Loss: 4.5706, Train MAE hat: 1.3169\n",
      "Iter: 945, Loss: 4.5380, Train MAE hat: 1.3161\n",
      "Iter: 946, Loss: 4.5063, Train MAE hat: 1.3153\n",
      "Iter: 947, Loss: 4.4765, Train MAE hat: 1.3145\n",
      "Iter: 948, Loss: 4.4491, Train MAE hat: 1.3138\n",
      "Iter: 949, Loss: 4.4272, Train MAE hat: 1.3130\n",
      "Iter: 950, Loss: 4.4136, Train MAE hat: 1.3122\n",
      "Iter: 951, Loss: 4.4159, Train MAE hat: 1.3114\n",
      "Iter: 952, Loss: 4.4442, Train MAE hat: 1.3107\n",
      "Iter: 953, Loss: 4.5194, Train MAE hat: 1.3099\n",
      "Iter: 954, Loss: 4.6514, Train MAE hat: 1.3091\n",
      "Iter: 955, Loss: 4.8463, Train MAE hat: 1.3084\n",
      "Iter: 956, Loss: 5.0111, Train MAE hat: 1.3077\n",
      "Iter: 957, Loss: 4.9963, Train MAE hat: 1.3069\n",
      "Iter: 958, Loss: 4.7095, Train MAE hat: 1.3062\n",
      "Iter: 959, Loss: 4.5011, Train MAE hat: 1.3055\n",
      "Iter: 960, Loss: 4.7269, Train MAE hat: 1.3047\n",
      "Iter: 961, Loss: 4.9747, Train MAE hat: 1.3040\n",
      "Iter: 962, Loss: 4.8293, Train MAE hat: 1.3033\n",
      "Iter: 963, Loss: 4.6135, Train MAE hat: 1.3026\n",
      "Iter: 964, Loss: 4.7906, Train MAE hat: 1.3018\n",
      "Iter: 965, Loss: 4.7892, Train MAE hat: 1.3011\n",
      "Iter: 966, Loss: 4.4662, Train MAE hat: 1.3004\n",
      "Iter: 967, Loss: 4.4778, Train MAE hat: 1.2996\n",
      "Iter: 968, Loss: 4.5603, Train MAE hat: 1.2989\n",
      "Iter: 969, Loss: 4.3246, Train MAE hat: 1.2982\n",
      "Iter: 970, Loss: 4.2929, Train MAE hat: 1.2974\n",
      "Iter: 971, Loss: 4.2717, Train MAE hat: 1.2967\n",
      "Iter: 972, Loss: 4.0790, Train MAE hat: 1.2959\n",
      "Iter: 973, Loss: 4.1221, Train MAE hat: 1.2952\n",
      "Iter: 974, Loss: 4.0618, Train MAE hat: 1.2945\n",
      "Iter: 975, Loss: 3.9167, Train MAE hat: 1.2937\n",
      "Iter: 976, Loss: 3.9617, Train MAE hat: 1.2929\n",
      "Iter: 977, Loss: 3.8763, Train MAE hat: 1.2922\n",
      "Iter: 978, Loss: 3.8221, Train MAE hat: 1.2914\n",
      "Iter: 979, Loss: 3.8131, Train MAE hat: 1.2907\n",
      "Iter: 980, Loss: 3.7250, Train MAE hat: 1.2899\n",
      "Iter: 981, Loss: 3.7279, Train MAE hat: 1.2892\n",
      "Iter: 982, Loss: 3.6799, Train MAE hat: 1.2884\n",
      "Iter: 983, Loss: 3.6273, Train MAE hat: 1.2876\n",
      "Iter: 984, Loss: 3.6230, Train MAE hat: 1.2869\n",
      "Iter: 985, Loss: 3.5759, Train MAE hat: 1.2861\n",
      "Iter: 986, Loss: 3.5541, Train MAE hat: 1.2853\n",
      "Iter: 987, Loss: 3.5234, Train MAE hat: 1.2846\n",
      "Iter: 988, Loss: 3.4975, Train MAE hat: 1.2838\n",
      "Iter: 989, Loss: 3.4865, Train MAE hat: 1.2831\n",
      "Iter: 990, Loss: 3.4580, Train MAE hat: 1.2823\n",
      "Iter: 991, Loss: 3.4545, Train MAE hat: 1.2815\n",
      "Iter: 992, Loss: 3.4606, Train MAE hat: 1.2808\n",
      "Iter: 993, Loss: 3.4837, Train MAE hat: 1.2800\n",
      "Iter: 994, Loss: 3.5396, Train MAE hat: 1.2793\n",
      "Iter: 995, Loss: 3.6315, Train MAE hat: 1.2785\n",
      "Iter: 996, Loss: 3.7512, Train MAE hat: 1.2778\n",
      "Iter: 997, Loss: 3.8702, Train MAE hat: 1.2770\n",
      "Iter: 998, Loss: 3.8844, Train MAE hat: 1.2763\n",
      "Iter: 999, Loss: 3.8091, Train MAE hat: 1.2756\n",
      "Iter: 1000, Loss: 3.8313, Train MAE hat: 1.2749\n",
      "Iter: 1001, Loss: 4.1714, Train MAE hat: 1.2742\n",
      "Iter: 1002, Loss: 4.6226, Train MAE hat: 1.2735\n",
      "Iter: 1003, Loss: 4.6784, Train MAE hat: 1.2728\n",
      "Iter: 1004, Loss: 4.2574, Train MAE hat: 1.2721\n",
      "Iter: 1005, Loss: 4.2425, Train MAE hat: 1.2714\n",
      "Iter: 1006, Loss: 4.4643, Train MAE hat: 1.2708\n",
      "Iter: 1007, Loss: 4.1575, Train MAE hat: 1.2701\n",
      "Iter: 1008, Loss: 3.9409, Train MAE hat: 1.2694\n",
      "Iter: 1009, Loss: 4.0376, Train MAE hat: 1.2687\n",
      "Iter: 1010, Loss: 3.8147, Train MAE hat: 1.2680\n",
      "Iter: 1011, Loss: 3.7145, Train MAE hat: 1.2673\n",
      "Iter: 1012, Loss: 3.7362, Train MAE hat: 1.2666\n",
      "Iter: 1013, Loss: 3.5333, Train MAE hat: 1.2659\n",
      "Iter: 1014, Loss: 3.4388, Train MAE hat: 1.2652\n",
      "Iter: 1015, Loss: 3.4103, Train MAE hat: 1.2644\n",
      "Iter: 1016, Loss: 3.2964, Train MAE hat: 1.2637\n",
      "Iter: 1017, Loss: 3.2584, Train MAE hat: 1.2630\n",
      "Iter: 1018, Loss: 3.1943, Train MAE hat: 1.2623\n",
      "Iter: 1019, Loss: 3.1303, Train MAE hat: 1.2615\n",
      "Iter: 1020, Loss: 3.1038, Train MAE hat: 1.2608\n",
      "Iter: 1021, Loss: 3.0271, Train MAE hat: 1.2601\n",
      "Iter: 1022, Loss: 3.0015, Train MAE hat: 1.2593\n",
      "Iter: 1023, Loss: 2.9498, Train MAE hat: 1.2586\n",
      "Iter: 1024, Loss: 2.9250, Train MAE hat: 1.2579\n",
      "Iter: 1025, Loss: 2.8942, Train MAE hat: 1.2571\n",
      "Iter: 1026, Loss: 2.8448, Train MAE hat: 1.2564\n",
      "Iter: 1027, Loss: 2.8265, Train MAE hat: 1.2556\n",
      "Iter: 1028, Loss: 2.7870, Train MAE hat: 1.2549\n",
      "Iter: 1029, Loss: 2.7630, Train MAE hat: 1.2541\n",
      "Iter: 1030, Loss: 2.7366, Train MAE hat: 1.2534\n",
      "Iter: 1031, Loss: 2.7033, Train MAE hat: 1.2526\n",
      "Iter: 1032, Loss: 2.6823, Train MAE hat: 1.2519\n",
      "Iter: 1033, Loss: 2.6550, Train MAE hat: 1.2511\n",
      "Iter: 1034, Loss: 2.6335, Train MAE hat: 1.2504\n",
      "Iter: 1035, Loss: 2.6089, Train MAE hat: 1.2496\n",
      "Iter: 1036, Loss: 2.5868, Train MAE hat: 1.2489\n",
      "Iter: 1037, Loss: 2.5680, Train MAE hat: 1.2481\n",
      "Iter: 1038, Loss: 2.5467, Train MAE hat: 1.2474\n",
      "Iter: 1039, Loss: 2.5298, Train MAE hat: 1.2466\n",
      "Iter: 1040, Loss: 2.5111, Train MAE hat: 1.2459\n",
      "Iter: 1041, Loss: 2.4995, Train MAE hat: 1.2451\n",
      "Iter: 1042, Loss: 2.4914, Train MAE hat: 1.2444\n",
      "Iter: 1043, Loss: 2.4940, Train MAE hat: 1.2436\n",
      "Iter: 1044, Loss: 2.5145, Train MAE hat: 1.2429\n",
      "Iter: 1045, Loss: 2.5675, Train MAE hat: 1.2421\n",
      "Iter: 1046, Loss: 2.6771, Train MAE hat: 1.2414\n",
      "Iter: 1047, Loss: 2.8802, Train MAE hat: 1.2407\n",
      "Iter: 1048, Loss: 3.1913, Train MAE hat: 1.2400\n",
      "Iter: 1049, Loss: 3.5325, Train MAE hat: 1.2393\n",
      "Iter: 1050, Loss: 3.6496, Train MAE hat: 1.2386\n",
      "Iter: 1051, Loss: 3.3417, Train MAE hat: 1.2380\n",
      "Iter: 1052, Loss: 3.3448, Train MAE hat: 1.2373\n",
      "Iter: 1053, Loss: 4.2247, Train MAE hat: 1.2366\n",
      "Iter: 1054, Loss: 5.0209, Train MAE hat: 1.2360\n",
      "Iter: 1055, Loss: 4.6411, Train MAE hat: 1.2354\n",
      "Iter: 1056, Loss: 4.2505, Train MAE hat: 1.2348\n",
      "Iter: 1057, Loss: 4.7558, Train MAE hat: 1.2342\n",
      "Iter: 1058, Loss: 4.4665, Train MAE hat: 1.2336\n",
      "Iter: 1059, Loss: 4.2771, Train MAE hat: 1.2330\n",
      "Iter: 1060, Loss: 4.2026, Train MAE hat: 1.2324\n",
      "Iter: 1061, Loss: 3.8712, Train MAE hat: 1.2318\n",
      "Iter: 1062, Loss: 3.7721, Train MAE hat: 1.2312\n",
      "Iter: 1063, Loss: 3.5684, Train MAE hat: 1.2305\n",
      "Iter: 1064, Loss: 3.3579, Train MAE hat: 1.2299\n",
      "Iter: 1065, Loss: 3.2494, Train MAE hat: 1.2292\n",
      "Iter: 1066, Loss: 3.0577, Train MAE hat: 1.2286\n",
      "Iter: 1067, Loss: 2.9750, Train MAE hat: 1.2279\n",
      "Iter: 1068, Loss: 2.8557, Train MAE hat: 1.2272\n",
      "Iter: 1069, Loss: 2.7892, Train MAE hat: 1.2265\n",
      "Iter: 1070, Loss: 2.6863, Train MAE hat: 1.2259\n",
      "Iter: 1071, Loss: 2.6248, Train MAE hat: 1.2252\n",
      "Iter: 1072, Loss: 2.5622, Train MAE hat: 1.2245\n",
      "Iter: 1073, Loss: 2.4920, Train MAE hat: 1.2238\n",
      "Iter: 1074, Loss: 2.4349, Train MAE hat: 1.2231\n",
      "Iter: 1075, Loss: 2.3868, Train MAE hat: 1.2224\n",
      "Iter: 1076, Loss: 2.3338, Train MAE hat: 1.2217\n",
      "Iter: 1077, Loss: 2.2952, Train MAE hat: 1.2210\n",
      "Iter: 1078, Loss: 2.2495, Train MAE hat: 1.2203\n",
      "Iter: 1079, Loss: 2.2145, Train MAE hat: 1.2195\n",
      "Iter: 1080, Loss: 2.1740, Train MAE hat: 1.2188\n",
      "Iter: 1081, Loss: 2.1409, Train MAE hat: 1.2181\n",
      "Iter: 1082, Loss: 2.1134, Train MAE hat: 1.2174\n",
      "Iter: 1083, Loss: 2.0809, Train MAE hat: 1.2167\n",
      "Iter: 1084, Loss: 2.0524, Train MAE hat: 1.2159\n",
      "Iter: 1085, Loss: 2.0267, Train MAE hat: 1.2152\n",
      "Iter: 1086, Loss: 2.0022, Train MAE hat: 1.2145\n",
      "Iter: 1087, Loss: 1.9756, Train MAE hat: 1.2138\n",
      "Iter: 1088, Loss: 1.9551, Train MAE hat: 1.2130\n",
      "Iter: 1089, Loss: 1.9329, Train MAE hat: 1.2123\n",
      "Iter: 1090, Loss: 1.9126, Train MAE hat: 1.2116\n",
      "Iter: 1091, Loss: 1.8926, Train MAE hat: 1.2108\n",
      "Iter: 1092, Loss: 1.8731, Train MAE hat: 1.2101\n",
      "Iter: 1093, Loss: 1.8541, Train MAE hat: 1.2094\n",
      "Iter: 1094, Loss: 1.8371, Train MAE hat: 1.2086\n",
      "Iter: 1095, Loss: 1.8205, Train MAE hat: 1.2079\n",
      "Iter: 1096, Loss: 1.8038, Train MAE hat: 1.2072\n",
      "Iter: 1097, Loss: 1.7875, Train MAE hat: 1.2064\n",
      "Iter: 1098, Loss: 1.7726, Train MAE hat: 1.2057\n",
      "Iter: 1099, Loss: 1.7572, Train MAE hat: 1.2050\n",
      "Iter: 1100, Loss: 1.7426, Train MAE hat: 1.2042\n",
      "Iter: 1101, Loss: 1.7286, Train MAE hat: 1.2035\n",
      "Iter: 1102, Loss: 1.7145, Train MAE hat: 1.2028\n",
      "Iter: 1103, Loss: 1.7013, Train MAE hat: 1.2020\n",
      "Iter: 1104, Loss: 1.6883, Train MAE hat: 1.2013\n",
      "Iter: 1105, Loss: 1.6754, Train MAE hat: 1.2006\n",
      "Iter: 1106, Loss: 1.6637, Train MAE hat: 1.1998\n",
      "Iter: 1107, Loss: 1.6526, Train MAE hat: 1.1991\n",
      "Iter: 1108, Loss: 1.6430, Train MAE hat: 1.1983\n",
      "Iter: 1109, Loss: 1.6368, Train MAE hat: 1.1976\n",
      "Iter: 1110, Loss: 1.6370, Train MAE hat: 1.1969\n",
      "Iter: 1111, Loss: 1.6505, Train MAE hat: 1.1961\n",
      "Iter: 1112, Loss: 1.6914, Train MAE hat: 1.1954\n",
      "Iter: 1113, Loss: 1.7829, Train MAE hat: 1.1947\n",
      "Iter: 1114, Loss: 1.9632, Train MAE hat: 1.1940\n",
      "Iter: 1115, Loss: 2.2525, Train MAE hat: 1.1933\n",
      "Iter: 1116, Loss: 2.5775, Train MAE hat: 1.1926\n",
      "Iter: 1117, Loss: 2.6827, Train MAE hat: 1.1920\n",
      "Iter: 1118, Loss: 2.4774, Train MAE hat: 1.1913\n",
      "Iter: 1119, Loss: 2.3269, Train MAE hat: 1.1907\n",
      "Iter: 1120, Loss: 2.5214, Train MAE hat: 1.1900\n",
      "Iter: 1121, Loss: 2.6672, Train MAE hat: 1.1894\n",
      "Iter: 1122, Loss: 2.6285, Train MAE hat: 1.1887\n",
      "Iter: 1123, Loss: 2.4609, Train MAE hat: 1.1881\n",
      "Iter: 1124, Loss: 2.2942, Train MAE hat: 1.1874\n",
      "Iter: 1125, Loss: 2.3914, Train MAE hat: 1.1868\n",
      "Iter: 1126, Loss: 2.3168, Train MAE hat: 1.1861\n",
      "Iter: 1127, Loss: 2.1644, Train MAE hat: 1.1855\n",
      "Iter: 1128, Loss: 2.1276, Train MAE hat: 1.1848\n",
      "Iter: 1129, Loss: 2.0312, Train MAE hat: 1.1841\n",
      "Iter: 1130, Loss: 1.9584, Train MAE hat: 1.1835\n",
      "Iter: 1131, Loss: 1.8930, Train MAE hat: 1.1828\n",
      "Iter: 1132, Loss: 1.8243, Train MAE hat: 1.1821\n",
      "Iter: 1133, Loss: 1.7819, Train MAE hat: 1.1814\n",
      "Iter: 1134, Loss: 1.7328, Train MAE hat: 1.1807\n",
      "Iter: 1135, Loss: 1.6813, Train MAE hat: 1.1800\n",
      "Iter: 1136, Loss: 1.6347, Train MAE hat: 1.1793\n",
      "Iter: 1137, Loss: 1.6098, Train MAE hat: 1.1786\n",
      "Iter: 1138, Loss: 1.5788, Train MAE hat: 1.1780\n",
      "Iter: 1139, Loss: 1.5509, Train MAE hat: 1.1772\n",
      "Iter: 1140, Loss: 1.5187, Train MAE hat: 1.1765\n",
      "Iter: 1141, Loss: 1.4899, Train MAE hat: 1.1758\n",
      "Iter: 1142, Loss: 1.4716, Train MAE hat: 1.1751\n",
      "Iter: 1143, Loss: 1.4468, Train MAE hat: 1.1744\n",
      "Iter: 1144, Loss: 1.4278, Train MAE hat: 1.1737\n",
      "Iter: 1145, Loss: 1.4100, Train MAE hat: 1.1730\n",
      "Iter: 1146, Loss: 1.3889, Train MAE hat: 1.1723\n",
      "Iter: 1147, Loss: 1.3750, Train MAE hat: 1.1716\n",
      "Iter: 1148, Loss: 1.3603, Train MAE hat: 1.1709\n",
      "Iter: 1149, Loss: 1.3428, Train MAE hat: 1.1702\n",
      "Iter: 1150, Loss: 1.3304, Train MAE hat: 1.1694\n",
      "Iter: 1151, Loss: 1.3141, Train MAE hat: 1.1687\n",
      "Iter: 1152, Loss: 1.3016, Train MAE hat: 1.1680\n",
      "Iter: 1153, Loss: 1.2900, Train MAE hat: 1.1673\n",
      "Iter: 1154, Loss: 1.2800, Train MAE hat: 1.1666\n",
      "Iter: 1155, Loss: 1.2691, Train MAE hat: 1.1658\n",
      "Iter: 1156, Loss: 1.2575, Train MAE hat: 1.1651\n",
      "Iter: 1157, Loss: 1.2504, Train MAE hat: 1.1644\n",
      "Iter: 1158, Loss: 1.2420, Train MAE hat: 1.1637\n",
      "Iter: 1159, Loss: 1.2365, Train MAE hat: 1.1630\n",
      "Iter: 1160, Loss: 1.2340, Train MAE hat: 1.1623\n",
      "Iter: 1161, Loss: 1.2379, Train MAE hat: 1.1615\n",
      "Iter: 1162, Loss: 1.2478, Train MAE hat: 1.1608\n",
      "Iter: 1163, Loss: 1.2732, Train MAE hat: 1.1601\n",
      "Iter: 1164, Loss: 1.3178, Train MAE hat: 1.1594\n",
      "Iter: 1165, Loss: 1.3983, Train MAE hat: 1.1587\n",
      "Iter: 1166, Loss: 1.5082, Train MAE hat: 1.1580\n",
      "Iter: 1167, Loss: 1.6598, Train MAE hat: 1.1574\n",
      "Iter: 1168, Loss: 1.7532, Train MAE hat: 1.1567\n",
      "Iter: 1169, Loss: 1.7354, Train MAE hat: 1.1560\n",
      "Iter: 1170, Loss: 1.5475, Train MAE hat: 1.1554\n",
      "Iter: 1171, Loss: 1.4581, Train MAE hat: 1.1547\n",
      "Iter: 1172, Loss: 1.6837, Train MAE hat: 1.1540\n",
      "Iter: 1173, Loss: 1.9773, Train MAE hat: 1.1534\n",
      "Iter: 1174, Loss: 2.0689, Train MAE hat: 1.1527\n",
      "Iter: 1175, Loss: 1.8878, Train MAE hat: 1.1521\n",
      "Iter: 1176, Loss: 1.8727, Train MAE hat: 1.1515\n",
      "Iter: 1177, Loss: 2.1108, Train MAE hat: 1.1508\n",
      "Iter: 1178, Loss: 2.1103, Train MAE hat: 1.1502\n",
      "Iter: 1179, Loss: 2.0291, Train MAE hat: 1.1496\n",
      "Iter: 1180, Loss: 2.2159, Train MAE hat: 1.1490\n",
      "Iter: 1181, Loss: 2.2026, Train MAE hat: 1.1484\n",
      "Iter: 1182, Loss: 1.8727, Train MAE hat: 1.1477\n",
      "Iter: 1183, Loss: 1.9231, Train MAE hat: 1.1471\n",
      "Iter: 1184, Loss: 2.0260, Train MAE hat: 1.1465\n",
      "Iter: 1185, Loss: 1.7312, Train MAE hat: 1.1459\n",
      "Iter: 1186, Loss: 1.6757, Train MAE hat: 1.1452\n",
      "Iter: 1187, Loss: 1.6855, Train MAE hat: 1.1446\n",
      "Iter: 1188, Loss: 1.4958, Train MAE hat: 1.1439\n",
      "Iter: 1189, Loss: 1.5185, Train MAE hat: 1.1433\n",
      "Iter: 1190, Loss: 1.4200, Train MAE hat: 1.1426\n",
      "Iter: 1191, Loss: 1.3054, Train MAE hat: 1.1420\n",
      "Iter: 1192, Loss: 1.3635, Train MAE hat: 1.1413\n",
      "Iter: 1193, Loss: 1.2503, Train MAE hat: 1.1406\n",
      "Iter: 1194, Loss: 1.2447, Train MAE hat: 1.1399\n",
      "Iter: 1195, Loss: 1.2356, Train MAE hat: 1.1393\n",
      "Iter: 1196, Loss: 1.1583, Train MAE hat: 1.1386\n",
      "Iter: 1197, Loss: 1.1838, Train MAE hat: 1.1379\n",
      "Iter: 1198, Loss: 1.1280, Train MAE hat: 1.1372\n",
      "Iter: 1199, Loss: 1.1187, Train MAE hat: 1.1365\n",
      "Iter: 1200, Loss: 1.1053, Train MAE hat: 1.1358\n",
      "Iter: 1201, Loss: 1.0665, Train MAE hat: 1.1352\n",
      "Iter: 1202, Loss: 1.0718, Train MAE hat: 1.1345\n",
      "Iter: 1203, Loss: 1.0379, Train MAE hat: 1.1338\n",
      "Iter: 1204, Loss: 1.0311, Train MAE hat: 1.1331\n",
      "Iter: 1205, Loss: 1.0191, Train MAE hat: 1.1324\n",
      "Iter: 1206, Loss: 1.0012, Train MAE hat: 1.1317\n",
      "Iter: 1207, Loss: 0.9941, Train MAE hat: 1.1310\n",
      "Iter: 1208, Loss: 0.9763, Train MAE hat: 1.1303\n",
      "Iter: 1209, Loss: 0.9707, Train MAE hat: 1.1296\n",
      "Iter: 1210, Loss: 0.9586, Train MAE hat: 1.1289\n",
      "Iter: 1211, Loss: 0.9479, Train MAE hat: 1.1282\n",
      "Iter: 1212, Loss: 0.9405, Train MAE hat: 1.1275\n",
      "Iter: 1213, Loss: 0.9290, Train MAE hat: 1.1268\n",
      "Iter: 1214, Loss: 0.9223, Train MAE hat: 1.1261\n",
      "Iter: 1215, Loss: 0.9132, Train MAE hat: 1.1254\n",
      "Iter: 1216, Loss: 0.9058, Train MAE hat: 1.1247\n",
      "Iter: 1217, Loss: 0.8988, Train MAE hat: 1.1240\n",
      "Iter: 1218, Loss: 0.8903, Train MAE hat: 1.1233\n",
      "Iter: 1219, Loss: 0.8848, Train MAE hat: 1.1226\n",
      "Iter: 1220, Loss: 0.8774, Train MAE hat: 1.1219\n",
      "Iter: 1221, Loss: 0.8713, Train MAE hat: 1.1212\n",
      "Iter: 1222, Loss: 0.8650, Train MAE hat: 1.1205\n",
      "Iter: 1223, Loss: 0.8590, Train MAE hat: 1.1198\n",
      "Iter: 1224, Loss: 0.8540, Train MAE hat: 1.1191\n",
      "Iter: 1225, Loss: 0.8489, Train MAE hat: 1.1184\n",
      "Iter: 1226, Loss: 0.8452, Train MAE hat: 1.1177\n",
      "Iter: 1227, Loss: 0.8422, Train MAE hat: 1.1170\n",
      "Iter: 1228, Loss: 0.8427, Train MAE hat: 1.1163\n",
      "Iter: 1229, Loss: 0.8475, Train MAE hat: 1.1156\n",
      "Iter: 1230, Loss: 0.8611, Train MAE hat: 1.1149\n",
      "Iter: 1231, Loss: 0.8914, Train MAE hat: 1.1142\n",
      "Iter: 1232, Loss: 0.9523, Train MAE hat: 1.1135\n",
      "Iter: 1233, Loss: 1.0693, Train MAE hat: 1.1129\n",
      "Iter: 1234, Loss: 1.2816, Train MAE hat: 1.1122\n",
      "Iter: 1235, Loss: 1.6365, Train MAE hat: 1.1116\n",
      "Iter: 1236, Loss: 2.1194, Train MAE hat: 1.1110\n",
      "Iter: 1237, Loss: 2.4995, Train MAE hat: 1.1104\n",
      "Iter: 1238, Loss: 2.3538, Train MAE hat: 1.1099\n",
      "Iter: 1239, Loss: 2.0946, Train MAE hat: 1.1093\n",
      "Iter: 1240, Loss: 2.9230, Train MAE hat: 1.1088\n",
      "Iter: 1241, Loss: 4.3026, Train MAE hat: 1.1083\n",
      "Iter: 1242, Loss: 3.7849, Train MAE hat: 1.1078\n",
      "Iter: 1243, Loss: 2.9383, Train MAE hat: 1.1073\n",
      "Iter: 1244, Loss: 3.7047, Train MAE hat: 1.1068\n",
      "Iter: 1245, Loss: 3.4137, Train MAE hat: 1.1063\n",
      "Iter: 1246, Loss: 3.1273, Train MAE hat: 1.1058\n",
      "Iter: 1247, Loss: 3.2535, Train MAE hat: 1.1053\n",
      "Iter: 1248, Loss: 2.7642, Train MAE hat: 1.1048\n",
      "Iter: 1249, Loss: 2.6887, Train MAE hat: 1.1043\n",
      "Iter: 1250, Loss: 2.4173, Train MAE hat: 1.1038\n",
      "Iter: 1251, Loss: 2.1518, Train MAE hat: 1.1032\n",
      "Iter: 1252, Loss: 2.0734, Train MAE hat: 1.1027\n",
      "Iter: 1253, Loss: 1.8667, Train MAE hat: 1.1021\n",
      "Iter: 1254, Loss: 1.7877, Train MAE hat: 1.1015\n",
      "Iter: 1255, Loss: 1.6370, Train MAE hat: 1.1010\n",
      "Iter: 1256, Loss: 1.5817, Train MAE hat: 1.1004\n",
      "Iter: 1257, Loss: 1.4832, Train MAE hat: 1.0998\n",
      "Iter: 1258, Loss: 1.4008, Train MAE hat: 1.0992\n",
      "Iter: 1259, Loss: 1.3378, Train MAE hat: 1.0986\n",
      "Iter: 1260, Loss: 1.2796, Train MAE hat: 1.0980\n",
      "Iter: 1261, Loss: 1.2222, Train MAE hat: 1.0973\n",
      "Iter: 1262, Loss: 1.1655, Train MAE hat: 1.0967\n",
      "Iter: 1263, Loss: 1.1242, Train MAE hat: 1.0961\n",
      "Iter: 1264, Loss: 1.0877, Train MAE hat: 1.0955\n",
      "Iter: 1265, Loss: 1.0467, Train MAE hat: 1.0948\n",
      "Iter: 1266, Loss: 1.0078, Train MAE hat: 1.0942\n",
      "Iter: 1267, Loss: 0.9836, Train MAE hat: 1.0936\n",
      "Iter: 1268, Loss: 0.9520, Train MAE hat: 1.0929\n",
      "Iter: 1269, Loss: 0.9252, Train MAE hat: 1.0923\n",
      "Iter: 1270, Loss: 0.9033, Train MAE hat: 1.0916\n",
      "Iter: 1271, Loss: 0.8817, Train MAE hat: 1.0910\n",
      "Iter: 1272, Loss: 0.8583, Train MAE hat: 1.0903\n",
      "Iter: 1273, Loss: 0.8433, Train MAE hat: 1.0897\n",
      "Iter: 1274, Loss: 0.8244, Train MAE hat: 1.0890\n",
      "Iter: 1275, Loss: 0.8093, Train MAE hat: 1.0884\n",
      "Iter: 1276, Loss: 0.7931, Train MAE hat: 1.0877\n",
      "Iter: 1277, Loss: 0.7817, Train MAE hat: 1.0871\n",
      "Iter: 1278, Loss: 0.7675, Train MAE hat: 1.0864\n",
      "Iter: 1279, Loss: 0.7561, Train MAE hat: 1.0857\n",
      "Iter: 1280, Loss: 0.7448, Train MAE hat: 1.0851\n",
      "Iter: 1281, Loss: 0.7346, Train MAE hat: 1.0844\n",
      "Iter: 1282, Loss: 0.7255, Train MAE hat: 1.0837\n",
      "Iter: 1283, Loss: 0.7158, Train MAE hat: 1.0831\n",
      "Iter: 1284, Loss: 0.7073, Train MAE hat: 1.0824\n",
      "Iter: 1285, Loss: 0.6995, Train MAE hat: 1.0817\n",
      "Iter: 1286, Loss: 0.6916, Train MAE hat: 1.0811\n",
      "Iter: 1287, Loss: 0.6848, Train MAE hat: 1.0804\n",
      "Iter: 1288, Loss: 0.6779, Train MAE hat: 1.0797\n",
      "Iter: 1289, Loss: 0.6706, Train MAE hat: 1.0790\n",
      "Iter: 1290, Loss: 0.6651, Train MAE hat: 1.0784\n",
      "Iter: 1291, Loss: 0.6590, Train MAE hat: 1.0777\n",
      "Iter: 1292, Loss: 0.6533, Train MAE hat: 1.0770\n",
      "Iter: 1293, Loss: 0.6477, Train MAE hat: 1.0764\n",
      "Iter: 1294, Loss: 0.6430, Train MAE hat: 1.0757\n",
      "Iter: 1295, Loss: 0.6378, Train MAE hat: 1.0750\n",
      "Iter: 1296, Loss: 0.6329, Train MAE hat: 1.0743\n",
      "Iter: 1297, Loss: 0.6281, Train MAE hat: 1.0737\n",
      "Iter: 1298, Loss: 0.6239, Train MAE hat: 1.0730\n",
      "Iter: 1299, Loss: 0.6194, Train MAE hat: 1.0723\n",
      "Iter: 1300, Loss: 0.6152, Train MAE hat: 1.0716\n",
      "Iter: 1301, Loss: 0.6110, Train MAE hat: 1.0710\n",
      "Iter: 1302, Loss: 0.6072, Train MAE hat: 1.0703\n",
      "Iter: 1303, Loss: 0.6033, Train MAE hat: 1.0696\n",
      "Iter: 1304, Loss: 0.5997, Train MAE hat: 1.0689\n",
      "Iter: 1305, Loss: 0.5964, Train MAE hat: 1.0683\n",
      "Iter: 1306, Loss: 0.5933, Train MAE hat: 1.0676\n",
      "Iter: 1307, Loss: 0.5908, Train MAE hat: 1.0669\n",
      "Iter: 1308, Loss: 0.5893, Train MAE hat: 1.0663\n",
      "Iter: 1309, Loss: 0.5895, Train MAE hat: 1.0656\n",
      "Iter: 1310, Loss: 0.5929, Train MAE hat: 1.0649\n",
      "Iter: 1311, Loss: 0.6016, Train MAE hat: 1.0642\n",
      "Iter: 1312, Loss: 0.6198, Train MAE hat: 1.0636\n",
      "Iter: 1313, Loss: 0.6541, Train MAE hat: 1.0629\n",
      "Iter: 1314, Loss: 0.7136, Train MAE hat: 1.0623\n",
      "Iter: 1315, Loss: 0.8101, Train MAE hat: 1.0616\n",
      "Iter: 1316, Loss: 0.9475, Train MAE hat: 1.0610\n",
      "Iter: 1317, Loss: 1.1056, Train MAE hat: 1.0604\n",
      "Iter: 1318, Loss: 1.2090, Train MAE hat: 1.0598\n",
      "Iter: 1319, Loss: 1.1598, Train MAE hat: 1.0592\n",
      "Iter: 1320, Loss: 1.0116, Train MAE hat: 1.0586\n",
      "Iter: 1321, Loss: 1.0388, Train MAE hat: 1.0580\n",
      "Iter: 1322, Loss: 1.3355, Train MAE hat: 1.0574\n",
      "Iter: 1323, Loss: 1.5979, Train MAE hat: 1.0568\n",
      "Iter: 1324, Loss: 1.5836, Train MAE hat: 1.0563\n",
      "Iter: 1325, Loss: 1.4576, Train MAE hat: 1.0557\n",
      "Iter: 1326, Loss: 1.4213, Train MAE hat: 1.0551\n",
      "Iter: 1327, Loss: 1.3816, Train MAE hat: 1.0546\n",
      "Iter: 1328, Loss: 1.2000, Train MAE hat: 1.0540\n",
      "Iter: 1329, Loss: 1.1843, Train MAE hat: 1.0534\n",
      "Iter: 1330, Loss: 1.1109, Train MAE hat: 1.0528\n",
      "Iter: 1331, Loss: 0.9613, Train MAE hat: 1.0523\n",
      "Iter: 1332, Loss: 0.9304, Train MAE hat: 1.0517\n",
      "Iter: 1333, Loss: 0.8778, Train MAE hat: 1.0510\n",
      "Iter: 1334, Loss: 0.8636, Train MAE hat: 1.0504\n",
      "Iter: 1335, Loss: 0.8085, Train MAE hat: 1.0498\n",
      "Iter: 1336, Loss: 0.7466, Train MAE hat: 1.0492\n",
      "Iter: 1337, Loss: 0.7685, Train MAE hat: 1.0486\n",
      "Iter: 1338, Loss: 0.7089, Train MAE hat: 1.0480\n",
      "Iter: 1339, Loss: 0.7021, Train MAE hat: 1.0473\n",
      "Iter: 1340, Loss: 0.6795, Train MAE hat: 1.0467\n",
      "Iter: 1341, Loss: 0.6510, Train MAE hat: 1.0461\n",
      "Iter: 1342, Loss: 0.6520, Train MAE hat: 1.0455\n",
      "Iter: 1343, Loss: 0.6202, Train MAE hat: 1.0448\n",
      "Iter: 1344, Loss: 0.6141, Train MAE hat: 1.0442\n",
      "Iter: 1345, Loss: 0.6014, Train MAE hat: 1.0436\n",
      "Iter: 1346, Loss: 0.5870, Train MAE hat: 1.0429\n",
      "Iter: 1347, Loss: 0.5771, Train MAE hat: 1.0423\n",
      "Iter: 1348, Loss: 0.5690, Train MAE hat: 1.0416\n",
      "Iter: 1349, Loss: 0.5575, Train MAE hat: 1.0410\n",
      "Iter: 1350, Loss: 0.5519, Train MAE hat: 1.0403\n",
      "Iter: 1351, Loss: 0.5404, Train MAE hat: 1.0397\n",
      "Iter: 1352, Loss: 0.5358, Train MAE hat: 1.0391\n",
      "Iter: 1353, Loss: 0.5285, Train MAE hat: 1.0384\n",
      "Iter: 1354, Loss: 0.5222, Train MAE hat: 1.0378\n",
      "Iter: 1355, Loss: 0.5160, Train MAE hat: 1.0371\n",
      "Iter: 1356, Loss: 0.5104, Train MAE hat: 1.0365\n",
      "Iter: 1357, Loss: 0.5060, Train MAE hat: 1.0358\n",
      "Iter: 1358, Loss: 0.5000, Train MAE hat: 1.0352\n",
      "Iter: 1359, Loss: 0.4971, Train MAE hat: 1.0345\n",
      "Iter: 1360, Loss: 0.4911, Train MAE hat: 1.0339\n",
      "Iter: 1361, Loss: 0.4878, Train MAE hat: 1.0332\n",
      "Iter: 1362, Loss: 0.4837, Train MAE hat: 1.0326\n",
      "Iter: 1363, Loss: 0.4801, Train MAE hat: 1.0319\n",
      "Iter: 1364, Loss: 0.4767, Train MAE hat: 1.0313\n",
      "Iter: 1365, Loss: 0.4730, Train MAE hat: 1.0306\n",
      "Iter: 1366, Loss: 0.4699, Train MAE hat: 1.0300\n",
      "Iter: 1367, Loss: 0.4669, Train MAE hat: 1.0293\n",
      "Iter: 1368, Loss: 0.4637, Train MAE hat: 1.0287\n",
      "Iter: 1369, Loss: 0.4612, Train MAE hat: 1.0280\n",
      "Iter: 1370, Loss: 0.4581, Train MAE hat: 1.0274\n",
      "Iter: 1371, Loss: 0.4557, Train MAE hat: 1.0267\n",
      "Iter: 1372, Loss: 0.4531, Train MAE hat: 1.0261\n",
      "Iter: 1373, Loss: 0.4505, Train MAE hat: 1.0254\n",
      "Iter: 1374, Loss: 0.4484, Train MAE hat: 1.0248\n",
      "Iter: 1375, Loss: 0.4461, Train MAE hat: 1.0241\n",
      "Iter: 1376, Loss: 0.4444, Train MAE hat: 1.0235\n",
      "Iter: 1377, Loss: 0.4430, Train MAE hat: 1.0228\n",
      "Iter: 1378, Loss: 0.4424, Train MAE hat: 1.0222\n",
      "Iter: 1379, Loss: 0.4433, Train MAE hat: 1.0215\n",
      "Iter: 1380, Loss: 0.4468, Train MAE hat: 1.0209\n",
      "Iter: 1381, Loss: 0.4554, Train MAE hat: 1.0202\n",
      "Iter: 1382, Loss: 0.4731, Train MAE hat: 1.0196\n",
      "Iter: 1383, Loss: 0.5073, Train MAE hat: 1.0190\n",
      "Iter: 1384, Loss: 0.5697, Train MAE hat: 1.0183\n",
      "Iter: 1385, Loss: 0.6777, Train MAE hat: 1.0177\n",
      "Iter: 1386, Loss: 0.8489, Train MAE hat: 1.0171\n",
      "Iter: 1387, Loss: 1.0754, Train MAE hat: 1.0166\n",
      "Iter: 1388, Loss: 1.2608, Train MAE hat: 1.0160\n",
      "Iter: 1389, Loss: 1.2047, Train MAE hat: 1.0155\n",
      "Iter: 1390, Loss: 0.8469, Train MAE hat: 1.0149\n",
      "Iter: 1391, Loss: 0.6981, Train MAE hat: 1.0143\n",
      "Iter: 1392, Loss: 0.9928, Train MAE hat: 1.0137\n",
      "Iter: 1393, Loss: 1.1696, Train MAE hat: 1.0132\n",
      "Iter: 1394, Loss: 1.0282, Train MAE hat: 1.0126\n",
      "Iter: 1395, Loss: 1.0386, Train MAE hat: 1.0121\n",
      "Iter: 1396, Loss: 1.1918, Train MAE hat: 1.0115\n",
      "Iter: 1397, Loss: 1.0766, Train MAE hat: 1.0110\n",
      "Iter: 1398, Loss: 0.9397, Train MAE hat: 1.0104\n",
      "Iter: 1399, Loss: 0.9762, Train MAE hat: 1.0099\n",
      "Iter: 1400, Loss: 0.9378, Train MAE hat: 1.0093\n",
      "Iter: 1401, Loss: 0.9082, Train MAE hat: 1.0087\n",
      "Iter: 1402, Loss: 0.8395, Train MAE hat: 1.0082\n",
      "Iter: 1403, Loss: 0.8204, Train MAE hat: 1.0076\n",
      "Iter: 1404, Loss: 0.7878, Train MAE hat: 1.0070\n",
      "Iter: 1405, Loss: 0.6991, Train MAE hat: 1.0065\n",
      "Iter: 1406, Loss: 0.6713, Train MAE hat: 1.0059\n",
      "Iter: 1407, Loss: 0.6235, Train MAE hat: 1.0053\n",
      "Iter: 1408, Loss: 0.6150, Train MAE hat: 1.0047\n",
      "Iter: 1409, Loss: 0.5865, Train MAE hat: 1.0041\n",
      "Iter: 1410, Loss: 0.5663, Train MAE hat: 1.0035\n",
      "Iter: 1411, Loss: 0.5451, Train MAE hat: 1.0029\n",
      "Iter: 1412, Loss: 0.5339, Train MAE hat: 1.0023\n",
      "Iter: 1413, Loss: 0.5117, Train MAE hat: 1.0017\n",
      "Iter: 1414, Loss: 0.5001, Train MAE hat: 1.0011\n",
      "Iter: 1415, Loss: 0.4930, Train MAE hat: 1.0005\n",
      "Iter: 1416, Loss: 0.4777, Train MAE hat: 0.9999\n",
      "Iter: 1417, Loss: 0.4639, Train MAE hat: 0.9992\n",
      "Iter: 1418, Loss: 0.4568, Train MAE hat: 0.9986\n",
      "Iter: 1419, Loss: 0.4504, Train MAE hat: 0.9980\n",
      "Iter: 1420, Loss: 0.4406, Train MAE hat: 0.9974\n",
      "Iter: 1421, Loss: 0.4335, Train MAE hat: 0.9968\n",
      "Iter: 1422, Loss: 0.4281, Train MAE hat: 0.9962\n",
      "Iter: 1423, Loss: 0.4226, Train MAE hat: 0.9955\n",
      "Iter: 1424, Loss: 0.4161, Train MAE hat: 0.9949\n",
      "Iter: 1425, Loss: 0.4107, Train MAE hat: 0.9943\n",
      "Iter: 1426, Loss: 0.4066, Train MAE hat: 0.9937\n",
      "Iter: 1427, Loss: 0.4031, Train MAE hat: 0.9931\n",
      "Iter: 1428, Loss: 0.3987, Train MAE hat: 0.9924\n",
      "Iter: 1429, Loss: 0.3952, Train MAE hat: 0.9918\n",
      "Iter: 1430, Loss: 0.3930, Train MAE hat: 0.9912\n",
      "Iter: 1431, Loss: 0.3898, Train MAE hat: 0.9906\n",
      "Iter: 1432, Loss: 0.3885, Train MAE hat: 0.9899\n",
      "Iter: 1433, Loss: 0.3879, Train MAE hat: 0.9893\n",
      "Iter: 1434, Loss: 0.3885, Train MAE hat: 0.9887\n",
      "Iter: 1435, Loss: 0.3914, Train MAE hat: 0.9881\n",
      "Iter: 1436, Loss: 0.3979, Train MAE hat: 0.9875\n",
      "Iter: 1437, Loss: 0.4092, Train MAE hat: 0.9868\n",
      "Iter: 1438, Loss: 0.4287, Train MAE hat: 0.9862\n",
      "Iter: 1439, Loss: 0.4607, Train MAE hat: 0.9856\n",
      "Iter: 1440, Loss: 0.5091, Train MAE hat: 0.9850\n",
      "Iter: 1441, Loss: 0.5816, Train MAE hat: 0.9844\n",
      "Iter: 1442, Loss: 0.6726, Train MAE hat: 0.9839\n",
      "Iter: 1443, Loss: 0.7710, Train MAE hat: 0.9833\n",
      "Iter: 1444, Loss: 0.8179, Train MAE hat: 0.9827\n",
      "Iter: 1445, Loss: 0.7639, Train MAE hat: 0.9822\n",
      "Iter: 1446, Loss: 0.6259, Train MAE hat: 0.9816\n",
      "Iter: 1447, Loss: 0.6050, Train MAE hat: 0.9810\n",
      "Iter: 1448, Loss: 0.7972, Train MAE hat: 0.9805\n",
      "Iter: 1449, Loss: 1.0526, Train MAE hat: 0.9799\n",
      "Iter: 1450, Loss: 1.1217, Train MAE hat: 0.9794\n",
      "Iter: 1451, Loss: 0.9757, Train MAE hat: 0.9789\n",
      "Iter: 1452, Loss: 0.8475, Train MAE hat: 0.9783\n",
      "Iter: 1453, Loss: 0.9229, Train MAE hat: 0.9778\n",
      "Iter: 1454, Loss: 0.9684, Train MAE hat: 0.9773\n",
      "Iter: 1455, Loss: 0.8492, Train MAE hat: 0.9767\n",
      "Iter: 1456, Loss: 0.8632, Train MAE hat: 0.9762\n",
      "Iter: 1457, Loss: 0.9746, Train MAE hat: 0.9756\n",
      "Iter: 1458, Loss: 0.9044, Train MAE hat: 0.9751\n",
      "Iter: 1459, Loss: 0.7981, Train MAE hat: 0.9746\n",
      "Iter: 1460, Loss: 0.9098, Train MAE hat: 0.9740\n",
      "Iter: 1461, Loss: 0.9189, Train MAE hat: 0.9735\n",
      "Iter: 1462, Loss: 0.7363, Train MAE hat: 0.9730\n",
      "Iter: 1463, Loss: 0.7329, Train MAE hat: 0.9724\n",
      "Iter: 1464, Loss: 0.7472, Train MAE hat: 0.9719\n",
      "Iter: 1465, Loss: 0.6288, Train MAE hat: 0.9713\n",
      "Iter: 1466, Loss: 0.6203, Train MAE hat: 0.9707\n",
      "Iter: 1467, Loss: 0.5944, Train MAE hat: 0.9702\n",
      "Iter: 1468, Loss: 0.5060, Train MAE hat: 0.9696\n",
      "Iter: 1469, Loss: 0.5393, Train MAE hat: 0.9690\n",
      "Iter: 1470, Loss: 0.5229, Train MAE hat: 0.9685\n",
      "Iter: 1471, Loss: 0.4556, Train MAE hat: 0.9679\n",
      "Iter: 1472, Loss: 0.4760, Train MAE hat: 0.9673\n",
      "Iter: 1473, Loss: 0.4526, Train MAE hat: 0.9667\n",
      "Iter: 1474, Loss: 0.4248, Train MAE hat: 0.9661\n",
      "Iter: 1475, Loss: 0.4350, Train MAE hat: 0.9655\n",
      "Iter: 1476, Loss: 0.4048, Train MAE hat: 0.9650\n",
      "Iter: 1477, Loss: 0.4014, Train MAE hat: 0.9644\n",
      "Iter: 1478, Loss: 0.4022, Train MAE hat: 0.9638\n",
      "Iter: 1479, Loss: 0.3785, Train MAE hat: 0.9632\n",
      "Iter: 1480, Loss: 0.3825, Train MAE hat: 0.9626\n",
      "Iter: 1481, Loss: 0.3723, Train MAE hat: 0.9620\n",
      "Iter: 1482, Loss: 0.3596, Train MAE hat: 0.9614\n",
      "Iter: 1483, Loss: 0.3642, Train MAE hat: 0.9608\n",
      "Iter: 1484, Loss: 0.3525, Train MAE hat: 0.9602\n",
      "Iter: 1485, Loss: 0.3494, Train MAE hat: 0.9596\n",
      "Iter: 1486, Loss: 0.3488, Train MAE hat: 0.9590\n",
      "Iter: 1487, Loss: 0.3386, Train MAE hat: 0.9584\n",
      "Iter: 1488, Loss: 0.3388, Train MAE hat: 0.9578\n",
      "Iter: 1489, Loss: 0.3356, Train MAE hat: 0.9572\n",
      "Iter: 1490, Loss: 0.3311, Train MAE hat: 0.9566\n",
      "Iter: 1491, Loss: 0.3301, Train MAE hat: 0.9560\n",
      "Iter: 1492, Loss: 0.3247, Train MAE hat: 0.9554\n",
      "Iter: 1493, Loss: 0.3234, Train MAE hat: 0.9548\n",
      "Iter: 1494, Loss: 0.3220, Train MAE hat: 0.9542\n",
      "Iter: 1495, Loss: 0.3180, Train MAE hat: 0.9536\n",
      "Iter: 1496, Loss: 0.3168, Train MAE hat: 0.9530\n",
      "Iter: 1497, Loss: 0.3147, Train MAE hat: 0.9524\n",
      "Iter: 1498, Loss: 0.3130, Train MAE hat: 0.9518\n",
      "Iter: 1499, Loss: 0.3121, Train MAE hat: 0.9512\n",
      "Iter: 1500, Loss: 0.3104, Train MAE hat: 0.9506\n",
      "Iter: 1501, Loss: 0.3100, Train MAE hat: 0.9499\n",
      "Iter: 1502, Loss: 0.3102, Train MAE hat: 0.9493\n",
      "Iter: 1503, Loss: 0.3113, Train MAE hat: 0.9487\n",
      "Iter: 1504, Loss: 0.3145, Train MAE hat: 0.9481\n",
      "Iter: 1505, Loss: 0.3202, Train MAE hat: 0.9475\n",
      "Iter: 1506, Loss: 0.3309, Train MAE hat: 0.9469\n",
      "Iter: 1507, Loss: 0.3486, Train MAE hat: 0.9464\n",
      "Iter: 1508, Loss: 0.3786, Train MAE hat: 0.9458\n",
      "Iter: 1509, Loss: 0.4262, Train MAE hat: 0.9452\n",
      "Iter: 1510, Loss: 0.5036, Train MAE hat: 0.9446\n",
      "Iter: 1511, Loss: 0.6132, Train MAE hat: 0.9441\n",
      "Iter: 1512, Loss: 0.7672, Train MAE hat: 0.9435\n",
      "Iter: 1513, Loss: 0.9078, Train MAE hat: 0.9430\n",
      "Iter: 1514, Loss: 0.9654, Train MAE hat: 0.9425\n",
      "Iter: 1515, Loss: 0.8298, Train MAE hat: 0.9420\n",
      "Iter: 1516, Loss: 0.6863, Train MAE hat: 0.9415\n",
      "Iter: 1517, Loss: 0.8715, Train MAE hat: 0.9410\n",
      "Iter: 1518, Loss: 1.3022, Train MAE hat: 0.9405\n",
      "Iter: 1519, Loss: 1.5679, Train MAE hat: 0.9400\n",
      "Iter: 1520, Loss: 1.4450, Train MAE hat: 0.9395\n",
      "Iter: 1521, Loss: 1.4444, Train MAE hat: 0.9391\n",
      "Iter: 1522, Loss: 1.6800, Train MAE hat: 0.9386\n",
      "Iter: 1523, Loss: 1.7108, Train MAE hat: 0.9382\n",
      "Iter: 1524, Loss: 1.7670, Train MAE hat: 0.9377\n",
      "Iter: 1525, Loss: 1.6605, Train MAE hat: 0.9373\n",
      "Iter: 1526, Loss: 1.6254, Train MAE hat: 0.9369\n",
      "Iter: 1527, Loss: 1.6045, Train MAE hat: 0.9364\n",
      "Iter: 1528, Loss: 1.4872, Train MAE hat: 0.9360\n",
      "Iter: 1529, Loss: 1.4209, Train MAE hat: 0.9355\n",
      "Iter: 1530, Loss: 1.3246, Train MAE hat: 0.9351\n",
      "Iter: 1531, Loss: 1.2373, Train MAE hat: 0.9346\n",
      "Iter: 1532, Loss: 1.1355, Train MAE hat: 0.9341\n",
      "Iter: 1533, Loss: 0.9870, Train MAE hat: 0.9336\n",
      "Iter: 1534, Loss: 0.9185, Train MAE hat: 0.9331\n",
      "Iter: 1535, Loss: 0.8329, Train MAE hat: 0.9326\n",
      "Iter: 1536, Loss: 0.7598, Train MAE hat: 0.9321\n",
      "Iter: 1537, Loss: 0.7185, Train MAE hat: 0.9316\n",
      "Iter: 1538, Loss: 0.6712, Train MAE hat: 0.9311\n",
      "Iter: 1539, Loss: 0.6448, Train MAE hat: 0.9306\n",
      "Iter: 1540, Loss: 0.5895, Train MAE hat: 0.9301\n",
      "Iter: 1541, Loss: 0.5628, Train MAE hat: 0.9296\n",
      "Iter: 1542, Loss: 0.5367, Train MAE hat: 0.9290\n",
      "Iter: 1543, Loss: 0.5075, Train MAE hat: 0.9285\n",
      "Iter: 1544, Loss: 0.4899, Train MAE hat: 0.9279\n",
      "Iter: 1545, Loss: 0.4660, Train MAE hat: 0.9274\n",
      "Iter: 1546, Loss: 0.4423, Train MAE hat: 0.9269\n",
      "Iter: 1547, Loss: 0.4311, Train MAE hat: 0.9263\n",
      "Iter: 1548, Loss: 0.4123, Train MAE hat: 0.9258\n",
      "Iter: 1549, Loss: 0.4031, Train MAE hat: 0.9252\n",
      "Iter: 1550, Loss: 0.3857, Train MAE hat: 0.9247\n",
      "Iter: 1551, Loss: 0.3748, Train MAE hat: 0.9241\n",
      "Iter: 1552, Loss: 0.3661, Train MAE hat: 0.9235\n",
      "Iter: 1553, Loss: 0.3562, Train MAE hat: 0.9230\n",
      "Iter: 1554, Loss: 0.3480, Train MAE hat: 0.9224\n",
      "Iter: 1555, Loss: 0.3391, Train MAE hat: 0.9219\n",
      "Iter: 1556, Loss: 0.3324, Train MAE hat: 0.9213\n",
      "Iter: 1557, Loss: 0.3261, Train MAE hat: 0.9207\n",
      "Iter: 1558, Loss: 0.3196, Train MAE hat: 0.9202\n",
      "Iter: 1559, Loss: 0.3141, Train MAE hat: 0.9196\n",
      "Iter: 1560, Loss: 0.3095, Train MAE hat: 0.9190\n",
      "Iter: 1561, Loss: 0.3049, Train MAE hat: 0.9185\n",
      "Iter: 1562, Loss: 0.3000, Train MAE hat: 0.9179\n",
      "Iter: 1563, Loss: 0.2965, Train MAE hat: 0.9173\n",
      "Iter: 1564, Loss: 0.2928, Train MAE hat: 0.9167\n",
      "Iter: 1565, Loss: 0.2894, Train MAE hat: 0.9162\n",
      "Iter: 1566, Loss: 0.2862, Train MAE hat: 0.9156\n",
      "Iter: 1567, Loss: 0.2828, Train MAE hat: 0.9150\n",
      "Iter: 1568, Loss: 0.2804, Train MAE hat: 0.9144\n",
      "Iter: 1569, Loss: 0.2781, Train MAE hat: 0.9139\n",
      "Iter: 1570, Loss: 0.2756, Train MAE hat: 0.9133\n",
      "Iter: 1571, Loss: 0.2732, Train MAE hat: 0.9127\n",
      "Iter: 1572, Loss: 0.2710, Train MAE hat: 0.9121\n",
      "Iter: 1573, Loss: 0.2692, Train MAE hat: 0.9116\n",
      "Iter: 1574, Loss: 0.2673, Train MAE hat: 0.9110\n",
      "Iter: 1575, Loss: 0.2655, Train MAE hat: 0.9104\n",
      "Iter: 1576, Loss: 0.2637, Train MAE hat: 0.9098\n",
      "Iter: 1577, Loss: 0.2622, Train MAE hat: 0.9093\n",
      "Iter: 1578, Loss: 0.2606, Train MAE hat: 0.9087\n",
      "Iter: 1579, Loss: 0.2593, Train MAE hat: 0.9081\n",
      "Iter: 1580, Loss: 0.2577, Train MAE hat: 0.9075\n",
      "Iter: 1581, Loss: 0.2565, Train MAE hat: 0.9070\n",
      "Iter: 1582, Loss: 0.2552, Train MAE hat: 0.9064\n",
      "Iter: 1583, Loss: 0.2541, Train MAE hat: 0.9058\n",
      "Iter: 1584, Loss: 0.2529, Train MAE hat: 0.9052\n",
      "Iter: 1585, Loss: 0.2520, Train MAE hat: 0.9046\n",
      "Iter: 1586, Loss: 0.2511, Train MAE hat: 0.9041\n",
      "Iter: 1587, Loss: 0.2505, Train MAE hat: 0.9035\n",
      "Iter: 1588, Loss: 0.2503, Train MAE hat: 0.9029\n",
      "Iter: 1589, Loss: 0.2507, Train MAE hat: 0.9023\n",
      "Iter: 1590, Loss: 0.2523, Train MAE hat: 0.9018\n",
      "Iter: 1591, Loss: 0.2555, Train MAE hat: 0.9012\n",
      "Iter: 1592, Loss: 0.2619, Train MAE hat: 0.9006\n",
      "Iter: 1593, Loss: 0.2725, Train MAE hat: 0.9001\n",
      "Iter: 1594, Loss: 0.2910, Train MAE hat: 0.8995\n",
      "Iter: 1595, Loss: 0.3182, Train MAE hat: 0.8989\n",
      "Iter: 1596, Loss: 0.3605, Train MAE hat: 0.8984\n",
      "Iter: 1597, Loss: 0.4128, Train MAE hat: 0.8979\n",
      "Iter: 1598, Loss: 0.4756, Train MAE hat: 0.8973\n",
      "Iter: 1599, Loss: 0.5277, Train MAE hat: 0.8968\n",
      "Iter: 1600, Loss: 0.5472, Train MAE hat: 0.8963\n",
      "Iter: 1601, Loss: 0.5331, Train MAE hat: 0.8958\n",
      "Iter: 1602, Loss: 0.5096, Train MAE hat: 0.8953\n",
      "Iter: 1603, Loss: 0.5728, Train MAE hat: 0.8948\n",
      "Iter: 1604, Loss: 0.6877, Train MAE hat: 0.8942\n",
      "Iter: 1605, Loss: 0.8326, Train MAE hat: 0.8938\n",
      "Iter: 1606, Loss: 0.8537, Train MAE hat: 0.8933\n",
      "Iter: 1607, Loss: 0.8041, Train MAE hat: 0.8928\n",
      "Iter: 1608, Loss: 0.8678, Train MAE hat: 0.8923\n",
      "Iter: 1609, Loss: 0.9881, Train MAE hat: 0.8919\n",
      "Iter: 1610, Loss: 1.0631, Train MAE hat: 0.8914\n",
      "Iter: 1611, Loss: 0.9809, Train MAE hat: 0.8909\n",
      "Iter: 1612, Loss: 0.8786, Train MAE hat: 0.8905\n",
      "Iter: 1613, Loss: 0.8952, Train MAE hat: 0.8900\n",
      "Iter: 1614, Loss: 0.8466, Train MAE hat: 0.8895\n",
      "Iter: 1615, Loss: 0.7812, Train MAE hat: 0.8891\n",
      "Iter: 1616, Loss: 0.8077, Train MAE hat: 0.8886\n",
      "Iter: 1617, Loss: 0.7074, Train MAE hat: 0.8881\n",
      "Iter: 1618, Loss: 0.5970, Train MAE hat: 0.8876\n",
      "Iter: 1619, Loss: 0.6205, Train MAE hat: 0.8871\n",
      "Iter: 1620, Loss: 0.5375, Train MAE hat: 0.8866\n",
      "Iter: 1621, Loss: 0.4671, Train MAE hat: 0.8861\n",
      "Iter: 1622, Loss: 0.4894, Train MAE hat: 0.8856\n",
      "Iter: 1623, Loss: 0.4251, Train MAE hat: 0.8851\n",
      "Iter: 1624, Loss: 0.4115, Train MAE hat: 0.8846\n",
      "Iter: 1625, Loss: 0.4145, Train MAE hat: 0.8841\n",
      "Iter: 1626, Loss: 0.3526, Train MAE hat: 0.8835\n",
      "Iter: 1627, Loss: 0.3673, Train MAE hat: 0.8830\n",
      "Iter: 1628, Loss: 0.3574, Train MAE hat: 0.8825\n",
      "Iter: 1629, Loss: 0.3233, Train MAE hat: 0.8820\n",
      "Iter: 1630, Loss: 0.3320, Train MAE hat: 0.8814\n",
      "Iter: 1631, Loss: 0.3079, Train MAE hat: 0.8809\n",
      "Iter: 1632, Loss: 0.3022, Train MAE hat: 0.8804\n",
      "Iter: 1633, Loss: 0.3026, Train MAE hat: 0.8798\n",
      "Iter: 1634, Loss: 0.2829, Train MAE hat: 0.8793\n",
      "Iter: 1635, Loss: 0.2826, Train MAE hat: 0.8787\n",
      "Iter: 1636, Loss: 0.2747, Train MAE hat: 0.8782\n",
      "Iter: 1637, Loss: 0.2678, Train MAE hat: 0.8777\n",
      "Iter: 1638, Loss: 0.2673, Train MAE hat: 0.8771\n",
      "Iter: 1639, Loss: 0.2576, Train MAE hat: 0.8766\n",
      "Iter: 1640, Loss: 0.2554, Train MAE hat: 0.8760\n",
      "Iter: 1641, Loss: 0.2518, Train MAE hat: 0.8755\n",
      "Iter: 1642, Loss: 0.2463, Train MAE hat: 0.8749\n",
      "Iter: 1643, Loss: 0.2456, Train MAE hat: 0.8744\n",
      "Iter: 1644, Loss: 0.2403, Train MAE hat: 0.8738\n",
      "Iter: 1645, Loss: 0.2381, Train MAE hat: 0.8733\n",
      "Iter: 1646, Loss: 0.2366, Train MAE hat: 0.8727\n",
      "Iter: 1647, Loss: 0.2328, Train MAE hat: 0.8722\n",
      "Iter: 1648, Loss: 0.2314, Train MAE hat: 0.8716\n",
      "Iter: 1649, Loss: 0.2286, Train MAE hat: 0.8711\n",
      "Iter: 1650, Loss: 0.2271, Train MAE hat: 0.8705\n",
      "Iter: 1651, Loss: 0.2254, Train MAE hat: 0.8700\n",
      "Iter: 1652, Loss: 0.2233, Train MAE hat: 0.8694\n",
      "Iter: 1653, Loss: 0.2218, Train MAE hat: 0.8689\n",
      "Iter: 1654, Loss: 0.2202, Train MAE hat: 0.8683\n",
      "Iter: 1655, Loss: 0.2191, Train MAE hat: 0.8678\n",
      "Iter: 1656, Loss: 0.2174, Train MAE hat: 0.8672\n",
      "Iter: 1657, Loss: 0.2162, Train MAE hat: 0.8667\n",
      "Iter: 1658, Loss: 0.2151, Train MAE hat: 0.8661\n",
      "Iter: 1659, Loss: 0.2139, Train MAE hat: 0.8656\n",
      "Iter: 1660, Loss: 0.2129, Train MAE hat: 0.8650\n",
      "Iter: 1661, Loss: 0.2118, Train MAE hat: 0.8645\n",
      "Iter: 1662, Loss: 0.2108, Train MAE hat: 0.8639\n",
      "Iter: 1663, Loss: 0.2100, Train MAE hat: 0.8634\n",
      "Iter: 1664, Loss: 0.2092, Train MAE hat: 0.8628\n",
      "Iter: 1665, Loss: 0.2085, Train MAE hat: 0.8623\n",
      "Iter: 1666, Loss: 0.2081, Train MAE hat: 0.8617\n",
      "Iter: 1667, Loss: 0.2081, Train MAE hat: 0.8612\n",
      "Iter: 1668, Loss: 0.2087, Train MAE hat: 0.8606\n",
      "Iter: 1669, Loss: 0.2106, Train MAE hat: 0.8601\n",
      "Iter: 1670, Loss: 0.2147, Train MAE hat: 0.8595\n",
      "Iter: 1671, Loss: 0.2227, Train MAE hat: 0.8590\n",
      "Iter: 1672, Loss: 0.2377, Train MAE hat: 0.8584\n",
      "Iter: 1673, Loss: 0.2656, Train MAE hat: 0.8579\n",
      "Iter: 1674, Loss: 0.3139, Train MAE hat: 0.8574\n",
      "Iter: 1675, Loss: 0.3986, Train MAE hat: 0.8569\n",
      "Iter: 1676, Loss: 0.5311, Train MAE hat: 0.8564\n",
      "Iter: 1677, Loss: 0.7304, Train MAE hat: 0.8559\n",
      "Iter: 1678, Loss: 0.9509, Train MAE hat: 0.8554\n",
      "Iter: 1679, Loss: 1.0939, Train MAE hat: 0.8550\n",
      "Iter: 1680, Loss: 1.0168, Train MAE hat: 0.8546\n",
      "Iter: 1681, Loss: 0.8861, Train MAE hat: 0.8541\n",
      "Iter: 1682, Loss: 1.1778, Train MAE hat: 0.8537\n",
      "Iter: 1683, Loss: 1.7994, Train MAE hat: 0.8533\n",
      "Iter: 1684, Loss: 2.0391, Train MAE hat: 0.8529\n",
      "Iter: 1685, Loss: 1.5293, Train MAE hat: 0.8525\n",
      "Iter: 1686, Loss: 1.6679, Train MAE hat: 0.8522\n",
      "Iter: 1687, Loss: 2.3153, Train MAE hat: 0.8518\n",
      "Iter: 1688, Loss: 2.0459, Train MAE hat: 0.8514\n",
      "Iter: 1689, Loss: 2.1752, Train MAE hat: 0.8511\n",
      "Iter: 1690, Loss: 2.6779, Train MAE hat: 0.8507\n",
      "Iter: 1691, Loss: 2.2511, Train MAE hat: 0.8504\n",
      "Iter: 1692, Loss: 2.1467, Train MAE hat: 0.8501\n",
      "Iter: 1693, Loss: 2.2402, Train MAE hat: 0.8497\n",
      "Iter: 1694, Loss: 1.9915, Train MAE hat: 0.8494\n",
      "Iter: 1695, Loss: 1.8926, Train MAE hat: 0.8490\n",
      "Iter: 1696, Loss: 1.6138, Train MAE hat: 0.8487\n",
      "Iter: 1697, Loss: 1.4432, Train MAE hat: 0.8483\n",
      "Iter: 1698, Loss: 1.3744, Train MAE hat: 0.8479\n",
      "Iter: 1699, Loss: 1.1652, Train MAE hat: 0.8475\n",
      "Iter: 1700, Loss: 1.0670, Train MAE hat: 0.8471\n",
      "Iter: 1701, Loss: 0.9877, Train MAE hat: 0.8467\n",
      "Iter: 1702, Loss: 0.9065, Train MAE hat: 0.8462\n",
      "Iter: 1703, Loss: 0.8350, Train MAE hat: 0.8458\n",
      "Iter: 1704, Loss: 0.7577, Train MAE hat: 0.8454\n",
      "Iter: 1705, Loss: 0.7109, Train MAE hat: 0.8449\n",
      "Iter: 1706, Loss: 0.6641, Train MAE hat: 0.8445\n",
      "Iter: 1707, Loss: 0.6170, Train MAE hat: 0.8440\n",
      "Iter: 1708, Loss: 0.5754, Train MAE hat: 0.8436\n",
      "Iter: 1709, Loss: 0.5367, Train MAE hat: 0.8431\n",
      "Iter: 1710, Loss: 0.5035, Train MAE hat: 0.8427\n",
      "Iter: 1711, Loss: 0.4758, Train MAE hat: 0.8422\n",
      "Iter: 1712, Loss: 0.4491, Train MAE hat: 0.8417\n",
      "Iter: 1713, Loss: 0.4243, Train MAE hat: 0.8412\n",
      "Iter: 1714, Loss: 0.4034, Train MAE hat: 0.8408\n",
      "Iter: 1715, Loss: 0.3851, Train MAE hat: 0.8403\n",
      "Iter: 1716, Loss: 0.3639, Train MAE hat: 0.8398\n",
      "Iter: 1717, Loss: 0.3494, Train MAE hat: 0.8393\n",
      "Iter: 1718, Loss: 0.3347, Train MAE hat: 0.8388\n",
      "Iter: 1719, Loss: 0.3228, Train MAE hat: 0.8383\n",
      "Iter: 1720, Loss: 0.3096, Train MAE hat: 0.8378\n",
      "Iter: 1721, Loss: 0.3000, Train MAE hat: 0.8373\n",
      "Iter: 1722, Loss: 0.2890, Train MAE hat: 0.8368\n",
      "Iter: 1723, Loss: 0.2805, Train MAE hat: 0.8363\n",
      "Iter: 1724, Loss: 0.2725, Train MAE hat: 0.8358\n",
      "Iter: 1725, Loss: 0.2648, Train MAE hat: 0.8353\n",
      "Iter: 1726, Loss: 0.2582, Train MAE hat: 0.8348\n",
      "Iter: 1727, Loss: 0.2526, Train MAE hat: 0.8343\n",
      "Iter: 1728, Loss: 0.2466, Train MAE hat: 0.8338\n",
      "Iter: 1729, Loss: 0.2413, Train MAE hat: 0.8333\n",
      "Iter: 1730, Loss: 0.2366, Train MAE hat: 0.8328\n",
      "Iter: 1731, Loss: 0.2320, Train MAE hat: 0.8322\n",
      "Iter: 1732, Loss: 0.2288, Train MAE hat: 0.8317\n",
      "Iter: 1733, Loss: 0.2247, Train MAE hat: 0.8312\n",
      "Iter: 1734, Loss: 0.2213, Train MAE hat: 0.8307\n",
      "Iter: 1735, Loss: 0.2182, Train MAE hat: 0.8302\n",
      "Iter: 1736, Loss: 0.2154, Train MAE hat: 0.8297\n",
      "Iter: 1737, Loss: 0.2126, Train MAE hat: 0.8291\n",
      "Iter: 1738, Loss: 0.2104, Train MAE hat: 0.8286\n",
      "Iter: 1739, Loss: 0.2077, Train MAE hat: 0.8281\n",
      "Iter: 1740, Loss: 0.2058, Train MAE hat: 0.8276\n",
      "Iter: 1741, Loss: 0.2039, Train MAE hat: 0.8271\n",
      "Iter: 1742, Loss: 0.2020, Train MAE hat: 0.8265\n",
      "Iter: 1743, Loss: 0.2003, Train MAE hat: 0.8260\n",
      "Iter: 1744, Loss: 0.1984, Train MAE hat: 0.8255\n",
      "Iter: 1745, Loss: 0.1970, Train MAE hat: 0.8250\n",
      "Iter: 1746, Loss: 0.1956, Train MAE hat: 0.8245\n",
      "Iter: 1747, Loss: 0.1942, Train MAE hat: 0.8239\n",
      "Iter: 1748, Loss: 0.1929, Train MAE hat: 0.8234\n",
      "Iter: 1749, Loss: 0.1917, Train MAE hat: 0.8229\n",
      "Iter: 1750, Loss: 0.1905, Train MAE hat: 0.8224\n",
      "Iter: 1751, Loss: 0.1893, Train MAE hat: 0.8218\n",
      "Iter: 1752, Loss: 0.1884, Train MAE hat: 0.8213\n",
      "Iter: 1753, Loss: 0.1873, Train MAE hat: 0.8208\n",
      "Iter: 1754, Loss: 0.1863, Train MAE hat: 0.8203\n",
      "Iter: 1755, Loss: 0.1855, Train MAE hat: 0.8198\n",
      "Iter: 1756, Loss: 0.1846, Train MAE hat: 0.8192\n",
      "Iter: 1757, Loss: 0.1838, Train MAE hat: 0.8187\n",
      "Iter: 1758, Loss: 0.1830, Train MAE hat: 0.8182\n",
      "Iter: 1759, Loss: 0.1823, Train MAE hat: 0.8177\n",
      "Iter: 1760, Loss: 0.1817, Train MAE hat: 0.8171\n",
      "Iter: 1761, Loss: 0.1812, Train MAE hat: 0.8166\n",
      "Iter: 1762, Loss: 0.1810, Train MAE hat: 0.8161\n",
      "Iter: 1763, Loss: 0.1811, Train MAE hat: 0.8156\n",
      "Iter: 1764, Loss: 0.1820, Train MAE hat: 0.8151\n",
      "Iter: 1765, Loss: 0.1840, Train MAE hat: 0.8145\n",
      "Iter: 1766, Loss: 0.1880, Train MAE hat: 0.8140\n",
      "Iter: 1767, Loss: 0.1952, Train MAE hat: 0.8135\n",
      "Iter: 1768, Loss: 0.2082, Train MAE hat: 0.8130\n",
      "Iter: 1769, Loss: 0.2291, Train MAE hat: 0.8125\n",
      "Iter: 1770, Loss: 0.2635, Train MAE hat: 0.8120\n",
      "Iter: 1771, Loss: 0.3124, Train MAE hat: 0.8115\n",
      "Iter: 1772, Loss: 0.3808, Train MAE hat: 0.8110\n",
      "Iter: 1773, Loss: 0.4496, Train MAE hat: 0.8105\n",
      "Iter: 1774, Loss: 0.4989, Train MAE hat: 0.8101\n",
      "Iter: 1775, Loss: 0.4676, Train MAE hat: 0.8096\n",
      "Iter: 1776, Loss: 0.3559, Train MAE hat: 0.8091\n",
      "Iter: 1777, Loss: 0.2496, Train MAE hat: 0.8087\n",
      "Iter: 1778, Loss: 0.2734, Train MAE hat: 0.8082\n",
      "Iter: 1779, Loss: 0.3746, Train MAE hat: 0.8077\n",
      "Iter: 1780, Loss: 0.4049, Train MAE hat: 0.8072\n",
      "Iter: 1781, Loss: 0.3344, Train MAE hat: 0.8067\n",
      "Iter: 1782, Loss: 0.2831, Train MAE hat: 0.8063\n",
      "Iter: 1783, Loss: 0.3193, Train MAE hat: 0.8058\n",
      "Iter: 1784, Loss: 0.3470, Train MAE hat: 0.8053\n",
      "Iter: 1785, Loss: 0.2880, Train MAE hat: 0.8048\n",
      "Iter: 1786, Loss: 0.2367, Train MAE hat: 0.8043\n",
      "Iter: 1787, Loss: 0.2590, Train MAE hat: 0.8039\n",
      "Iter: 1788, Loss: 0.2725, Train MAE hat: 0.8034\n",
      "Iter: 1789, Loss: 0.2321, Train MAE hat: 0.8029\n",
      "Iter: 1790, Loss: 0.2095, Train MAE hat: 0.8024\n",
      "Iter: 1791, Loss: 0.2302, Train MAE hat: 0.8019\n",
      "Iter: 1792, Loss: 0.2284, Train MAE hat: 0.8014\n",
      "Iter: 1793, Loss: 0.2010, Train MAE hat: 0.8009\n",
      "Iter: 1794, Loss: 0.2024, Train MAE hat: 0.8004\n",
      "Iter: 1795, Loss: 0.2151, Train MAE hat: 0.7999\n",
      "Iter: 1796, Loss: 0.1992, Train MAE hat: 0.7994\n",
      "Iter: 1797, Loss: 0.1833, Train MAE hat: 0.7989\n",
      "Iter: 1798, Loss: 0.1917, Train MAE hat: 0.7984\n",
      "Iter: 1799, Loss: 0.1932, Train MAE hat: 0.7979\n",
      "Iter: 1800, Loss: 0.1799, Train MAE hat: 0.7974\n",
      "Iter: 1801, Loss: 0.1782, Train MAE hat: 0.7969\n",
      "Iter: 1802, Loss: 0.1844, Train MAE hat: 0.7964\n",
      "Iter: 1803, Loss: 0.1786, Train MAE hat: 0.7959\n",
      "Iter: 1804, Loss: 0.1717, Train MAE hat: 0.7954\n",
      "Iter: 1805, Loss: 0.1750, Train MAE hat: 0.7949\n",
      "Iter: 1806, Loss: 0.1756, Train MAE hat: 0.7944\n",
      "Iter: 1807, Loss: 0.1700, Train MAE hat: 0.7939\n",
      "Iter: 1808, Loss: 0.1699, Train MAE hat: 0.7934\n",
      "Iter: 1809, Loss: 0.1730, Train MAE hat: 0.7928\n",
      "Iter: 1810, Loss: 0.1708, Train MAE hat: 0.7923\n",
      "Iter: 1811, Loss: 0.1688, Train MAE hat: 0.7918\n",
      "Iter: 1812, Loss: 0.1722, Train MAE hat: 0.7913\n",
      "Iter: 1813, Loss: 0.1750, Train MAE hat: 0.7908\n",
      "Iter: 1814, Loss: 0.1762, Train MAE hat: 0.7903\n",
      "Iter: 1815, Loss: 0.1805, Train MAE hat: 0.7898\n",
      "Iter: 1816, Loss: 0.1894, Train MAE hat: 0.7893\n",
      "Iter: 1817, Loss: 0.1985, Train MAE hat: 0.7888\n",
      "Iter: 1818, Loss: 0.2102, Train MAE hat: 0.7883\n",
      "Iter: 1819, Loss: 0.2275, Train MAE hat: 0.7879\n",
      "Iter: 1820, Loss: 0.2495, Train MAE hat: 0.7874\n",
      "Iter: 1821, Loss: 0.2713, Train MAE hat: 0.7869\n",
      "Iter: 1822, Loss: 0.2910, Train MAE hat: 0.7864\n",
      "Iter: 1823, Loss: 0.3029, Train MAE hat: 0.7860\n",
      "Iter: 1824, Loss: 0.3011, Train MAE hat: 0.7855\n",
      "Iter: 1825, Loss: 0.2861, Train MAE hat: 0.7850\n",
      "Iter: 1826, Loss: 0.2751, Train MAE hat: 0.7845\n",
      "Iter: 1827, Loss: 0.2964, Train MAE hat: 0.7841\n",
      "Iter: 1828, Loss: 0.3654, Train MAE hat: 0.7836\n",
      "Iter: 1829, Loss: 0.4769, Train MAE hat: 0.7832\n",
      "Iter: 1830, Loss: 0.6030, Train MAE hat: 0.7827\n",
      "Iter: 1831, Loss: 0.7185, Train MAE hat: 0.7823\n",
      "Iter: 1832, Loss: 0.7336, Train MAE hat: 0.7819\n",
      "Iter: 1833, Loss: 0.6671, Train MAE hat: 0.7815\n",
      "Iter: 1834, Loss: 0.6226, Train MAE hat: 0.7810\n",
      "Iter: 1835, Loss: 0.7423, Train MAE hat: 0.7806\n",
      "Iter: 1836, Loss: 0.9182, Train MAE hat: 0.7802\n",
      "Iter: 1837, Loss: 0.8737, Train MAE hat: 0.7798\n",
      "Iter: 1838, Loss: 0.7306, Train MAE hat: 0.7794\n",
      "Iter: 1839, Loss: 0.7725, Train MAE hat: 0.7790\n",
      "Iter: 1840, Loss: 0.9304, Train MAE hat: 0.7786\n",
      "Iter: 1841, Loss: 0.8830, Train MAE hat: 0.7782\n",
      "Iter: 1842, Loss: 0.7339, Train MAE hat: 0.7778\n",
      "Iter: 1843, Loss: 0.7835, Train MAE hat: 0.7774\n",
      "Iter: 1844, Loss: 0.7541, Train MAE hat: 0.7770\n",
      "Iter: 1845, Loss: 0.5715, Train MAE hat: 0.7766\n",
      "Iter: 1846, Loss: 0.5462, Train MAE hat: 0.7762\n",
      "Iter: 1847, Loss: 0.5293, Train MAE hat: 0.7758\n",
      "Iter: 1848, Loss: 0.4444, Train MAE hat: 0.7754\n",
      "Iter: 1849, Loss: 0.4336, Train MAE hat: 0.7749\n",
      "Iter: 1850, Loss: 0.3872, Train MAE hat: 0.7745\n",
      "Iter: 1851, Loss: 0.3564, Train MAE hat: 0.7740\n",
      "Iter: 1852, Loss: 0.3444, Train MAE hat: 0.7736\n",
      "Iter: 1853, Loss: 0.3167, Train MAE hat: 0.7732\n",
      "Iter: 1854, Loss: 0.3023, Train MAE hat: 0.7727\n",
      "Iter: 1855, Loss: 0.2821, Train MAE hat: 0.7722\n",
      "Iter: 1856, Loss: 0.2708, Train MAE hat: 0.7718\n",
      "Iter: 1857, Loss: 0.2545, Train MAE hat: 0.7713\n",
      "Iter: 1858, Loss: 0.2485, Train MAE hat: 0.7709\n",
      "Iter: 1859, Loss: 0.2360, Train MAE hat: 0.7704\n",
      "Iter: 1860, Loss: 0.2267, Train MAE hat: 0.7699\n",
      "Iter: 1861, Loss: 0.2200, Train MAE hat: 0.7695\n",
      "Iter: 1862, Loss: 0.2091, Train MAE hat: 0.7690\n",
      "Iter: 1863, Loss: 0.2063, Train MAE hat: 0.7685\n",
      "Iter: 1864, Loss: 0.1994, Train MAE hat: 0.7680\n",
      "Iter: 1865, Loss: 0.1927, Train MAE hat: 0.7676\n",
      "Iter: 1866, Loss: 0.1892, Train MAE hat: 0.7671\n",
      "Iter: 1867, Loss: 0.1842, Train MAE hat: 0.7666\n",
      "Iter: 1868, Loss: 0.1798, Train MAE hat: 0.7661\n",
      "Iter: 1869, Loss: 0.1768, Train MAE hat: 0.7657\n",
      "Iter: 1870, Loss: 0.1728, Train MAE hat: 0.7652\n",
      "Iter: 1871, Loss: 0.1704, Train MAE hat: 0.7647\n",
      "Iter: 1872, Loss: 0.1667, Train MAE hat: 0.7642\n",
      "Iter: 1873, Loss: 0.1652, Train MAE hat: 0.7637\n",
      "Iter: 1874, Loss: 0.1618, Train MAE hat: 0.7632\n",
      "Iter: 1875, Loss: 0.1601, Train MAE hat: 0.7628\n",
      "Iter: 1876, Loss: 0.1586, Train MAE hat: 0.7623\n",
      "Iter: 1877, Loss: 0.1561, Train MAE hat: 0.7618\n",
      "Iter: 1878, Loss: 0.1549, Train MAE hat: 0.7613\n",
      "Iter: 1879, Loss: 0.1530, Train MAE hat: 0.7608\n",
      "Iter: 1880, Loss: 0.1516, Train MAE hat: 0.7603\n",
      "Iter: 1881, Loss: 0.1507, Train MAE hat: 0.7598\n",
      "Iter: 1882, Loss: 0.1493, Train MAE hat: 0.7594\n",
      "Iter: 1883, Loss: 0.1482, Train MAE hat: 0.7589\n",
      "Iter: 1884, Loss: 0.1470, Train MAE hat: 0.7584\n",
      "Iter: 1885, Loss: 0.1460, Train MAE hat: 0.7579\n",
      "Iter: 1886, Loss: 0.1452, Train MAE hat: 0.7574\n",
      "Iter: 1887, Loss: 0.1443, Train MAE hat: 0.7569\n",
      "Iter: 1888, Loss: 0.1434, Train MAE hat: 0.7564\n",
      "Iter: 1889, Loss: 0.1428, Train MAE hat: 0.7559\n",
      "Iter: 1890, Loss: 0.1421, Train MAE hat: 0.7555\n",
      "Iter: 1891, Loss: 0.1415, Train MAE hat: 0.7550\n",
      "Iter: 1892, Loss: 0.1410, Train MAE hat: 0.7545\n",
      "Iter: 1893, Loss: 0.1406, Train MAE hat: 0.7540\n",
      "Iter: 1894, Loss: 0.1406, Train MAE hat: 0.7535\n",
      "Iter: 1895, Loss: 0.1407, Train MAE hat: 0.7530\n",
      "Iter: 1896, Loss: 0.1414, Train MAE hat: 0.7525\n",
      "Iter: 1897, Loss: 0.1428, Train MAE hat: 0.7520\n",
      "Iter: 1898, Loss: 0.1456, Train MAE hat: 0.7516\n",
      "Iter: 1899, Loss: 0.1505, Train MAE hat: 0.7511\n",
      "Iter: 1900, Loss: 0.1589, Train MAE hat: 0.7506\n",
      "Iter: 1901, Loss: 0.1730, Train MAE hat: 0.7501\n",
      "Iter: 1902, Loss: 0.1955, Train MAE hat: 0.7496\n",
      "Iter: 1903, Loss: 0.2319, Train MAE hat: 0.7492\n",
      "Iter: 1904, Loss: 0.2874, Train MAE hat: 0.7487\n",
      "Iter: 1905, Loss: 0.3701, Train MAE hat: 0.7483\n",
      "Iter: 1906, Loss: 0.4770, Train MAE hat: 0.7479\n",
      "Iter: 1907, Loss: 0.5962, Train MAE hat: 0.7475\n",
      "Iter: 1908, Loss: 0.6598, Train MAE hat: 0.7470\n",
      "Iter: 1909, Loss: 0.5949, Train MAE hat: 0.7466\n",
      "Iter: 1910, Loss: 0.3915, Train MAE hat: 0.7462\n",
      "Iter: 1911, Loss: 0.2776, Train MAE hat: 0.7458\n",
      "Iter: 1912, Loss: 0.4190, Train MAE hat: 0.7454\n",
      "Iter: 1913, Loss: 0.5739, Train MAE hat: 0.7449\n",
      "Iter: 1914, Loss: 0.5270, Train MAE hat: 0.7445\n",
      "Iter: 1915, Loss: 0.4102, Train MAE hat: 0.7441\n",
      "Iter: 1916, Loss: 0.4694, Train MAE hat: 0.7437\n",
      "Iter: 1917, Loss: 0.5506, Train MAE hat: 0.7433\n",
      "Iter: 1918, Loss: 0.4710, Train MAE hat: 0.7429\n",
      "Iter: 1919, Loss: 0.3917, Train MAE hat: 0.7425\n",
      "Iter: 1920, Loss: 0.4630, Train MAE hat: 0.7420\n",
      "Iter: 1921, Loss: 0.4959, Train MAE hat: 0.7416\n",
      "Iter: 1922, Loss: 0.4173, Train MAE hat: 0.7412\n",
      "Iter: 1923, Loss: 0.3948, Train MAE hat: 0.7408\n",
      "Iter: 1924, Loss: 0.4174, Train MAE hat: 0.7404\n",
      "Iter: 1925, Loss: 0.3696, Train MAE hat: 0.7400\n",
      "Iter: 1926, Loss: 0.3432, Train MAE hat: 0.7395\n",
      "Iter: 1927, Loss: 0.3483, Train MAE hat: 0.7391\n",
      "Iter: 1928, Loss: 0.3038, Train MAE hat: 0.7387\n",
      "Iter: 1929, Loss: 0.2762, Train MAE hat: 0.7382\n",
      "Iter: 1930, Loss: 0.2916, Train MAE hat: 0.7378\n",
      "Iter: 1931, Loss: 0.2726, Train MAE hat: 0.7374\n",
      "Iter: 1932, Loss: 0.2391, Train MAE hat: 0.7369\n",
      "Iter: 1933, Loss: 0.2237, Train MAE hat: 0.7365\n",
      "Iter: 1934, Loss: 0.2181, Train MAE hat: 0.7360\n",
      "Iter: 1935, Loss: 0.2094, Train MAE hat: 0.7356\n",
      "Iter: 1936, Loss: 0.1957, Train MAE hat: 0.7351\n",
      "Iter: 1937, Loss: 0.1915, Train MAE hat: 0.7347\n",
      "Iter: 1938, Loss: 0.1850, Train MAE hat: 0.7342\n",
      "Iter: 1939, Loss: 0.1767, Train MAE hat: 0.7338\n",
      "Iter: 1940, Loss: 0.1737, Train MAE hat: 0.7333\n",
      "Iter: 1941, Loss: 0.1664, Train MAE hat: 0.7329\n",
      "Iter: 1942, Loss: 0.1629, Train MAE hat: 0.7324\n",
      "Iter: 1943, Loss: 0.1597, Train MAE hat: 0.7319\n",
      "Iter: 1944, Loss: 0.1538, Train MAE hat: 0.7315\n",
      "Iter: 1945, Loss: 0.1524, Train MAE hat: 0.7310\n",
      "Iter: 1946, Loss: 0.1498, Train MAE hat: 0.7305\n",
      "Iter: 1947, Loss: 0.1472, Train MAE hat: 0.7301\n",
      "Iter: 1948, Loss: 0.1452, Train MAE hat: 0.7296\n",
      "Iter: 1949, Loss: 0.1420, Train MAE hat: 0.7291\n",
      "Iter: 1950, Loss: 0.1407, Train MAE hat: 0.7287\n",
      "Iter: 1951, Loss: 0.1391, Train MAE hat: 0.7282\n",
      "Iter: 1952, Loss: 0.1372, Train MAE hat: 0.7277\n",
      "Iter: 1953, Loss: 0.1359, Train MAE hat: 0.7273\n",
      "Iter: 1954, Loss: 0.1341, Train MAE hat: 0.7268\n",
      "Iter: 1955, Loss: 0.1329, Train MAE hat: 0.7263\n",
      "Iter: 1956, Loss: 0.1321, Train MAE hat: 0.7259\n",
      "Iter: 1957, Loss: 0.1309, Train MAE hat: 0.7254\n",
      "Iter: 1958, Loss: 0.1300, Train MAE hat: 0.7249\n",
      "Iter: 1959, Loss: 0.1290, Train MAE hat: 0.7245\n",
      "Iter: 1960, Loss: 0.1281, Train MAE hat: 0.7240\n",
      "Iter: 1961, Loss: 0.1276, Train MAE hat: 0.7235\n",
      "Iter: 1962, Loss: 0.1268, Train MAE hat: 0.7230\n",
      "Iter: 1963, Loss: 0.1261, Train MAE hat: 0.7226\n",
      "Iter: 1964, Loss: 0.1257, Train MAE hat: 0.7221\n",
      "Iter: 1965, Loss: 0.1252, Train MAE hat: 0.7216\n",
      "Iter: 1966, Loss: 0.1248, Train MAE hat: 0.7212\n",
      "Iter: 1967, Loss: 0.1246, Train MAE hat: 0.7207\n",
      "Iter: 1968, Loss: 0.1248, Train MAE hat: 0.7202\n",
      "Iter: 1969, Loss: 0.1253, Train MAE hat: 0.7197\n",
      "Iter: 1970, Loss: 0.1263, Train MAE hat: 0.7193\n",
      "Iter: 1971, Loss: 0.1286, Train MAE hat: 0.7188\n",
      "Iter: 1972, Loss: 0.1324, Train MAE hat: 0.7183\n",
      "Iter: 1973, Loss: 0.1389, Train MAE hat: 0.7179\n",
      "Iter: 1974, Loss: 0.1504, Train MAE hat: 0.7174\n",
      "Iter: 1975, Loss: 0.1693, Train MAE hat: 0.7170\n",
      "Iter: 1976, Loss: 0.2017, Train MAE hat: 0.7165\n",
      "Iter: 1977, Loss: 0.2549, Train MAE hat: 0.7161\n",
      "Iter: 1978, Loss: 0.3438, Train MAE hat: 0.7156\n",
      "Iter: 1979, Loss: 0.4868, Train MAE hat: 0.7152\n",
      "Iter: 1980, Loss: 0.7021, Train MAE hat: 0.7148\n",
      "Iter: 1981, Loss: 0.9980, Train MAE hat: 0.7145\n",
      "Iter: 1982, Loss: 1.2435, Train MAE hat: 0.7141\n",
      "Iter: 1983, Loss: 1.3087, Train MAE hat: 0.7138\n",
      "Iter: 1984, Loss: 1.1526, Train MAE hat: 0.7135\n",
      "Iter: 1985, Loss: 1.5849, Train MAE hat: 0.7132\n",
      "Iter: 1986, Loss: 2.7783, Train MAE hat: 0.7129\n",
      "Iter: 1987, Loss: 3.9958, Train MAE hat: 0.7127\n",
      "Iter: 1988, Loss: 3.6752, Train MAE hat: 0.7125\n",
      "Iter: 1989, Loss: 4.7186, Train MAE hat: 0.7123\n",
      "Iter: 1990, Loss: 7.1056, Train MAE hat: 0.7121\n",
      "Iter: 1991, Loss: 7.4419, Train MAE hat: 0.7121\n",
      "Iter: 1992, Loss: 8.2424, Train MAE hat: 0.7120\n",
      "Iter: 1993, Loss: 11.3105, Train MAE hat: 0.7120\n",
      "Iter: 1994, Loss: 12.4644, Train MAE hat: 0.7120\n",
      "Iter: 1995, Loss: 15.5135, Train MAE hat: 0.7121\n",
      "Iter: 1996, Loss: 20.1641, Train MAE hat: 0.7123\n",
      "Iter: 1997, Loss: 25.0578, Train MAE hat: 0.7125\n",
      "Iter: 1998, Loss: 31.9689, Train MAE hat: 0.7128\n",
      "Iter: 1999, Loss: 48.8214, Train MAE hat: 0.7132\n",
      "Test Loss: 114.8918, Test MAE hat: 0.7136\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./my_model_final5.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_train, y: y_train, batch_size: BATCH_SIZE})\n",
    "    print('Training...')\n",
    "    for i in range(EPOCHS):\n",
    "        tot_loss = 0\n",
    "        for _ in range(n_batches):\n",
    "            _, loss_value, tr_lmae = sess.run([training_op, l2_loss, log_MAE_hat])\n",
    "            tot_loss += loss_value\n",
    "        print(\"Iter: {}, Loss: {:.4f}, Train MAE hat: {:.4f}\".format(i, tot_loss / n_batches, tr_lmae))\n",
    "    # initialise iterator with test data\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_val, y: y_val, batch_size: X_val.shape[0]})\n",
    "    t_loss, l_mae = sess.run([l2_loss, log_MAE_hat])\n",
    "    print('Test Loss: {:.4f}, Test MAE hat: {:.4f}'.format(t_loss, l_mae))\n",
    "    save_path = saver.save(sess, \"./my_model_final6.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "arcWcXAIihh5",
    "outputId": "bb76de1f-1b41-488e-b3ef-9ed23ef96075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Test Loss: 114.8918, Test MAE hat: 1.1163\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./my_model_final6.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_val, y: y_val, batch_size: X_val.shape[0]})\n",
    "    out, t_loss, l_mae = sess.run([output, l2_loss, log_MAE_hat])\n",
    "    print('Test Loss: {:.4f}, Test MAE hat: {:.4f}'.format(t_loss, l_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zfyWU6gasSH"
   },
   "outputs": [],
   "source": [
    "def actual_mae(X_val, y_val, out):\n",
    "    abs_err = np.absolute(y_val - out)\n",
    "    summe = np.zeros(8)\n",
    "    for i in range(8):\n",
    "        new_X_val = X_val[:,:,i,0]\n",
    "        mult = abs_err * new_X_val\n",
    "        summe[i] = np.sum(mult)/np.sum(new_X_val)\n",
    "    summe = np.log(summe)\n",
    "    MAE = np.sum(summe)/8.0\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FPGzRHLCa4eB",
    "outputId": "f917cb9d-b0e2-498d-9c65-40ff6990a23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3549514063901205\n"
     ]
    }
   ],
   "source": [
    "mae = actual_mae(X_val, y_val, out)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnHkkJ2Ga7fJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "molecules.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
