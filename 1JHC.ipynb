{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1JHC = train[train[\"type\"] == '1JHC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709416, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1JHC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_csv(\"structures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_train_1JHC = train_1JHC.merge(structures, how='inner', left_on=['molecule_name','atom_index_0'], \n",
    "                right_on=['molecule_name','atom_index'])\n",
    "loaded_train_1JHC = inter_train_1JHC.merge(structures, how='inner', left_on=['molecule_name','atom_index_1'], \n",
    "                right_on=['molecule_name','atom_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom_index_x</th>\n",
       "      <th>atom_x</th>\n",
       "      <th>x_x</th>\n",
       "      <th>y_x</th>\n",
       "      <th>z_x</th>\n",
       "      <th>atom_index_y</th>\n",
       "      <th>atom_y</th>\n",
       "      <th>x_y</th>\n",
       "      <th>y_y</th>\n",
       "      <th>z_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8093</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8095</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>dsgdb9nsd_000005</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>171.2200</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.027803</td>\n",
       "      <td>2.198949</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.013324</td>\n",
       "      <td>1.132466</td>\n",
       "      <td>0.008276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5429</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>0.994873</td>\n",
       "      <td>1.939743</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5417</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.542076</td>\n",
       "      <td>1.923611</td>\n",
       "      <td>-0.865117</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5484</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.525241</td>\n",
       "      <td>1.914173</td>\n",
       "      <td>0.900024</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5418</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>-0.401908</td>\n",
       "      <td>0.877544</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5430</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>-1.011477</td>\n",
       "      <td>-0.418034</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45</td>\n",
       "      <td>dsgdb9nsd_000007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>83.5486</td>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>-0.392470</td>\n",
       "      <td>-0.887601</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46</td>\n",
       "      <td>dsgdb9nsd_000008</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>87.6326</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.006583</td>\n",
       "      <td>1.815564</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>1.390470</td>\n",
       "      <td>-0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>dsgdb9nsd_000008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>87.6253</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.546575</td>\n",
       "      <td>1.799170</td>\n",
       "      <td>-0.873901</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>1.390470</td>\n",
       "      <td>-0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>dsgdb9nsd_000008</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>90.0888</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.522889</td>\n",
       "      <td>1.725552</td>\n",
       "      <td>0.899073</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>1.390470</td>\n",
       "      <td>-0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56</td>\n",
       "      <td>dsgdb9nsd_000009</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>91.4487</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>0.997822</td>\n",
       "      <td>1.874253</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>1.464358</td>\n",
       "      <td>0.010094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>61</td>\n",
       "      <td>dsgdb9nsd_000009</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>91.4554</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.542204</td>\n",
       "      <td>1.858012</td>\n",
       "      <td>-0.867212</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>1.464358</td>\n",
       "      <td>0.010094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "      <td>dsgdb9nsd_000009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>91.4543</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.525333</td>\n",
       "      <td>1.848344</td>\n",
       "      <td>0.901481</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.017821</td>\n",
       "      <td>1.464358</td>\n",
       "      <td>0.010094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70</td>\n",
       "      <td>dsgdb9nsd_000009</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>198.9130</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>0.032317</td>\n",
       "      <td>-2.253148</td>\n",
       "      <td>-0.010260</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>-1.191805</td>\n",
       "      <td>-0.004505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>71</td>\n",
       "      <td>dsgdb9nsd_000010</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>91.6355</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>1.002029</td>\n",
       "      <td>1.860899</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.017886</td>\n",
       "      <td>1.467128</td>\n",
       "      <td>0.010113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>76</td>\n",
       "      <td>dsgdb9nsd_000010</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>91.6216</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.543988</td>\n",
       "      <td>1.844799</td>\n",
       "      <td>-0.870755</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.017886</td>\n",
       "      <td>1.467128</td>\n",
       "      <td>0.010113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0    0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1    4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "2    7  dsgdb9nsd_000001             3             0  1JHC   \n",
       "3    9  dsgdb9nsd_000001             4             0  1JHC   \n",
       "4   17  dsgdb9nsd_000005             2             0  1JHC   \n",
       "5   19  dsgdb9nsd_000007             2             0  1JHC   \n",
       "6   26  dsgdb9nsd_000007             3             0  1JHC   \n",
       "7   32  dsgdb9nsd_000007             4             0  1JHC   \n",
       "8   38  dsgdb9nsd_000007             5             1  1JHC   \n",
       "9   42  dsgdb9nsd_000007             6             1  1JHC   \n",
       "10  45  dsgdb9nsd_000007             7             1  1JHC   \n",
       "11  46  dsgdb9nsd_000008             2             0  1JHC   \n",
       "12  50  dsgdb9nsd_000008             3             0  1JHC   \n",
       "13  53  dsgdb9nsd_000008             4             0  1JHC   \n",
       "14  56  dsgdb9nsd_000009             3             0  1JHC   \n",
       "15  61  dsgdb9nsd_000009             4             0  1JHC   \n",
       "16  65  dsgdb9nsd_000009             5             0  1JHC   \n",
       "17  70  dsgdb9nsd_000009             6             2  1JHC   \n",
       "18  71  dsgdb9nsd_000010             3             0  1JHC   \n",
       "19  76  dsgdb9nsd_000010             4             0  1JHC   \n",
       "\n",
       "    scalar_coupling_constant  atom_index_x atom_x       x_x       y_x  \\\n",
       "0                    84.8076             1      H  0.002150 -0.006031   \n",
       "1                    84.8074             2      H  1.011731  1.463751   \n",
       "2                    84.8093             3      H -0.540815  1.447527   \n",
       "3                    84.8095             4      H -0.523814  1.437933   \n",
       "4                   171.2200             2      H -0.027803  2.198949   \n",
       "5                    83.5429             2      H  0.994873  1.939743   \n",
       "6                    83.5417             3      H -0.542076  1.923611   \n",
       "7                    83.5484             4      H -0.525241  1.914173   \n",
       "8                    83.5418             5      H  0.525487 -0.401908   \n",
       "9                    83.5430             6      H -1.011477 -0.418034   \n",
       "10                   83.5486             7      H  0.508626 -0.392470   \n",
       "11                   87.6326             2      H  1.006583  1.815564   \n",
       "12                   87.6253             3      H -0.546575  1.799170   \n",
       "13                   90.0888             4      H -0.522889  1.725552   \n",
       "14                   91.4487             3      H  0.997822  1.874253   \n",
       "15                   91.4554             4      H -0.542204  1.858012   \n",
       "16                   91.4543             5      H -0.525333  1.848344   \n",
       "17                  198.9130             6      H  0.032317 -2.253148   \n",
       "18                   91.6355             3      H  1.002029  1.860899   \n",
       "19                   91.6216             4      H -0.543988  1.844799   \n",
       "\n",
       "         z_x  atom_index_y atom_y       x_y       y_y       z_y  \n",
       "0   0.001976             0      C -0.012698  1.085804  0.008001  \n",
       "1   0.000277             0      C -0.012698  1.085804  0.008001  \n",
       "2  -0.876644             0      C -0.012698  1.085804  0.008001  \n",
       "3   0.906397             0      C -0.012698  1.085804  0.008001  \n",
       "4   0.014154             0      C -0.013324  1.132466  0.008276  \n",
       "5   0.002941             0      C -0.018704  1.525582  0.010433  \n",
       "6  -0.865117             0      C -0.018704  1.525582  0.010433  \n",
       "7   0.900024             0      C -0.018704  1.525582  0.010433  \n",
       "8   0.877544             1      C  0.002104 -0.003882  0.001999  \n",
       "9   0.009508             1      C  0.002104 -0.003882  0.001999  \n",
       "10 -0.887601             1      C  0.002104 -0.003882  0.001999  \n",
       "11  0.003483             0      C -0.008288  1.390470 -0.005601  \n",
       "12 -0.873901             0      C -0.008288  1.390470 -0.005601  \n",
       "13  0.899073             0      C -0.008288  1.390470 -0.005601  \n",
       "14  0.002606             0      C -0.017821  1.464358  0.010094  \n",
       "15 -0.867212             0      C -0.017821  1.464358  0.010094  \n",
       "16  0.901481             0      C -0.017821  1.464358  0.010094  \n",
       "17 -0.010260             2      C  0.018341 -1.191805 -0.004505  \n",
       "18  0.002454             0      C -0.017886  1.467128  0.010113  \n",
       "19 -0.870755             0      C -0.017886  1.467128  0.010113  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_train_1JHC[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train_1JHC_dropped_cols = loaded_train_1JHC.drop(['atom_index_x','atom_index_y','atom_x','atom_y','type','id','molecule_name','atom_index_0','atom_index_1'], \n",
    "                                                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_x</th>\n",
       "      <th>y_x</th>\n",
       "      <th>z_x</th>\n",
       "      <th>x_y</th>\n",
       "      <th>y_y</th>\n",
       "      <th>z_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.8076</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.8074</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.8093</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.8095</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.2200</td>\n",
       "      <td>-0.027803</td>\n",
       "      <td>2.198949</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>-0.013324</td>\n",
       "      <td>1.132466</td>\n",
       "      <td>0.008276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.5429</td>\n",
       "      <td>0.994873</td>\n",
       "      <td>1.939743</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.5417</td>\n",
       "      <td>-0.542076</td>\n",
       "      <td>1.923611</td>\n",
       "      <td>-0.865117</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.5484</td>\n",
       "      <td>-0.525241</td>\n",
       "      <td>1.914173</td>\n",
       "      <td>0.900024</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>0.010433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83.5418</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>-0.401908</td>\n",
       "      <td>0.877544</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.5430</td>\n",
       "      <td>-1.011477</td>\n",
       "      <td>-0.418034</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scalar_coupling_constant       x_x       y_x       z_x       x_y       y_y  \\\n",
       "0                   84.8076  0.002150 -0.006031  0.001976 -0.012698  1.085804   \n",
       "1                   84.8074  1.011731  1.463751  0.000277 -0.012698  1.085804   \n",
       "2                   84.8093 -0.540815  1.447527 -0.876644 -0.012698  1.085804   \n",
       "3                   84.8095 -0.523814  1.437933  0.906397 -0.012698  1.085804   \n",
       "4                  171.2200 -0.027803  2.198949  0.014154 -0.013324  1.132466   \n",
       "5                   83.5429  0.994873  1.939743  0.002941 -0.018704  1.525582   \n",
       "6                   83.5417 -0.542076  1.923611 -0.865117 -0.018704  1.525582   \n",
       "7                   83.5484 -0.525241  1.914173  0.900024 -0.018704  1.525582   \n",
       "8                   83.5418  0.525487 -0.401908  0.877544  0.002104 -0.003882   \n",
       "9                   83.5430 -1.011477 -0.418034  0.009508  0.002104 -0.003882   \n",
       "\n",
       "        z_y  \n",
       "0  0.008001  \n",
       "1  0.008001  \n",
       "2  0.008001  \n",
       "3  0.008001  \n",
       "4  0.008276  \n",
       "5  0.010433  \n",
       "6  0.010433  \n",
       "7  0.010433  \n",
       "8  0.001999  \n",
       "9  0.001999  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_train_1JHC_dropped_cols[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709416, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_train_1JHC_dropped_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankushhore/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_1JHC_array = loaded_train_1JHC_dropped_cols.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709416, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1JHC_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_1JHC_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1JHC_array_train = train_1JHC_array[:500000]\n",
    "train_1JHC_array_val = train_1JHC_array[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_1JHC_array_train[:,1:]\n",
    "y_train = train_1JHC_array_train[:,0].reshape((500000,1))\n",
    "X_val = train_1JHC_array_val[:,1:]\n",
    "y_val = train_1JHC_array_val[:,0].reshape((209416,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 6) (500000, 1) (209416, 6) (209416, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 6])\n",
    "y = tf.placeholder(tf.float32)\n",
    "training_flag = 1\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(batch_size).repeat()\n",
    "iter = dataset.make_initializable_iterator()\n",
    "features, labels = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cnn\"):\n",
    "    X1 = tf.layers.dense(features, 80, activation = 'relu')\n",
    "    X2 = tf.layers.dropout(X1, rate=0.5)\n",
    "    X3 = tf.layers.dense(X2, 40, activation = 'relu')\n",
    "    X4 = tf.layers.dropout(X3, rate=0.5)\n",
    "    X5 = tf.layers.dense(X4, 20, activation = 'relu')\n",
    "    X6 = tf.layers.dropout(X5, rate=0.5)\n",
    "    X7 = tf.layers.dense(X6, 10, activation = 'relu')\n",
    "    X8 = tf.layers.dropout(X7, rate=0.5)\n",
    "    output = tf.layers.dense(X8, 1, activation = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    l2_loss = tf.losses.mean_squared_error(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ankushhore/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    training_op = tf.train.AdamOptimizer().minimize(l2_loss)\n",
    "    #training_op = optimizer.minimize(l2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"estimated_MAE\"):\n",
    "    MAE_hat = tf.math.reduce_mean(tf.metrics.mean_absolute_error(labels, output))\n",
    "    log_MAE_hat = tf.math.log(MAE_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = len(X_train)\n",
    "n_batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Iter: 0, Loss: 9375.6572, Train MAE hat: 3.8616\n",
      "Iter: 1, Loss: 9363.0010, Train MAE hat: 4.5546\n",
      "Iter: 2, Loss: 9351.1475, Train MAE hat: 4.5543\n",
      "Iter: 3, Loss: 9340.1396, Train MAE hat: 4.5539\n",
      "Iter: 4, Loss: 9330.1289, Train MAE hat: 4.5536\n",
      "Iter: 5, Loss: 9320.8945, Train MAE hat: 4.5533\n",
      "Iter: 6, Loss: 9312.0166, Train MAE hat: 4.5531\n",
      "Iter: 7, Loss: 9303.2217, Train MAE hat: 4.5528\n",
      "Iter: 8, Loss: 9294.4258, Train MAE hat: 4.5525\n",
      "Iter: 9, Loss: 9285.5469, Train MAE hat: 4.5523\n",
      "Iter: 10, Loss: 9276.4893, Train MAE hat: 4.5520\n",
      "Iter: 11, Loss: 9267.1689, Train MAE hat: 4.5518\n",
      "Iter: 12, Loss: 9257.4697, Train MAE hat: 4.5515\n",
      "Iter: 13, Loss: 9247.2461, Train MAE hat: 4.5513\n",
      "Iter: 14, Loss: 9236.3838, Train MAE hat: 4.5510\n",
      "Iter: 15, Loss: 9224.7627, Train MAE hat: 4.5507\n",
      "Iter: 16, Loss: 9212.2412, Train MAE hat: 4.5504\n",
      "Iter: 17, Loss: 9198.7188, Train MAE hat: 4.5502\n",
      "Iter: 18, Loss: 9184.0938, Train MAE hat: 4.5499\n",
      "Iter: 19, Loss: 9168.2881, Train MAE hat: 4.5496\n",
      "Iter: 20, Loss: 9151.1973, Train MAE hat: 4.5492\n",
      "Iter: 21, Loss: 9132.6260, Train MAE hat: 4.5489\n",
      "Iter: 22, Loss: 9112.3838, Train MAE hat: 4.5485\n",
      "Iter: 23, Loss: 9090.3760, Train MAE hat: 4.5482\n",
      "Iter: 24, Loss: 9066.5391, Train MAE hat: 4.5478\n",
      "Iter: 25, Loss: 9040.8623, Train MAE hat: 4.5473\n",
      "Iter: 26, Loss: 9013.2842, Train MAE hat: 4.5469\n",
      "Iter: 27, Loss: 8983.6758, Train MAE hat: 4.5464\n",
      "Iter: 28, Loss: 8951.8857, Train MAE hat: 4.5459\n",
      "Iter: 29, Loss: 8917.8340, Train MAE hat: 4.5454\n",
      "Iter: 30, Loss: 8881.3994, Train MAE hat: 4.5448\n",
      "Iter: 31, Loss: 8842.4551, Train MAE hat: 4.5442\n",
      "Iter: 32, Loss: 8800.8213, Train MAE hat: 4.5436\n",
      "Iter: 33, Loss: 8756.2734, Train MAE hat: 4.5429\n",
      "Iter: 34, Loss: 8708.6104, Train MAE hat: 4.5422\n",
      "Iter: 35, Loss: 8657.6328, Train MAE hat: 4.5415\n",
      "Iter: 36, Loss: 8603.2920, Train MAE hat: 4.5407\n",
      "Iter: 37, Loss: 8545.4658, Train MAE hat: 4.5399\n",
      "Iter: 38, Loss: 8483.9258, Train MAE hat: 4.5390\n",
      "Iter: 39, Loss: 8418.4355, Train MAE hat: 4.5381\n",
      "Iter: 40, Loss: 8348.8262, Train MAE hat: 4.5371\n",
      "Iter: 41, Loss: 8274.9033, Train MAE hat: 4.5360\n",
      "Iter: 42, Loss: 8196.4258, Train MAE hat: 4.5349\n",
      "Iter: 43, Loss: 8113.1060, Train MAE hat: 4.5338\n",
      "Iter: 44, Loss: 8024.6743, Train MAE hat: 4.5325\n",
      "Iter: 45, Loss: 7930.9136, Train MAE hat: 4.5313\n",
      "Iter: 46, Loss: 7831.6484, Train MAE hat: 4.5299\n",
      "Iter: 47, Loss: 7726.7026, Train MAE hat: 4.5284\n",
      "Iter: 48, Loss: 7615.8608, Train MAE hat: 4.5269\n",
      "Iter: 49, Loss: 7498.7959, Train MAE hat: 4.5253\n",
      "Iter: 50, Loss: 7375.2476, Train MAE hat: 4.5236\n",
      "Iter: 51, Loss: 7245.1274, Train MAE hat: 4.5218\n",
      "Iter: 52, Loss: 7108.2427, Train MAE hat: 4.5199\n",
      "Iter: 53, Loss: 6964.4814, Train MAE hat: 4.5179\n",
      "Iter: 54, Loss: 6813.7896, Train MAE hat: 4.5158\n",
      "Iter: 55, Loss: 6656.1436, Train MAE hat: 4.5135\n",
      "Iter: 56, Loss: 6491.5186, Train MAE hat: 4.5112\n",
      "Iter: 57, Loss: 6319.9214, Train MAE hat: 4.5087\n",
      "Iter: 58, Loss: 6141.4155, Train MAE hat: 4.5061\n",
      "Iter: 59, Loss: 5956.1016, Train MAE hat: 4.5033\n",
      "Iter: 60, Loss: 5764.1440, Train MAE hat: 4.5004\n",
      "Iter: 61, Loss: 5565.7646, Train MAE hat: 4.4973\n",
      "Iter: 62, Loss: 5361.2651, Train MAE hat: 4.4940\n",
      "Iter: 63, Loss: 5151.0215, Train MAE hat: 4.4906\n",
      "Iter: 64, Loss: 4935.4839, Train MAE hat: 4.4870\n",
      "Iter: 65, Loss: 4715.2935, Train MAE hat: 4.4832\n",
      "Iter: 66, Loss: 4491.2168, Train MAE hat: 4.4792\n",
      "Iter: 67, Loss: 4264.1870, Train MAE hat: 4.4749\n",
      "Iter: 68, Loss: 4035.2153, Train MAE hat: 4.4705\n",
      "Iter: 69, Loss: 3805.5215, Train MAE hat: 4.4658\n",
      "Iter: 70, Loss: 3576.3992, Train MAE hat: 4.4609\n",
      "Iter: 71, Loss: 3349.3064, Train MAE hat: 4.4558\n",
      "Iter: 72, Loss: 3125.9978, Train MAE hat: 4.4504\n",
      "Iter: 73, Loss: 2908.3416, Train MAE hat: 4.4448\n",
      "Iter: 74, Loss: 2698.3345, Train MAE hat: 4.4389\n",
      "Iter: 75, Loss: 2498.0793, Train MAE hat: 4.4328\n",
      "Iter: 76, Loss: 2309.6760, Train MAE hat: 4.4265\n",
      "Iter: 77, Loss: 2135.0005, Train MAE hat: 4.4200\n",
      "Iter: 78, Loss: 1976.0193, Train MAE hat: 4.4133\n",
      "Iter: 79, Loss: 1835.1735, Train MAE hat: 4.4065\n",
      "Iter: 80, Loss: 1713.9847, Train MAE hat: 4.3996\n",
      "Iter: 81, Loss: 1613.3276, Train MAE hat: 4.3925\n",
      "Iter: 82, Loss: 1533.4143, Train MAE hat: 4.3854\n",
      "Iter: 83, Loss: 1473.5878, Train MAE hat: 4.3783\n",
      "Iter: 84, Loss: 1432.2363, Train MAE hat: 4.3712\n",
      "Iter: 85, Loss: 1406.8203, Train MAE hat: 4.3641\n",
      "Iter: 86, Loss: 1394.1091, Train MAE hat: 4.3571\n",
      "Iter: 87, Loss: 1390.3916, Train MAE hat: 4.3502\n",
      "Iter: 88, Loss: 1391.8068, Train MAE hat: 4.3433\n",
      "Iter: 89, Loss: 1394.7239, Train MAE hat: 4.3365\n",
      "Iter: 90, Loss: 1396.0861, Train MAE hat: 4.3298\n",
      "Iter: 91, Loss: 1393.6536, Train MAE hat: 4.3232\n",
      "Iter: 92, Loss: 1386.1163, Train MAE hat: 4.3166\n",
      "Iter: 93, Loss: 1373.0706, Train MAE hat: 4.3101\n",
      "Iter: 94, Loss: 1354.8822, Train MAE hat: 4.3037\n",
      "Iter: 95, Loss: 1332.4817, Train MAE hat: 4.2973\n",
      "Iter: 96, Loss: 1307.1462, Train MAE hat: 4.2910\n",
      "Iter: 97, Loss: 1280.2819, Train MAE hat: 4.2847\n",
      "Iter: 98, Loss: 1253.2493, Train MAE hat: 4.2784\n",
      "Iter: 99, Loss: 1227.2347, Train MAE hat: 4.2722\n",
      "Iter: 100, Loss: 1203.1725, Train MAE hat: 4.2661\n",
      "Iter: 101, Loss: 1181.7107, Train MAE hat: 4.2600\n",
      "Iter: 102, Loss: 1163.2115, Train MAE hat: 4.2539\n",
      "Iter: 103, Loss: 1147.7814, Train MAE hat: 4.2479\n",
      "Iter: 104, Loss: 1135.3125, Train MAE hat: 4.2420\n",
      "Iter: 105, Loss: 1125.5382, Train MAE hat: 4.2361\n",
      "Iter: 106, Loss: 1118.0840, Train MAE hat: 4.2303\n",
      "Iter: 107, Loss: 1112.5186, Train MAE hat: 4.2246\n",
      "Iter: 108, Loss: 1108.3938, Train MAE hat: 4.2190\n",
      "Iter: 109, Loss: 1105.2791, Train MAE hat: 4.2134\n",
      "Iter: 110, Loss: 1102.7865, Train MAE hat: 4.2078\n",
      "Iter: 111, Loss: 1100.5851, Train MAE hat: 4.2024\n",
      "Iter: 112, Loss: 1098.4095, Train MAE hat: 4.1970\n",
      "Iter: 113, Loss: 1096.0625, Train MAE hat: 4.1917\n",
      "Iter: 114, Loss: 1093.4116, Train MAE hat: 4.1864\n",
      "Iter: 115, Loss: 1090.3838, Train MAE hat: 4.1812\n",
      "Iter: 116, Loss: 1086.9570, Train MAE hat: 4.1761\n",
      "Iter: 117, Loss: 1083.1499, Train MAE hat: 4.1710\n",
      "Iter: 118, Loss: 1079.0128, Train MAE hat: 4.1659\n",
      "Iter: 119, Loss: 1074.6155, Train MAE hat: 4.1609\n",
      "Iter: 120, Loss: 1070.0396, Train MAE hat: 4.1560\n",
      "Iter: 121, Loss: 1065.3691, Train MAE hat: 4.1511\n",
      "Iter: 122, Loss: 1060.6848, Train MAE hat: 4.1462\n",
      "Iter: 123, Loss: 1056.0573, Train MAE hat: 4.1414\n",
      "Iter: 124, Loss: 1051.5435, Train MAE hat: 4.1366\n",
      "Iter: 125, Loss: 1047.1849, Train MAE hat: 4.1319\n",
      "Iter: 126, Loss: 1043.0062, Train MAE hat: 4.1272\n",
      "Iter: 127, Loss: 1039.0168, Train MAE hat: 4.1225\n",
      "Iter: 128, Loss: 1035.2114, Train MAE hat: 4.1179\n",
      "Iter: 129, Loss: 1031.5741, Train MAE hat: 4.1133\n",
      "Iter: 130, Loss: 1028.0803, Train MAE hat: 4.1088\n",
      "Iter: 131, Loss: 1024.7009, Train MAE hat: 4.1043\n",
      "Iter: 132, Loss: 1021.4049, Train MAE hat: 4.0999\n",
      "Iter: 133, Loss: 1018.1632, Train MAE hat: 4.0955\n",
      "Iter: 134, Loss: 1014.9500, Train MAE hat: 4.0911\n",
      "Iter: 135, Loss: 1011.7443, Train MAE hat: 4.0868\n",
      "Iter: 136, Loss: 1008.5317, Train MAE hat: 4.0825\n",
      "Iter: 137, Loss: 1005.3044, Train MAE hat: 4.0782\n",
      "Iter: 138, Loss: 1002.0605, Train MAE hat: 4.0740\n",
      "Iter: 139, Loss: 998.8028, Train MAE hat: 4.0698\n",
      "Iter: 140, Loss: 995.5386, Train MAE hat: 4.0657\n",
      "Iter: 141, Loss: 992.2766, Train MAE hat: 4.0616\n",
      "Iter: 142, Loss: 989.0268, Train MAE hat: 4.0575\n",
      "Iter: 143, Loss: 985.7996, Train MAE hat: 4.0535\n",
      "Iter: 144, Loss: 982.6029, Train MAE hat: 4.0495\n",
      "Iter: 145, Loss: 979.4431, Train MAE hat: 4.0456\n",
      "Iter: 146, Loss: 976.3242, Train MAE hat: 4.0417\n",
      "Iter: 147, Loss: 973.2479, Train MAE hat: 4.0378\n",
      "Iter: 148, Loss: 970.2131, Train MAE hat: 4.0340\n",
      "Iter: 149, Loss: 967.2175, Train MAE hat: 4.0301\n",
      "Iter: 150, Loss: 964.2564, Train MAE hat: 4.0264\n",
      "Iter: 151, Loss: 961.3243, Train MAE hat: 4.0226\n",
      "Iter: 152, Loss: 958.4156, Train MAE hat: 4.0189\n",
      "Iter: 153, Loss: 955.5248, Train MAE hat: 4.0152\n",
      "Iter: 154, Loss: 952.6459, Train MAE hat: 4.0116\n",
      "Iter: 155, Loss: 949.7742, Train MAE hat: 4.0080\n",
      "Iter: 156, Loss: 946.9055, Train MAE hat: 4.0044\n",
      "Iter: 157, Loss: 944.0380, Train MAE hat: 4.0008\n",
      "Iter: 158, Loss: 941.1691, Train MAE hat: 3.9973\n",
      "Iter: 159, Loss: 938.2980, Train MAE hat: 3.9938\n",
      "Iter: 160, Loss: 935.4248, Train MAE hat: 3.9903\n",
      "Iter: 161, Loss: 932.5500, Train MAE hat: 3.9868\n",
      "Iter: 162, Loss: 929.6747, Train MAE hat: 3.9834\n",
      "Iter: 163, Loss: 926.7995, Train MAE hat: 3.9800\n",
      "Iter: 164, Loss: 923.9257, Train MAE hat: 3.9766\n",
      "Iter: 165, Loss: 921.0538, Train MAE hat: 3.9733\n",
      "Iter: 166, Loss: 918.1849, Train MAE hat: 3.9699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 167, Loss: 915.3192, Train MAE hat: 3.9666\n",
      "Iter: 168, Loss: 912.4571, Train MAE hat: 3.9633\n",
      "Iter: 169, Loss: 909.5982, Train MAE hat: 3.9601\n",
      "Iter: 170, Loss: 906.7426, Train MAE hat: 3.9568\n",
      "Iter: 171, Loss: 903.8891, Train MAE hat: 3.9536\n",
      "Iter: 172, Loss: 901.0373, Train MAE hat: 3.9504\n",
      "Iter: 173, Loss: 898.1863, Train MAE hat: 3.9472\n",
      "Iter: 174, Loss: 895.3358, Train MAE hat: 3.9441\n",
      "Iter: 175, Loss: 892.4851, Train MAE hat: 3.9409\n",
      "Iter: 176, Loss: 889.6337, Train MAE hat: 3.9378\n",
      "Iter: 177, Loss: 886.7809, Train MAE hat: 3.9347\n",
      "Iter: 178, Loss: 883.9268, Train MAE hat: 3.9317\n",
      "Iter: 179, Loss: 881.0710, Train MAE hat: 3.9286\n",
      "Iter: 180, Loss: 878.2135, Train MAE hat: 3.9256\n",
      "Iter: 181, Loss: 875.3542, Train MAE hat: 3.9226\n",
      "Iter: 182, Loss: 872.4937, Train MAE hat: 3.9196\n",
      "Iter: 183, Loss: 869.6315, Train MAE hat: 3.9166\n",
      "Iter: 184, Loss: 866.7679, Train MAE hat: 3.9136\n",
      "Iter: 185, Loss: 863.9027, Train MAE hat: 3.9107\n",
      "Iter: 186, Loss: 861.0358, Train MAE hat: 3.9078\n",
      "Iter: 187, Loss: 858.1675, Train MAE hat: 3.9049\n",
      "Iter: 188, Loss: 855.2978, Train MAE hat: 3.9020\n",
      "Iter: 189, Loss: 852.4266, Train MAE hat: 3.8991\n",
      "Iter: 190, Loss: 849.5534, Train MAE hat: 3.8963\n",
      "Iter: 191, Loss: 846.6784, Train MAE hat: 3.8935\n",
      "Iter: 192, Loss: 843.8016, Train MAE hat: 3.8906\n",
      "Iter: 193, Loss: 840.9226, Train MAE hat: 3.8878\n",
      "Iter: 194, Loss: 838.0416, Train MAE hat: 3.8851\n",
      "Iter: 195, Loss: 835.1583, Train MAE hat: 3.8823\n",
      "Iter: 196, Loss: 832.2731, Train MAE hat: 3.8795\n",
      "Iter: 197, Loss: 829.3853, Train MAE hat: 3.8768\n",
      "Iter: 198, Loss: 826.4951, Train MAE hat: 3.8741\n",
      "Iter: 199, Loss: 823.6027, Train MAE hat: 3.8714\n",
      "Iter: 200, Loss: 820.7079, Train MAE hat: 3.8687\n",
      "Iter: 201, Loss: 817.8105, Train MAE hat: 3.8660\n",
      "Iter: 202, Loss: 814.9106, Train MAE hat: 3.8633\n",
      "Iter: 203, Loss: 812.0077, Train MAE hat: 3.8607\n",
      "Iter: 204, Loss: 809.1018, Train MAE hat: 3.8581\n",
      "Iter: 205, Loss: 806.1925, Train MAE hat: 3.8554\n",
      "Iter: 206, Loss: 803.2795, Train MAE hat: 3.8528\n",
      "Iter: 207, Loss: 800.3627, Train MAE hat: 3.8503\n",
      "Iter: 208, Loss: 797.4425, Train MAE hat: 3.8477\n",
      "Iter: 209, Loss: 794.5198, Train MAE hat: 3.8451\n",
      "Iter: 210, Loss: 791.5951, Train MAE hat: 3.8426\n",
      "Iter: 211, Loss: 788.6680, Train MAE hat: 3.8400\n",
      "Iter: 212, Loss: 785.7397, Train MAE hat: 3.8375\n",
      "Iter: 213, Loss: 782.8104, Train MAE hat: 3.8350\n",
      "Iter: 214, Loss: 779.8807, Train MAE hat: 3.8325\n",
      "Iter: 215, Loss: 776.9499, Train MAE hat: 3.8300\n",
      "Iter: 216, Loss: 774.0179, Train MAE hat: 3.8275\n",
      "Iter: 217, Loss: 771.0841, Train MAE hat: 3.8250\n",
      "Iter: 218, Loss: 768.1476, Train MAE hat: 3.8226\n",
      "Iter: 219, Loss: 765.2112, Train MAE hat: 3.8201\n",
      "Iter: 220, Loss: 762.2753, Train MAE hat: 3.8177\n",
      "Iter: 221, Loss: 759.3402, Train MAE hat: 3.8153\n",
      "Iter: 222, Loss: 756.4059, Train MAE hat: 3.8129\n",
      "Iter: 223, Loss: 753.4725, Train MAE hat: 3.8105\n",
      "Iter: 224, Loss: 750.5397, Train MAE hat: 3.8081\n",
      "Iter: 225, Loss: 747.6075, Train MAE hat: 3.8057\n",
      "Iter: 226, Loss: 744.6757, Train MAE hat: 3.8033\n",
      "Iter: 227, Loss: 741.7441, Train MAE hat: 3.8010\n",
      "Iter: 228, Loss: 738.8122, Train MAE hat: 3.7986\n",
      "Iter: 229, Loss: 735.8805, Train MAE hat: 3.7963\n",
      "Iter: 230, Loss: 732.9490, Train MAE hat: 3.7940\n",
      "Iter: 231, Loss: 730.0175, Train MAE hat: 3.7917\n",
      "Iter: 232, Loss: 727.0862, Train MAE hat: 3.7894\n",
      "Iter: 233, Loss: 724.1556, Train MAE hat: 3.7871\n",
      "Iter: 234, Loss: 721.2256, Train MAE hat: 3.7848\n",
      "Iter: 235, Loss: 718.2961, Train MAE hat: 3.7825\n",
      "Iter: 236, Loss: 715.3675, Train MAE hat: 3.7802\n",
      "Iter: 237, Loss: 712.4396, Train MAE hat: 3.7780\n",
      "Iter: 238, Loss: 709.5127, Train MAE hat: 3.7757\n",
      "Iter: 239, Loss: 706.5865, Train MAE hat: 3.7735\n",
      "Iter: 240, Loss: 703.6615, Train MAE hat: 3.7712\n",
      "Iter: 241, Loss: 700.7377, Train MAE hat: 3.7690\n",
      "Iter: 242, Loss: 697.8151, Train MAE hat: 3.7668\n",
      "Iter: 243, Loss: 694.8937, Train MAE hat: 3.7646\n",
      "Iter: 244, Loss: 691.9739, Train MAE hat: 3.7624\n",
      "Iter: 245, Loss: 689.0554, Train MAE hat: 3.7602\n",
      "Iter: 246, Loss: 686.1385, Train MAE hat: 3.7580\n",
      "Iter: 247, Loss: 683.2230, Train MAE hat: 3.7558\n",
      "Iter: 248, Loss: 680.3094, Train MAE hat: 3.7537\n",
      "Iter: 249, Loss: 677.3975, Train MAE hat: 3.7515\n",
      "Iter: 250, Loss: 674.4871, Train MAE hat: 3.7494\n",
      "Iter: 251, Loss: 671.5786, Train MAE hat: 3.7472\n",
      "Iter: 252, Loss: 668.6720, Train MAE hat: 3.7451\n",
      "Iter: 253, Loss: 665.7677, Train MAE hat: 3.7430\n",
      "Iter: 254, Loss: 662.8656, Train MAE hat: 3.7408\n",
      "Iter: 255, Loss: 659.9658, Train MAE hat: 3.7387\n",
      "Iter: 256, Loss: 657.0685, Train MAE hat: 3.7366\n",
      "Iter: 257, Loss: 654.1740, Train MAE hat: 3.7345\n",
      "Iter: 258, Loss: 651.2819, Train MAE hat: 3.7324\n",
      "Iter: 259, Loss: 648.3927, Train MAE hat: 3.7303\n",
      "Iter: 260, Loss: 645.5064, Train MAE hat: 3.7283\n",
      "Iter: 261, Loss: 642.6234, Train MAE hat: 3.7262\n",
      "Iter: 262, Loss: 639.7432, Train MAE hat: 3.7241\n",
      "Iter: 263, Loss: 636.8661, Train MAE hat: 3.7221\n",
      "Iter: 264, Loss: 633.9927, Train MAE hat: 3.7200\n",
      "Iter: 265, Loss: 631.1227, Train MAE hat: 3.7180\n",
      "Iter: 266, Loss: 628.2564, Train MAE hat: 3.7159\n",
      "Iter: 267, Loss: 625.3938, Train MAE hat: 3.7139\n",
      "Iter: 268, Loss: 622.5349, Train MAE hat: 3.7119\n",
      "Iter: 269, Loss: 619.6802, Train MAE hat: 3.7098\n",
      "Iter: 270, Loss: 616.8297, Train MAE hat: 3.7078\n",
      "Iter: 271, Loss: 613.9835, Train MAE hat: 3.7058\n",
      "Iter: 272, Loss: 611.1415, Train MAE hat: 3.7038\n",
      "Iter: 273, Loss: 608.3041, Train MAE hat: 3.7018\n",
      "Iter: 274, Loss: 605.4709, Train MAE hat: 3.6998\n",
      "Iter: 275, Loss: 602.6426, Train MAE hat: 3.6978\n",
      "Iter: 276, Loss: 599.8193, Train MAE hat: 3.6958\n",
      "Iter: 277, Loss: 597.0010, Train MAE hat: 3.6939\n",
      "Iter: 278, Loss: 594.1879, Train MAE hat: 3.6919\n",
      "Iter: 279, Loss: 591.3802, Train MAE hat: 3.6899\n",
      "Iter: 280, Loss: 588.5781, Train MAE hat: 3.6880\n",
      "Iter: 281, Loss: 585.7817, Train MAE hat: 3.6860\n",
      "Iter: 282, Loss: 582.9917, Train MAE hat: 3.6841\n",
      "Iter: 283, Loss: 580.2083, Train MAE hat: 3.6821\n",
      "Iter: 284, Loss: 577.4316, Train MAE hat: 3.6802\n",
      "Iter: 285, Loss: 574.6616, Train MAE hat: 3.6782\n",
      "Iter: 286, Loss: 571.8984, Train MAE hat: 3.6763\n",
      "Iter: 287, Loss: 569.1420, Train MAE hat: 3.6744\n",
      "Iter: 288, Loss: 566.3926, Train MAE hat: 3.6725\n",
      "Iter: 289, Loss: 563.6500, Train MAE hat: 3.6706\n",
      "Iter: 290, Loss: 560.9149, Train MAE hat: 3.6686\n",
      "Iter: 291, Loss: 558.1877, Train MAE hat: 3.6667\n",
      "Iter: 292, Loss: 555.4689, Train MAE hat: 3.6648\n",
      "Iter: 293, Loss: 552.7593, Train MAE hat: 3.6629\n",
      "Iter: 294, Loss: 550.0596, Train MAE hat: 3.6610\n",
      "Iter: 295, Loss: 547.3702, Train MAE hat: 3.6592\n",
      "Iter: 296, Loss: 544.6915, Train MAE hat: 3.6573\n",
      "Iter: 297, Loss: 542.0237, Train MAE hat: 3.6554\n",
      "Iter: 298, Loss: 539.3669, Train MAE hat: 3.6535\n",
      "Iter: 299, Loss: 536.7220, Train MAE hat: 3.6516\n",
      "Iter: 300, Loss: 534.0897, Train MAE hat: 3.6498\n",
      "Iter: 301, Loss: 531.4706, Train MAE hat: 3.6479\n",
      "Iter: 302, Loss: 528.8652, Train MAE hat: 3.6461\n",
      "Iter: 303, Loss: 526.2741, Train MAE hat: 3.6442\n",
      "Iter: 304, Loss: 523.6970, Train MAE hat: 3.6424\n",
      "Iter: 305, Loss: 521.1346, Train MAE hat: 3.6405\n",
      "Iter: 306, Loss: 518.5872, Train MAE hat: 3.6387\n",
      "Iter: 307, Loss: 516.0551, Train MAE hat: 3.6368\n",
      "Iter: 308, Loss: 513.5388, Train MAE hat: 3.6350\n",
      "Iter: 309, Loss: 511.0388, Train MAE hat: 3.6332\n",
      "Iter: 310, Loss: 508.5557, Train MAE hat: 3.6313\n",
      "Iter: 311, Loss: 506.0900, Train MAE hat: 3.6295\n",
      "Iter: 312, Loss: 503.6419, Train MAE hat: 3.6277\n",
      "Iter: 313, Loss: 501.2122, Train MAE hat: 3.6259\n",
      "Iter: 314, Loss: 498.8008, Train MAE hat: 3.6241\n",
      "Iter: 315, Loss: 496.4080, Train MAE hat: 3.6223\n",
      "Iter: 316, Loss: 494.0342, Train MAE hat: 3.6205\n",
      "Iter: 317, Loss: 491.6796, Train MAE hat: 3.6187\n",
      "Iter: 318, Loss: 489.3438, Train MAE hat: 3.6169\n",
      "Iter: 319, Loss: 487.0268, Train MAE hat: 3.6151\n",
      "Iter: 320, Loss: 484.7285, Train MAE hat: 3.6133\n",
      "Iter: 321, Loss: 482.4490, Train MAE hat: 3.6115\n",
      "Iter: 322, Loss: 480.1884, Train MAE hat: 3.6097\n",
      "Iter: 323, Loss: 477.9464, Train MAE hat: 3.6079\n",
      "Iter: 324, Loss: 475.7228, Train MAE hat: 3.6062\n",
      "Iter: 325, Loss: 473.5173, Train MAE hat: 3.6044\n",
      "Iter: 326, Loss: 471.3300, Train MAE hat: 3.6026\n",
      "Iter: 327, Loss: 469.1607, Train MAE hat: 3.6009\n",
      "Iter: 328, Loss: 467.0093, Train MAE hat: 3.5991\n",
      "Iter: 329, Loss: 464.8757, Train MAE hat: 3.5974\n",
      "Iter: 330, Loss: 462.7599, Train MAE hat: 3.5956\n",
      "Iter: 331, Loss: 460.6620, Train MAE hat: 3.5939\n",
      "Iter: 332, Loss: 458.5817, Train MAE hat: 3.5921\n",
      "Iter: 333, Loss: 456.5190, Train MAE hat: 3.5904\n",
      "Iter: 334, Loss: 454.4742, Train MAE hat: 3.5886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 335, Loss: 452.4472, Train MAE hat: 3.5869\n",
      "Iter: 336, Loss: 450.4379, Train MAE hat: 3.5852\n",
      "Iter: 337, Loss: 448.4464, Train MAE hat: 3.5834\n",
      "Iter: 338, Loss: 446.4727, Train MAE hat: 3.5817\n",
      "Iter: 339, Loss: 444.5171, Train MAE hat: 3.5800\n",
      "Iter: 340, Loss: 442.5793, Train MAE hat: 3.5783\n",
      "Iter: 341, Loss: 440.6595, Train MAE hat: 3.5766\n",
      "Iter: 342, Loss: 438.7573, Train MAE hat: 3.5749\n",
      "Iter: 343, Loss: 436.8733, Train MAE hat: 3.5732\n",
      "Iter: 344, Loss: 435.0071, Train MAE hat: 3.5715\n",
      "Iter: 345, Loss: 433.1592, Train MAE hat: 3.5698\n",
      "Iter: 346, Loss: 431.3293, Train MAE hat: 3.5681\n",
      "Iter: 347, Loss: 429.5170, Train MAE hat: 3.5664\n",
      "Iter: 348, Loss: 427.7227, Train MAE hat: 3.5647\n",
      "Iter: 349, Loss: 425.9461, Train MAE hat: 3.5630\n",
      "Iter: 350, Loss: 424.1877, Train MAE hat: 3.5613\n",
      "Iter: 351, Loss: 422.4472, Train MAE hat: 3.5597\n",
      "Iter: 352, Loss: 420.7247, Train MAE hat: 3.5580\n",
      "Iter: 353, Loss: 419.0201, Train MAE hat: 3.5563\n",
      "Iter: 354, Loss: 417.3335, Train MAE hat: 3.5546\n",
      "Iter: 355, Loss: 415.6649, Train MAE hat: 3.5530\n",
      "Iter: 356, Loss: 414.0142, Train MAE hat: 3.5513\n",
      "Iter: 357, Loss: 412.3810, Train MAE hat: 3.5497\n",
      "Iter: 358, Loss: 410.7657, Train MAE hat: 3.5480\n",
      "Iter: 359, Loss: 409.1678, Train MAE hat: 3.5464\n",
      "Iter: 360, Loss: 407.5871, Train MAE hat: 3.5447\n",
      "Iter: 361, Loss: 406.0234, Train MAE hat: 3.5431\n",
      "Iter: 362, Loss: 404.4767, Train MAE hat: 3.5414\n",
      "Iter: 363, Loss: 402.9471, Train MAE hat: 3.5398\n",
      "Iter: 364, Loss: 401.4343, Train MAE hat: 3.5382\n",
      "Iter: 365, Loss: 399.9379, Train MAE hat: 3.5365\n",
      "Iter: 366, Loss: 398.4578, Train MAE hat: 3.5349\n",
      "Iter: 367, Loss: 396.9940, Train MAE hat: 3.5333\n",
      "Iter: 368, Loss: 395.5466, Train MAE hat: 3.5317\n",
      "Iter: 369, Loss: 394.1152, Train MAE hat: 3.5301\n",
      "Iter: 370, Loss: 392.6996, Train MAE hat: 3.5285\n",
      "Iter: 371, Loss: 391.3001, Train MAE hat: 3.5269\n",
      "Iter: 372, Loss: 389.9164, Train MAE hat: 3.5253\n",
      "Iter: 373, Loss: 388.5488, Train MAE hat: 3.5237\n",
      "Iter: 374, Loss: 387.1971, Train MAE hat: 3.5221\n",
      "Iter: 375, Loss: 385.8607, Train MAE hat: 3.5205\n",
      "Iter: 376, Loss: 384.5394, Train MAE hat: 3.5189\n",
      "Iter: 377, Loss: 383.2332, Train MAE hat: 3.5173\n",
      "Iter: 378, Loss: 381.9423, Train MAE hat: 3.5157\n",
      "Iter: 379, Loss: 380.6666, Train MAE hat: 3.5141\n",
      "Iter: 380, Loss: 379.4060, Train MAE hat: 3.5126\n",
      "Iter: 381, Loss: 378.1611, Train MAE hat: 3.5110\n",
      "Iter: 382, Loss: 376.9323, Train MAE hat: 3.5094\n",
      "Iter: 383, Loss: 375.7198, Train MAE hat: 3.5078\n",
      "Iter: 384, Loss: 374.5235, Train MAE hat: 3.5063\n",
      "Iter: 385, Loss: 373.3432, Train MAE hat: 3.5047\n",
      "Iter: 386, Loss: 372.1785, Train MAE hat: 3.5032\n",
      "Iter: 387, Loss: 371.0289, Train MAE hat: 3.5016\n",
      "Iter: 388, Loss: 369.8945, Train MAE hat: 3.5001\n",
      "Iter: 389, Loss: 368.7755, Train MAE hat: 3.4985\n",
      "Iter: 390, Loss: 367.6715, Train MAE hat: 3.4970\n",
      "Iter: 391, Loss: 366.5826, Train MAE hat: 3.4955\n",
      "Iter: 392, Loss: 365.5082, Train MAE hat: 3.4939\n",
      "Iter: 393, Loss: 364.4484, Train MAE hat: 3.4924\n",
      "Iter: 394, Loss: 363.4032, Train MAE hat: 3.4909\n",
      "Iter: 395, Loss: 362.3726, Train MAE hat: 3.4893\n",
      "Iter: 396, Loss: 361.3563, Train MAE hat: 3.4878\n",
      "Iter: 397, Loss: 360.3540, Train MAE hat: 3.4863\n",
      "Iter: 398, Loss: 359.3656, Train MAE hat: 3.4848\n",
      "Iter: 399, Loss: 358.3905, Train MAE hat: 3.4833\n",
      "Iter: 400, Loss: 357.4281, Train MAE hat: 3.4818\n",
      "Iter: 401, Loss: 356.4786, Train MAE hat: 3.4803\n",
      "Iter: 402, Loss: 355.5422, Train MAE hat: 3.4788\n",
      "Iter: 403, Loss: 354.6189, Train MAE hat: 3.4773\n",
      "Iter: 404, Loss: 353.7088, Train MAE hat: 3.4758\n",
      "Iter: 405, Loss: 352.8115, Train MAE hat: 3.4743\n",
      "Iter: 406, Loss: 351.9266, Train MAE hat: 3.4728\n",
      "Iter: 407, Loss: 351.0543, Train MAE hat: 3.4713\n",
      "Iter: 408, Loss: 350.1942, Train MAE hat: 3.4699\n",
      "Iter: 409, Loss: 349.3464, Train MAE hat: 3.4684\n",
      "Iter: 410, Loss: 348.5109, Train MAE hat: 3.4669\n",
      "Iter: 411, Loss: 347.6877, Train MAE hat: 3.4655\n",
      "Iter: 412, Loss: 346.8768, Train MAE hat: 3.4640\n",
      "Iter: 413, Loss: 346.0776, Train MAE hat: 3.4625\n",
      "Iter: 414, Loss: 345.2898, Train MAE hat: 3.4611\n",
      "Iter: 415, Loss: 344.5131, Train MAE hat: 3.4596\n",
      "Iter: 416, Loss: 343.7473, Train MAE hat: 3.4582\n",
      "Iter: 417, Loss: 342.9922, Train MAE hat: 3.4567\n",
      "Iter: 418, Loss: 342.2473, Train MAE hat: 3.4553\n",
      "Iter: 419, Loss: 341.5126, Train MAE hat: 3.4538\n",
      "Iter: 420, Loss: 340.7878, Train MAE hat: 3.4524\n",
      "Iter: 421, Loss: 340.0731, Train MAE hat: 3.4510\n",
      "Iter: 422, Loss: 339.3685, Train MAE hat: 3.4496\n",
      "Iter: 423, Loss: 338.6741, Train MAE hat: 3.4481\n",
      "Iter: 424, Loss: 337.9894, Train MAE hat: 3.4467\n",
      "Iter: 425, Loss: 337.3141, Train MAE hat: 3.4453\n",
      "Iter: 426, Loss: 336.6482, Train MAE hat: 3.4439\n",
      "Iter: 427, Loss: 335.9915, Train MAE hat: 3.4425\n",
      "Iter: 428, Loss: 335.3436, Train MAE hat: 3.4411\n",
      "Iter: 429, Loss: 334.7045, Train MAE hat: 3.4397\n",
      "Iter: 430, Loss: 334.0738, Train MAE hat: 3.4383\n",
      "Iter: 431, Loss: 333.4514, Train MAE hat: 3.4369\n",
      "Iter: 432, Loss: 332.8370, Train MAE hat: 3.4355\n",
      "Iter: 433, Loss: 332.2306, Train MAE hat: 3.4341\n",
      "Iter: 434, Loss: 331.6319, Train MAE hat: 3.4327\n",
      "Iter: 435, Loss: 331.0410, Train MAE hat: 3.4313\n",
      "Iter: 436, Loss: 330.4577, Train MAE hat: 3.4299\n",
      "Iter: 437, Loss: 329.8821, Train MAE hat: 3.4286\n",
      "Iter: 438, Loss: 329.3140, Train MAE hat: 3.4272\n",
      "Iter: 439, Loss: 328.7534, Train MAE hat: 3.4258\n",
      "Iter: 440, Loss: 328.2004, Train MAE hat: 3.4245\n",
      "Iter: 441, Loss: 327.6548, Train MAE hat: 3.4231\n",
      "Iter: 442, Loss: 327.1168, Train MAE hat: 3.4218\n",
      "Iter: 443, Loss: 326.5863, Train MAE hat: 3.4204\n",
      "Iter: 444, Loss: 326.0630, Train MAE hat: 3.4190\n",
      "Iter: 445, Loss: 325.5469, Train MAE hat: 3.4177\n",
      "Iter: 446, Loss: 325.0381, Train MAE hat: 3.4164\n",
      "Iter: 447, Loss: 324.5362, Train MAE hat: 3.4150\n",
      "Iter: 448, Loss: 324.0410, Train MAE hat: 3.4137\n",
      "Iter: 449, Loss: 323.5529, Train MAE hat: 3.4124\n",
      "Iter: 450, Loss: 323.0721, Train MAE hat: 3.4110\n",
      "Iter: 451, Loss: 322.5983, Train MAE hat: 3.4097\n",
      "Iter: 452, Loss: 322.1318, Train MAE hat: 3.4084\n",
      "Iter: 453, Loss: 321.6726, Train MAE hat: 3.4071\n",
      "Iter: 454, Loss: 321.2206, Train MAE hat: 3.4057\n",
      "Iter: 455, Loss: 320.7758, Train MAE hat: 3.4044\n",
      "Iter: 456, Loss: 320.3378, Train MAE hat: 3.4031\n",
      "Iter: 457, Loss: 319.9066, Train MAE hat: 3.4018\n",
      "Iter: 458, Loss: 319.4822, Train MAE hat: 3.4005\n",
      "Iter: 459, Loss: 319.0646, Train MAE hat: 3.3992\n",
      "Iter: 460, Loss: 318.6536, Train MAE hat: 3.3979\n",
      "Iter: 461, Loss: 318.2491, Train MAE hat: 3.3966\n",
      "Iter: 462, Loss: 317.8509, Train MAE hat: 3.3953\n",
      "Iter: 463, Loss: 317.4590, Train MAE hat: 3.3941\n",
      "Iter: 464, Loss: 317.0732, Train MAE hat: 3.3928\n",
      "Iter: 465, Loss: 316.6935, Train MAE hat: 3.3915\n",
      "Iter: 466, Loss: 316.3196, Train MAE hat: 3.3902\n",
      "Iter: 467, Loss: 315.9516, Train MAE hat: 3.3890\n",
      "Iter: 468, Loss: 315.5892, Train MAE hat: 3.3877\n",
      "Iter: 469, Loss: 315.2326, Train MAE hat: 3.3864\n",
      "Iter: 470, Loss: 314.8817, Train MAE hat: 3.3852\n",
      "Iter: 471, Loss: 314.5365, Train MAE hat: 3.3839\n",
      "Iter: 472, Loss: 314.1967, Train MAE hat: 3.3827\n",
      "Iter: 473, Loss: 313.8624, Train MAE hat: 3.3814\n",
      "Iter: 474, Loss: 313.5334, Train MAE hat: 3.3802\n",
      "Iter: 475, Loss: 313.2099, Train MAE hat: 3.3789\n",
      "Iter: 476, Loss: 312.8917, Train MAE hat: 3.3777\n",
      "Iter: 477, Loss: 312.5787, Train MAE hat: 3.3764\n",
      "Iter: 478, Loss: 312.2708, Train MAE hat: 3.3752\n",
      "Iter: 479, Loss: 311.9680, Train MAE hat: 3.3740\n",
      "Iter: 480, Loss: 311.6702, Train MAE hat: 3.3727\n",
      "Iter: 481, Loss: 311.3773, Train MAE hat: 3.3715\n",
      "Iter: 482, Loss: 311.0891, Train MAE hat: 3.3703\n",
      "Iter: 483, Loss: 310.8056, Train MAE hat: 3.3691\n",
      "Iter: 484, Loss: 310.5268, Train MAE hat: 3.3679\n",
      "Iter: 485, Loss: 310.2525, Train MAE hat: 3.3666\n",
      "Iter: 486, Loss: 309.9826, Train MAE hat: 3.3654\n",
      "Iter: 487, Loss: 309.7172, Train MAE hat: 3.3642\n",
      "Iter: 488, Loss: 309.4561, Train MAE hat: 3.3630\n",
      "Iter: 489, Loss: 309.1992, Train MAE hat: 3.3618\n",
      "Iter: 490, Loss: 308.9464, Train MAE hat: 3.3606\n",
      "Iter: 491, Loss: 308.6975, Train MAE hat: 3.3594\n",
      "Iter: 492, Loss: 308.4525, Train MAE hat: 3.3583\n",
      "Iter: 493, Loss: 308.2114, Train MAE hat: 3.3571\n",
      "Iter: 494, Loss: 307.9742, Train MAE hat: 3.3559\n",
      "Iter: 495, Loss: 307.7405, Train MAE hat: 3.3547\n",
      "Iter: 496, Loss: 307.5107, Train MAE hat: 3.3535\n",
      "Iter: 497, Loss: 307.2842, Train MAE hat: 3.3524\n",
      "Iter: 498, Loss: 307.0611, Train MAE hat: 3.3512\n",
      "Iter: 499, Loss: 306.8413, Train MAE hat: 3.3500\n",
      "Test Loss: 308.0571, Test MAE hat: 3.3492\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # initialise iterator with train data\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_train, y: y_train, batch_size: BATCH_SIZE})\n",
    "    print('Training...')\n",
    "    for i in range(EPOCHS):\n",
    "        tot_loss = 0\n",
    "        for _ in range(n_batches):\n",
    "            _, loss_value, tr_lmae = sess.run([training_op, l2_loss, log_MAE_hat])\n",
    "            tot_loss += loss_value\n",
    "        print(\"Iter: {}, Loss: {:.4f}, Train MAE hat: {:.4f}\".format(i, tot_loss / n_batches, tr_lmae))\n",
    "    # initialise iterator with test data\n",
    "    sess.run(iter.initializer, feed_dict={ X: X_val, y: y_val, batch_size: X_val.shape[0]})\n",
    "    t_loss, l_mae = sess.run([l2_loss, log_MAE_hat])\n",
    "    print('Test Loss: {:.4f}, Test MAE hat: {:.4f}'.format(t_loss, l_mae))\n",
    "    save_path = saver.save(sess, \"./my_model_final4.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
